name: Kubernetes Anomalous Inbound to Outbound Network IO Ratio
id: 9d8f6e3f-39df-46d8-a9d4-96173edc501f
version: 2
date: '2024-05-26'
author: Matthew Moore, Splunk
status: experimental
type: Anomaly
description: The following analytic identifies significant changes in network communication
  behavior within Kubernetes containers by examining the inbound to outbound network
  IO ratios. It leverages process metrics from an OTEL collector and Kubelet Stats
  Receiver, along with data from Splunk Observability Cloud. Anomalies are detected
  using a lookup table containing average and standard deviation values for network
  IO, triggering an event if the anomaly persists for over an hour. This activity
  is significant as it may indicate data exfiltration, command and control communication,
  or compromised container behavior. If confirmed malicious, it could lead to data
  breaches, service outages, and unauthorized access within the Kubernetes cluster.
data_source: []
search: '| mstats avg(k8s.pod.network.io) as io where `kubernetes_metrics` by k8s.cluster.name k8s.pod.name k8s.node.name direction span=10s 
  | eval service = replace(''k8s.pod.name'', "-\w{5}$|-[abcdef0-9]{8,10}-\w{5}$", "") 
  | eval key = ''k8s.cluster.name'' + ":" + ''service''
  | stats avg(eval(if(direction="transmit", io,null()))) as outbound_network_io avg(eval(if(direction="receive", io,null()))) as inbound_network_io by key service k8s.cluster.name k8s.pod.name k8s.node.name _time 
  | eval inbound:outbound = inbound_network_io/outbound_network_io 
  | eval outbound:inbound = outbound_network_io/inbound_network_io 
  | fields - *network_io 
  | lookup k8s_container_network_io_ratio_baseline key 
  | eval anomalies = "" 
  | foreach stdev_* 
    [ eval anomalies =if( ''<<MATCHSTR>>'' > (''avg_<<MATCHSTR>>'' + 4 * ''stdev_<<MATCHSTR>>''), anomalies + "<<MATCHSTR>> ratio higher than average by " + 
        tostring(round((''<<MATCHSTR>>'' - ''avg_<<MATCHSTR>>'')/''stdev_<<MATCHSTR>>'' ,2)) + " Standard Deviations. <<MATCHSTR>>=" + tostring(''<<MATCHSTR>>'') + " avg_<<MATCHSTR>>=" 
        + tostring(''avg_<<MATCHSTR>>'') + " ''stdev_<<MATCHSTR>>''=" + tostring(''stdev_<<MATCHSTR>>'') + ", "
        , anomalies)
        ] 
  | eval anomalies = replace(anomalies, ",\s$", "") 
  | where anomalies!="" 
  | stats count values(anomalies) as anomalies by k8s.cluster.name k8s.node.name k8s.pod.name service 
  | rename service as k8s.service  
  | where count > 5
  | rename k8s.node.name as host
  | `kubernetes_anomalous_inbound_to_outbound_network_io_ratio_filter`'
how_to_implement: 'To implement this detection, follow these steps: 
  
  * Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.

  * Enable the hostmetrics/process receiver in the OTEL configuration.

  * Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization,
  are enabled.

  * Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)

  * Configure the SIM add-on with your Observability Cloud Organization ID and Access
  Token.

  * Set up the SIM modular input to ingest Process Metrics. Name this input "sim_process_metrics_to_metrics_index".

  * In the SIM configuration, set the Organization ID to your Observability Cloud
  Organization ID.

  * Set the Signal Flow Program to the following: data(''process.threads'').publish(label=''A'');
  data(''process.cpu.utilization'').publish(label=''B''); data(''process.cpu.time'').publish(label=''C'');
  data(''process.disk.io'').publish(label=''D''); data(''process.memory.usage'').publish(label=''E'');
  data(''process.memory.virtual'').publish(label=''F''); data(''process.memory.utilization'').publish(label=''G'');
  data(''process.cpu.utilization'').publish(label=''H''); data(''process.disk.operations'').publish(label=''I'');
  data(''process.handles'').publish(label=''J''); data(''process.threads'').publish(label=''K'')

  * Set the Metric Resolution to 10000.

  * Leave all other settings at their default values.

  * Run the Search Baseline Of Kubernetes Container Network IO Ratio '
known_false_positives: unknown
references:
- https://github.com/signalfx/splunk-otel-collector-chart
tags:
  analytic_story:
  - Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring
  asset_type: Kubernetes
  confidence: 50
  impact: 50
  message: Kubernetes Anomalous Inbound to Outbound Network IO Ratio from Container
    on host $host$
  mitre_attack_id:
  - T1204
  observable:
  - name: host
    type: Hostname
    role:
    - Victim
  product:
  - Splunk Enterprise
  - Splunk Enterprise Security
  - Splunk Cloud
  required_fields:
  - k8s.pod.network.io
  - direction
  - k8s.cluster.name
  - k8s.node.name
  - k8s.pod.name
  security_domain: network
