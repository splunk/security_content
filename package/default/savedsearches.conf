#############
# Automatically generated by generator.py in splunk/security-content
# On Date: 2020-08-27T18:32:42 UTC
# Author: Splunk Security Research
# Contact: research@splunk.com
#############

### ESCU DETECTIONS ###

[ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen cities.  Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1535"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for AWS provisioning activities from previously unseen cities.  Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new city is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your city, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for AWS provisioning activities from previously unseen cities.  Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.notable.param.rule_title = AWS Cloud Provisioning From Previously Unseen City
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by City | eval newCity=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCity=1 | table City] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, City, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_city_filter`

[ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1535"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for AWS provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching over plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new country is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for AWS provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.notable.param.rule_title = AWS Cloud Provisioning From Previously Unseen Country
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Country | eval newCountry=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCountry=1 | table Country] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Country, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_country_filter`

[ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for AWS provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for AWS provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.notable.param.rule_title = AWS Cloud Provisioning From Previously Unseen IP Address
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` (eventName=Run* OR eventName=Create*) [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | table sourceIPAddress] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_ip_address_filter`

[ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen regions. Region in this context is similar to a state in the United States. Provisioning activities are defined broadly as any event that begins with "Run" or "Create."
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1535"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for AWS provisioning activities from previously unseen regions. Region in this context is similar to a state in the United States. Provisioning activities are defined broadly as any event that begins with "Run" or "Create."
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new region is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your region, there should be few false positives. If you are located in regions where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for AWS provisioning activities from previously unseen regions. Region in this context is similar to a state in the United States. Provisioning activities are defined broadly as any event that begins with "Run" or "Create."
action.notable.param.rule_title = AWS Cloud Provisioning From Previously Unseen Region
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Region | eval newRegion=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newRegion=1 | table Region] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Region, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_region_filter`

[ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the `Previously Seen AWS Cross Account Activity` support search only once to create the baseline of previously seen cross account activity. Thanks to Pablo Vega at Recurly for suggesting improvements to the search.
action.escu.known_false_positives = Using multiple AWS accounts and roles is perfectly valid behavior. It's suspicious when an account requests privileges of an account it hasn't before. You should validate with the account owner that this is a legitimate request.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.
action.notable.param.rule_title = AWS Cross Account Activity From Previously Unseen Account
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId != requestedAccountId | inputlookup append=t previously_seen_aws_cross_account_activity | multireport [| stats min(eval(coalesce(firstTime, _time))) as firstTime max(eval(coalesce(lastTime, _time))) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | where fact=fiction] [| eventstats min(eval(coalesce(firstTime, _time))) as firstTime, max(eval(coalesce(lastTime, _time))) as lastTime by requestingAccountId, requestedAccountId | where firstTime >= relative_time(now(), "-70m@m") AND isnotnull(_time) | spath output=accessKeyId path=responseElements.credentials.accessKeyId | spath output=requestingARN path=resources{}.ARN | stats values(awsRegion) as awsRegion values(firstTime) as firstTime values(lastTime) as lastTime values(sharedEventID) as sharedEventID, values(requestingARN) as src_user, values(responseElements.assumedRoleUser.arn) as dest_user by _time, requestingAccountId, requestedAccountId, accessKeyId] | table _time, firstTime, lastTime, src_user, requestingAccountId, dest_user, requestedAccountId, awsRegion, accessKeyId, sharedEventID | `aws_cross_account_activity_from_previously_unseen_account_filter`

[ESCU - AWS EKS Kubernetes cluster sensitive object access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.
action.escu.known_false_positives = Sensitive object access is not necessarily malicious but user and object context can provide guidance for detection.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS EKS Kubernetes cluster sensitive object access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS EKS Kubernetes cluster sensitive object access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets
action.notable.param.rule_title = AWS EKS Kubernetes cluster sensitive object access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` objectRef.resource=secrets OR configmaps sourceIPs{}!=::1 sourceIPs{}!=127.0.0.1  |table sourceIPs{} user.username user.groups{} objectRef.resource objectRef.namespace objectRef.name annotations.authorization.k8s.io/reason |dedup user.username user.groups{} |`aws_eks_kubernetes_cluster_sensitive_object_access_filter`

[ESCU - AWS Network Access Control List Created with All Open Ports - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.
action.escu.creation_date = 2017-01-10
action.escu.modification_date = 2017-01-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Network Access Control List Created with All Open Ports - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Network Access Control List Created with All Open Ports - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src']
action.notable.param.rule_description = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
action.notable.param.rule_title = AWS Network Access Control List Created with All Open Ports
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=CreateNetworkAclEntry | mvexpand requestParameters | mvexpand responseElements | search requestParameters.portRange.from=1024 requestParameters.portRange.to=65535 requestParameters.ruleAction=allow | rename userIdentity.arn as arn | rename requestParameters.networkAclId as networkAclId | table _time aws_account_id src userName arn networkAclId requestParameters.* responseElements.* | `aws_network_access_control_list_created_with_all_open_ports_filter`

[ESCU - AWS Network Access Control List Deleted - Rule]
action.escu = 0
action.escu.enabled = 1
description = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that a user has legitimately deleted a network ACL.
action.escu.creation_date = 2017-01-10
action.escu.modification_date = 2017-01-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Network Access Control List Deleted - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Network Access Control List Deleted - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src']
action.notable.param.rule_description = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
action.notable.param.rule_title = AWS Network Access Control List Deleted
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=DeleteNetworkAcl|rename userIdentity.arn as arn  | stats count min(_time) as firstTime max(_time) as lastTime values(errorMessage) values(errorCode) values(userAgent) values(userIdentity.*) by src userName arn eventName | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `aws_network_access_control_list_deleted_filter`

[ESCU - Abnormally High AWS Instances Launched by User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Launched by User - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High AWS Instances Launched by User - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.notable.param.rule_title = Abnormally High AWS Instances Launched by User
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success | bucket span=10m _time | stats count AS instances_launched by _time userName | eventstats avg(instances_launched) as total_launched_avg, stdev(instances_launched) as total_launched_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_launched > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m") | eval num_standard_deviations_away = round(abs(instances_launched - total_launched_avg) / total_launched_stdev, 2) | table _time, userName, instances_launched, num_standard_deviations_away, total_launched_avg, total_launched_stdev | `abnormally_high_aws_instances_launched_by_user_filter`

[ESCU - Abnormally High AWS Instances Launched by User - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Launched by User - MLTK - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High AWS Instances Launched by User - MLTK - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.notable.param.rule_title = Abnormally High AWS Instances Launched by User - MLTK
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success `abnormally_high_aws_instances_launched_by_user___mltk_filter` | bucket span=10m _time  | stats count as instances_launched by _time src_user  | apply ec2_excessive_runinstances_v1  | rename "IsOutlier(instances_launched)" as isOutlier  | where isOutlier=1

[ESCU - Abnormally High AWS Instances Terminated by User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where an abnormally high number of instances were successfully terminated by a user in a 10-minute window
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where an abnormally high number of instances were successfully terminated by a user in a 10-minute window
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = Many service accounts configured with your AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify whether this search alerted on a human user.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Terminated by User - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High AWS Instances Terminated by User - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for CloudTrail events where an abnormally high number of instances were successfully terminated by a user in a 10-minute window
action.notable.param.rule_title = Abnormally High AWS Instances Terminated by User
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=TerminateInstances errorCode=success | bucket span=10m _time | stats count AS instances_terminated by _time userName | eventstats avg(instances_terminated) as total_terminations_avg, stdev(instances_terminated) as total_terminations_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_terminated > total_terminations_avg+(total_terminations_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m")| eval num_standard_deviations_away = round(abs(instances_terminated - total_terminations_avg) / total_terminations_stdev, 2) |table _time, userName, instances_terminated, num_standard_deviations_away, total_terminations_avg, total_terminations_stdev | `abnormally_high_aws_instances_terminated_by_user_filter`

[ESCU - Abnormally High AWS Instances Terminated by User - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user successfully terminates an abnormally high number of instances.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user successfully terminates an abnormally high number of instances.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Terminated by User - MLTK - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High AWS Instances Terminated by User - MLTK - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events where a user successfully terminates an abnormally high number of instances.
action.notable.param.rule_title = Abnormally High AWS Instances Terminated by User - MLTK
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=TerminateInstances errorCode=success `abnormally_high_aws_instances_terminated_by_user___mltk_filter` | bucket span=10m _time  | stats count as instances_terminated by _time src_user  | apply ec2_excessive_terminateinstances_v1  | rename "IsOutlier(instances_terminated)" as isOutlier  | where isOutlier=1

[ESCU - Access LSASS Memory for Dump Creation - Rule]
action.escu = 0
action.escu.enabled = 1
description = Detect memory dumping of the LSASS process.
action.escu.mappings = {"cis20": ["CIS 6", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.001"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = Detect memory dumping of the LSASS process.
action.escu.how_to_implement = This search requires Sysmon Logs and a Sysmon configuration, which includes EventCode 10 for lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Administrators can create memory dumps for debugging purposes, but memory dumps of the LSASS process would be unusual.
action.escu.creation_date = 2019-12-06
action.escu.modification_date = 2019-12-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Access LSASS Memory for Dump Creation - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Access LSASS Memory for Dump Creation - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = Detect memory dumping of the LSASS process.
action.notable.param.rule_title = Access LSASS Memory for Dump Creation
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `sysmon` EventCode=10 TargetImage=*lsass.exe CallTrace=*dbgcore.dll* OR CallTrace=*dbghelp.dll* | stats count min(_time) as firstTime max(_time) as lastTime by Computer, TargetImage, TargetProcessId, SourceImage, SourceProcessId | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `access_lsass_memory_for_dump_creation_filter` 

[ESCU - Amazon EKS Kubernetes Pod scan detection - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection information on unauthenticated requests against Kubernetes' Pods API
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"], "mitre_attack": ["T1526"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection information on unauthenticated requests against Kubernetes' Pods API
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on forAWS (version 4.4.0 or later), then configure your AWS CloudWatch EKS Logs.Please also customize the `kubernetes_pods_aws_scan_fingerprint_detection` macro to filter out the false positives.
action.escu.known_false_positives = Not all unauthenticated requests are malicious, but frequency, UA and source IPs and direct request to API provide context.
action.escu.creation_date = 2020-04-15
action.escu.modification_date = 2020-04-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Amazon EKS Kubernetes Pod scan detection - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Amazon EKS Kubernetes Pod scan detection - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides detection information on unauthenticated requests against Kubernetes' Pods API
action.notable.param.rule_title = Amazon EKS Kubernetes Pod scan detection
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` "user.username"="system:anonymous" verb=list objectRef.resource=pods requestURI="/api/v1/pods" | rename source as cluster_name sourceIPs{} as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(responseStatus.reason) values(responseStatus.code) values(userAgent) values(verb) values(requestURI) by src_ip cluster_name user.username user.groups{} | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `amazon_eks_kubernetes_pod_scan_detection_filter` 

[ESCU - Amazon EKS Kubernetes cluster scan detection - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster in AWS
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"], "mitre_attack": ["T1526"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster in AWS
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudWatch EKS Logs inputs.
action.escu.known_false_positives = Not all unauthenticated requests are malicious, but frequency, UA and source IPs will provide context.
action.escu.creation_date = 2020-04-15
action.escu.modification_date = 2020-04-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Amazon EKS Kubernetes cluster scan detection - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Amazon EKS Kubernetes cluster scan detection - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster in AWS
action.notable.param.rule_title = Amazon EKS Kubernetes cluster scan detection
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` "user.username"="system:anonymous" userAgent!="AWS Security Scanner" | rename sourceIPs{} as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(responseStatus.reason) values(source) as cluster_name values(responseStatus.code) values(userAgent) as http_user_agent values(verb) values(requestURI) by src_ip user.username user.groups{} | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` |`amazon_eks_kubernetes_cluster_scan_detection_filter` 

[ESCU - Attempt To Add Certificate To Untrusted Store - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attempt to add a certificate to the untrusted certificate store
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["T1553.004"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attempt to add a certificate to the untrusted certificate store
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = There may be legitimate reasons for administrators to add a certificate to the untrusted certificate store. In such cases, this will typically be done on a large number of systems.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Add Certificate To Untrusted Store - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Attempt To Add Certificate To Untrusted Store - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = Attempt to add a certificate to the untrusted certificate store
action.notable.param.rule_title = Attempt To Add Certificate To Untrusted Store
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=certutil.exe (Processes.process=*-addstore* AND Processes.process=*disallowed* ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `attempt_to_add_certificate_to_untrusted_store_filter`

[ESCU - Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass - Rule]
action.escu = 0
action.escu.enabled = 1
description = Monitor for changes of the ExecutionPolicy in the registry to the values "unrestricted" or "bypass," which allows the execution of malicious scripts.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["T1059.001"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Monitor for changes of the ExecutionPolicy in the registry to the values "unrestricted" or "bypass," which allows the execution of malicious scripts.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Registry node. You must also be ingesting logs with the fields registry_path, registry_key_name, and registry_value_name from your endpoints.
action.escu.known_false_positives = Administrators may attempt to change the default execution policy on a system for a variety of reasons. However, setting the policy to "unrestricted" or "bypass" as this search is designed to identify, would be unusual. Hits should be reviewed and investigated as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Malicious PowerShell", "Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = Monitor for changes of the ExecutionPolicy in the registry to the values "unrestricted" or "bypass," which allows the execution of malicious scripts.
action.notable.param.rule_title = Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Registry where Registry.registry_path=*Software\\Microsoft\\Powershell\\1\\ShellIds\\Microsoft.PowerShell* Registry.registry_key_name=ExecutionPolicy (Registry.registry_value_name=Unrestricted OR Registry.registry_value_name=Bypass) by Registry.registry_path Registry.registry_key_name Registry.registry_value_name Registry.dest | `drop_dm_object_name(Registry)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `attempt_to_set_default_powershell_execution_policy_to_unrestricted_or_bypass_filter`

[ESCU - Attempt To Stop Security Service - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for attempts to stop security-related services on the endpoint.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["T1562.001"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for attempts to stop security-related services on the endpoint.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data. The search is shipped with a lookup file, `security_services.csv`, that can be edited to update the list of services to monitor. This lookup file can be edited directly where it lives in `$SPLUNK_HOME/etc/apps/DA-ESS-ContentUpdate/lookups`, or via the Splunk console. You should add the names of services an attacker might use on the command line and surround with asterisks (*****), so that they work properly when searching the command line. The file should be updated with the names of any services you would like to monitor for attempts to stop the service.,
action.escu.known_false_positives = None identified. Attempts to disable security-related services should be identified and understood.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Stop Security Service - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Attempt To Stop Security Service - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for attempts to stop security-related services on the endpoint.
action.notable.param.rule_title = Attempt To Stop Security Service
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name = net.exe OR  Processes.process_name = sc.exe) Processes.process="* stop *" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |lookup security_services_lookup service as process OUTPUTNEW category, description | search category=security | `attempt_to_stop_security_service_filter`

[ESCU - Attempted Credential Dump From Registry via Reg exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = Monitor for execution of reg.exe with parameters specifying an export of keys that contain hashed credentials that attackers may try to crack offline.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.002"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Monitor for execution of reg.exe with parameters specifying an export of keys that contain hashed credentials that attackers may try to crack offline.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2019-12-02
action.escu.modification_date = 2019-12-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempted Credential Dump From Registry via Reg exe - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Attempted Credential Dump From Registry via Reg exe - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Monitor for execution of reg.exe with parameters specifying an export of keys that contain hashed credentials that attackers may try to crack offline.
action.notable.param.rule_title = Attempted Credential Dump From Registry via Reg exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=reg.exe OR Processes.process_name=cmd.exe) Processes.process=*save* (Processes.process=*HKEY_LOCAL_MACHINE\\Security* OR Processes.process=*HKEY_LOCAL_MACHINE\\SAM* OR Processes.process=*HKEY_LOCAL_MACHINE\\System* OR Processes.process=*HKLM\\Security* OR Processes.process=*HKLM\\System* OR Processes.process=*HKLM\\SAM*) by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `attempted_credential_dump_from_registry_via_reg_exe_filter` 

[ESCU - Batch File Write to System32 - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a batch file (.bat) written to the Windows system directory tree.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Delivery"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for a batch file (.bat) written to the Windows system directory tree.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = It is possible for this search to generate a notable event for a batch file write to a path that includes the string "system32", but is not the actual Windows system directory. As such, you should confirm the path of the batch file identified by the search. In addition, a false positive may be generated by an administrator copying a legitimate batch file in this directory tree. You should confirm that the activity is legitimate and modify the search to add exclusions, as necessary.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - Batch File Write to System32 - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Batch File Write to System32 - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The search looks for a batch file (.bat) written to the Windows system directory tree.
action.notable.param.rule_title = Batch File Write to System32
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name values(Filesystem.user) as user from datamodel=Endpoint.Filesystem by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_path=*system32* AND file_extension=.bat | `batch_file_write_to_system32_filter`

[ESCU - Child Processes of Spoolsv exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for child processes of spoolsv.exe. This activity is associated with a POC privilege-escalation exploit associated with CVE-2018-8440. Spoolsv.exe is the process associated with the Print Spooler service in Windows and typically runs as SYSTEM.
action.escu.mappings = {"cis20": ["CIS 5", "CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["T1068"], "nist": ["PR.AC", "PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for child processes of spoolsv.exe. This activity is associated with a POC privilege-escalation exploit associated with CVE-2018-8440. Spoolsv.exe is the process associated with the Print Spooler service in Windows and typically runs as SYSTEM.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model. Update the `children_of_spoolsv_filter` macro to filter out legitimate child processes spawned by spoolsv.exe.
action.escu.known_false_positives = Some legitimate printer-related processes may show up as children of spoolsv.exe. You should confirm that any activity as legitimate and may be added as exclusions in the search.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Child Processes of Spoolsv exe - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Child Processes of Spoolsv exe - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for child processes of spoolsv.exe. This activity is associated with a POC privilege-escalation exploit associated with CVE-2018-8440. Spoolsv.exe is the process associated with the Print Spooler service in Windows and typically runs as SYSTEM.
action.notable.param.rule_title = Child Processes of Spoolsv exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process_name) as process_name values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name=spoolsv.exe AND Processes.process_name!=regsvr32.exe by Processes.dest Processes.parent_process Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `child_processes_of_spoolsv_exe_filter` 

[ESCU - Clients Connecting to Multiple DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify the endpoints that have connected to more than five DNS servers and made DNS Queries over the time frame of the search.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12", "CIS 13"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1048.003"], "nist": ["PR.PT", "DE.AE", "PR.DS"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search allows you to identify the endpoints that have connected to more than five DNS servers and made DNS Queries over the time frame of the search.
action.escu.how_to_implement = This search requires that DNS data is being ingested and populating the `Network_Resolution` data model. This data can come from DNS logs or from solutions that parse network traffic for this data, such as Splunk Stream or Bro.\
This search produces fields (`dest_count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** Distinct DNS Connections, **Field:** dest_count\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It's possible that an enterprise has more than five DNS servers that are configured in a round-robin rotation. Please customize the search, as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Clients Connecting to Multiple DNS Servers - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DNS Hijacking", "Command and Control", "Suspicious DNS Traffic", "Host Redirection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Clients Connecting to Multiple DNS Servers - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search allows you to identify the endpoints that have connected to more than five DNS servers and made DNS Queries over the time frame of the search.
action.notable.param.rule_title = Clients Connecting to Multiple DNS Servers
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count, values(DNS.dest) AS dest dc(DNS.dest) as dest_count from datamodel=Network_Resolution where DNS.message_type=QUERY by DNS.src | `drop_dm_object_name("Network_Resolution")` |where dest_count > 5 | `clients_connecting_to_multiple_dns_servers_filter` 

[ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud compute instances created by users who have not created them before.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = This search looks for cloud compute instances created by users who have not created them before.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the "Previously Seen Cloud Compute Creations By User" support search to create of baseline of previously seen users.
action.escu.known_false_positives = It's possible that a user will start to create compute instances for the first time, for any number of reasons. Verify with the user launching instances that this is the intended behavior.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for cloud compute instances created by users who have not created them before.
action.notable.param.rule_title = Cloud Compute Instance Created By Previously Unseen User
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.action=run by Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_creations_by_user  | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by src_user | multireport [| table src_user, firstTime, lastTime | outputlookup previously_seen_cloud_compute_creations_by_user | where fact=fiction][| eval new_user=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_creations_by_user_search_window_begin_offset`), 1, 0) | where new_user=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table src_user, dest, firstTime, lastTime | `cloud_compute_instance_created_by_previously_unseen_user_filter`

[ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud compute instances being created with previously unseen image IDs.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = This search looks for cloud compute instances being created with previously unseen image IDs.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the "Previously Seen Cloud Compute Images" support search to create a baseline of previously seen images.
action.escu.known_false_positives = After a new image is created, the first systems created with that image will cause this alert to fire.  Verify that the image being used was created by a legitimate user.
action.escu.creation_date = 2018-10-12
action.escu.modification_date = 2018-10-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for cloud compute instances being created with previously unseen image IDs.
action.notable.param.rule_title = Cloud Compute Instance Created With Previously Unseen Image
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `cloud_compute_instance_created_with_previously_unseen_image_filter` by Compute.image_id, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_images | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by image_id, src_user | multireport [| table image_id, firstTime, lastTime | outputlookup previously_seen_cloud_compute_images | where fact=fiction][| eval new_image=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_image_search_window_begin_offset`), 1, 0) | where new_image=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table image_id, dest, src_user, firstTime, lastTime

[ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule]
action.escu = 0
action.escu.enabled = 1
description = Find EC2 instances being created with previously unseen instance types.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = Find EC2 instances being created with previously unseen instance types.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the " Previously Seen Cloud Compute Instance Types" support search to create a baseline of previously seen regions.
action.escu.known_false_positives = It is possible that an admin will create a new system using a new instance type that has never been used before. Verify with the creator that they intended to create the system with the new instance type.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Find EC2 instances being created with previously unseen instance types.
action.notable.param.rule_title = Cloud Compute Instance Created With Previously Unseen Instance Type
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.event_name=RunInstances `cloud_compute_instance_created_with_previously_unseen_instance_type_filter` by Compute.instance_type, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_instance_types | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by instance_type, src_user | multireport [| table instance_type, firstTime, lastTime | outputlookup previously_seen_cloud_compute_instance_types | where fact=fiction][| eval new_type=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_instance_types_search_window_begin_offset`), 1, 0) | where new_type=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table instance_type, dest, src_user, firstTime, lastTime

[ESCU - Cloud Compute Instance Started In Previously Unused Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.
action.escu.mappings = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the \"Previously Seen Cloud Compute Instance Types\" support search to create a baseline of previously seen regions.
action.escu.known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
action.escu.creation_date = 2019-10-02
action.escu.modification_date = 2019-10-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Started In Previously Unused Region - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Started In Previously Unused Region - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.
action.notable.param.rule_title = Cloud Compute Instance Started In Previously Unused Region
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.event_name=RunInstances `cloud_compute_instance_started_in_previously_unused_region_filter` by Compute.region, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_regions | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by region, src_user | multireport [| table region, firstTime, lastTime | outputlookup previously_seen_cloud_regions | where fact=fiction][| eval new_region=if(firstTime >= relative_time(now(), `previously_seen_cloud_regions_search_window_begin_offset`), 1, 0) | where new_region=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table region, dest, src_user, firstTime, lastTime

[ESCU - Common Ransomware Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for file modifications with extensions commonly used by Ransomware
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for file modifications with extensions commonly used by Ransomware
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.\
This search produces fields (`query`,`query_length`,`count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** Name, **Field:** Name\
1. \
1. **Label:** File Extension, **Field:** file_extension\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It is possible for a legitimate file with these extensions to be created. If this is a true ransomware attack, there will be a large number of files created with these extensions.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Common Ransomware Extensions - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Common Ransomware Extensions - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The search looks for file modifications with extensions commonly used by Ransomware
action.notable.param.rule_title = Common Ransomware Extensions
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | `ransomware_extensions` | `common_ransomware_extensions_filter`

[ESCU - Common Ransomware Notes - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for files created with names matching those typically used in ransomware notes that tell the victim how to get their data back.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for files created with names matching those typically used in ransomware notes that tell the victim how to get their data back.
action.escu.how_to_implement = You must be ingesting data that records file-system activity from your hosts to populate the Endpoint Filesystem data-model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = It's possible that a legitimate file could be created with the same name used by ransomware note files.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Common Ransomware Notes - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Common Ransomware Notes - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The search looks for files created with names matching those typically used in ransomware notes that tell the victim how to get their data back.
action.notable.param.rule_title = Common Ransomware Notes
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `ransomware_notes` | `common_ransomware_notes_filter`

[ESCU - Create Remote Thread into LSASS - Rule]
action.escu = 0
action.escu.enabled = 1
description = Detect remote thread creation into LSASS consistent with credential dumping.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.001"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = Detect remote thread creation into LSASS consistent with credential dumping.
action.escu.how_to_implement = This search needs Sysmon Logs with a Sysmon configuration, which includes EventCode 8 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Other tools can access LSASS for legitimate reasons and generate an event. In these cases, tweaking the search may help eliminate noise.
action.escu.creation_date = 2019-12-06
action.escu.modification_date = 2019-12-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Create Remote Thread into LSASS - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Create Remote Thread into LSASS - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = Detect remote thread creation into LSASS consistent with credential dumping.
action.notable.param.rule_title = Create Remote Thread into LSASS
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `sysmon` EventID=8 TargetImage=*lsass.exe | stats count min(_time) as firstTime max(_time) as lastTime by Computer, EventCode, TargetImage, TargetProcessId | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `create_remote_thread_into_lsass_filter`

[ESCU - Create local admin accounts using net exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of local administrator accounts using net.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.001"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the creation of local administrator accounts using net.exe.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators often leverage net.exe to create admin accounts.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Create local admin accounts using net exe - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Create local admin accounts using net exe - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for the creation of local administrator accounts using net.exe.
action.notable.param.rule_title = Create local admin accounts using net exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=net.exe OR Processes.process_name=net1.exe) AND (Processes.process=*localgroup* OR Processes.process=*/add* OR Processes.process=*user*) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`create_local_admin_accounts_using_net_exe_filter` 

[ESCU - Create or delete windows shares using net exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation or deletion of hidden shares using net.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1059.003"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the creation or deletion of hidden shares using net.exe.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators often leverage net.exe to create or delete network shares. You should verify that the activity was intentional and is legitimate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Create or delete windows shares using net exe - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Hidden Cobra Malware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Create or delete windows shares using net exe - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for the creation or deletion of hidden shares using net.exe.
action.notable.param.rule_title = Create or delete windows shares using net exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processs.process_name=net.exe OR Processes.process_name=net1.exe) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process=*share* | `create_or_delete_windows_shares_using_net_exe_filter` 

[ESCU - Creation of Shadow Copy - Rule]
action.escu = 0
action.escu.enabled = 1
description = Monitor for signs that Ntdsutil, Vssadmin, or Wmic has been used to create a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.003"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Monitor for signs that Ntdsutil, Vssadmin, or Wmic has been used to create a shadow copy.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legtimate administrator usage of Ntdsutil, Vssadmin, or Wmic will create false positives.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Creation of Shadow Copy - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Creation of Shadow Copy - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Monitor for signs that Ntdsutil, Vssadmin, or Wmic has been used to create a shadow copy.
action.notable.param.rule_title = Creation of Shadow Copy
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=ntdsutil.exe Processes.process=*ntds* Processes.process=*create*) OR (Processes.process_name=vssadmin.exe Processes.process=*create* Processes.process=*shadow*) OR (Processes.process_name=wmic.exe Processes.process=*shadowcopy* Processes.process=*create*) by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `creation_of_shadow_copy_filter`

[ESCU - Creation of Shadow Copy with wmic and powershell - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the use of wmic and Powershell to create a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.003"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search detects the use of wmic and Powershell to create a shadow copy.
action.escu.how_to_implement = none
action.escu.known_false_positives = Legtimate administrator usage of wmic to create a shadow copy.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Creation of Shadow Copy with wmic and powershell - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Creation of Shadow Copy with wmic and powershell - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search detects the use of wmic and Powershell to create a shadow copy.
action.notable.param.rule_title = Creation of Shadow Copy with wmic and powershell
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=wmic* OR Processes.process_name=powershell* Processes.process=*shadowcopy* Processes.process=*create* by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `creation_of_shadow_copy_with_wmic_and_powershell_filter`

[ESCU - Credential Dumping via Copy Command from Shadow Copy - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects credential dumping using copy command from a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.003"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search detects credential dumping using copy command from a shadow copy.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = unknown
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Credential Dumping via Copy Command from Shadow Copy - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Credential Dumping via Copy Command from Shadow Copy - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search detects credential dumping using copy command from a shadow copy.
action.notable.param.rule_title = Credential Dumping via Copy Command from Shadow Copy
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe (Processes.process=*\\system32\\config\\sam* OR Processes.process=*\\system32\\config\\security* OR Processes.process=*\\system32\\config\\system* OR Processes.process=*\\windows\\ntds\\ntds.dit*) by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `credential_dumping_via_copy_command_from_shadow_copy_filter` 

[ESCU - Credential Dumping via Symlink to Shadow Copy - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the creation of a symlink to a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.003"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search detects the creation of a symlink to a shadow copy.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = unknown
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Credential Dumping via Symlink to Shadow Copy - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Credential Dumping via Symlink to Shadow Copy - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search detects the creation of a symlink to a shadow copy.
action.notable.param.rule_title = Credential Dumping via Symlink to Shadow Copy
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe Processes.process=*mklink* Processes.process=*HarddiskVolumeShadowCopy* by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `credential_dumping_via_symlink_to_shadow_copy_filter` 

[ESCU - DNS Query Length Outliers - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify DNS requests that are unusually large for the record type being requested in your environment.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1071.004"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search allows you to identify DNS requests that are unusually large for the record type being requested in your environment.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, the Machine Learning Toolkit (MLTK) version 4.2 or greater must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of DNS Query Length - MLTK" must be executed before this detection search, because it builds a machine-learning (ML) model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.\
This search produces fields (`query`,`query_length`,`count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** DNS Query, **Field:** query\
1. \
1. **Label:** DNS Query Length, **Field:** query_length\
1. \
1. **Label:** Number of events, **Field:** count\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = If you are seeing more results than desired, you may consider reducing the value for threshold in the search. You should also periodically re-run the support search to re-build the ML model on the latest data.
action.escu.creation_date = 2020-01-22
action.escu.modification_date = 2020-01-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - DNS Query Length Outliers - MLTK - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Hidden Cobra Malware", "Suspicious DNS Traffic", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - DNS Query Length Outliers - MLTK - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search allows you to identify DNS requests that are unusually large for the record type being requested in your environment.
action.notable.param.rule_title = DNS Query Length Outliers - MLTK
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as start_time max(_time) as end_time values(DNS.src) as src values(DNS.dest) as dest from datamodel=Network_Resolution by DNS.query DNS.record_type | search DNS.record_type=* |  `drop_dm_object_name(DNS)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | eval query_length = len(query) | apply dns_query_pdfmodel threshold=0.01 | rename "IsOutlier(query_length)" as isOutlier | search isOutlier > 0 | sort -query_length | table start_time end_time query record_type count src dest query_length | `dns_query_length_outliers___mltk_filter` 

[ESCU - DNS Query Length With High Standard Deviation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify DNS requests and compute the standard deviation on the length of the names being resolved, then filter on two times the standard deviation to show you those queries that are unusually large for your environment.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1071.004"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search allows you to identify DNS requests and compute the standard deviation on the length of the names being resolved, then filter on two times the standard deviation to show you those queries that are unusually large for your environment.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = It's possible there can be long domain names that are legitimate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - DNS Query Length With High Standard Deviation - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Hidden Cobra Malware", "Suspicious DNS Traffic", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - DNS Query Length With High Standard Deviation - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search allows you to identify DNS requests and compute the standard deviation on the length of the names being resolved, then filter on two times the standard deviation to show you those queries that are unusually large for your environment.
action.notable.param.rule_title = DNS Query Length With High Standard Deviation
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type |  `drop_dm_object_name("DNS")` | eval query_length = len(query) | table query query_length record_type count | eventstats stdev(query_length) AS stdev avg(query_length) AS avg p50(query_length) AS p50| where query_length>(avg+stdev*2) | eval z_score=(query_length-avg)/stdev | `dns_query_length_with_high_standard_deviation_filter` 

[ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect DNS requests resolved by unauthorized DNS servers. Legitimate DNS servers should be identified in the Enterprise Security Assets and Identity Framework.
action.escu.mappings = {"cis20": ["CIS 1", "CIS 3", "CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1071.004"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search will detect DNS requests resolved by unauthorized DNS servers. Legitimate DNS servers should be identified in the Enterprise Security Assets and Identity Framework.
action.escu.how_to_implement = To successfully implement this search you will need to ensure that DNS data is populating the Network_Resolution data model. It also requires that your DNS servers are identified correctly in the Assets and Identity table of Enterprise Security.
action.escu.known_false_positives = Legitimate DNS activity can be detected in this search. Investigate, verify and update the list of authorized DNS servers as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DNS Hijacking", "Command and Control", "Suspicious DNS Traffic", "Host Redirection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search will detect DNS requests resolved by unauthorized DNS servers. Legitimate DNS servers should be identified in the Enterprise Security Assets and Identity Framework.
action.notable.param.rule_title = DNS Query Requests Resolved by Unauthorized DNS Servers
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution where DNS.dest_category != dns_server AND DNS.src_category != dns_server by DNS.src DNS.dest | `drop_dm_object_name("DNS")` | `dns_query_requests_resolved_by_unauthorized_dns_servers_filter` 

[ESCU - DNS record changed - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search takes the DNS records and their answers results of the discovered_dns_records lookup and finds if any records have changed by searching DNS response from the Network_Resolution datamodel across the last day.
action.escu.mappings = {"cis20": ["CIS 1", "CIS 3", "CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1071.004"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = The search takes the DNS records and their answers results of the discovered_dns_records lookup and finds if any records have changed by searching DNS response from the Network_Resolution datamodel across the last day.
action.escu.how_to_implement = To successfully implement this search you will need to ensure that DNS data is populating the `Network_Resolution` data model. It also requires that the `discover_dns_record` lookup table be populated by the included support search "Discover DNS record". \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called "DNS Hijack Enrichment" can be configured to run when any results are found by this detection search. The playbook takes in the DNS record changed and uses Geoip, whois, Censys and PassiveTotal to detect if DNS issuers changed. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook Link:`https://my.phantom.us/4.2/playbook/dns-hijack-enrichment/`).\

action.escu.known_false_positives = Legitimate DNS changes can be detected in this search. Investigate, verify and update the list of provided current answers for the domains in question as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - DNS record changed - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DNS Hijacking"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - DNS record changed - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src']
action.notable.param.rule_description = The search takes the DNS records and their answers results of the discovered_dns_records lookup and finds if any records have changed by searching DNS response from the Network_Resolution datamodel across the last day.
action.notable.param.rule_title = DNS record changed
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | inputlookup discovered_dns_records.csv | rename answer as discovered_answer | join domain[|tstats `security_content_summariesonly` count values(DNS.record_type) as type, values(DNS.answer) as current_answer values(DNS.src) as src from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,src,domain,type,query,current_answer,discovered_answer | makemv current_answer  | mvexpand current_answer | makemv discovered_answer | eval n=mvfind(discovered_answer, current_answer) | where isnull(n) | `dns_record_changed_filter`

[ESCU - Deleting Shadow Copies - Rule]
action.escu = 0
action.escu.enabled = 1
description = The vssadmin.exe utility is used to interact with the Volume Shadow Copy Service.  Wmic is an interface to the Windows Management Instrumentation.  This search looks for either of these tools being used to delete shadow copies.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 10"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1485"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The vssadmin.exe utility is used to interact with the Volume Shadow Copy Service.  Wmic is an interface to the Windows Management Instrumentation.  This search looks for either of these tools being used to delete shadow copies.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = vssadmin.exe and wmic.exe are standard applications shipped with modern versions of windows. They may be used by administrators to legitimately delete old backup copies, although this is typically rare.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Deleting Shadow Copies - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Log Manipulation", "SamSam Ransomware", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Deleting Shadow Copies - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The vssadmin.exe utility is used to interact with the Volume Shadow Copy Service.  Wmic is an interface to the Windows Management Instrumentation.  This search looks for either of these tools being used to delete shadow copies.
action.notable.param.rule_title = Deleting Shadow Copies
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=vssadmin.exe OR Processes.process_name=wmic.exe)  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process=*delete* AND process=*shadow* | `deleting_shadow_copies_filter`

[ESCU - Detect API activity from users without MFA - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user logged into the AWS account, is making API calls and has not enabled Multi Factor authentication. Multi factor authentication adds a layer of security by forcing the users to type a unique authentication code from an approved authentication device when they access AWS websites or services. AWS Best Practices recommend that you enable MFA for privileged IAM users.
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["DE.DP", "PR.AC"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user logged into the AWS account, is making API calls and has not enabled Multi Factor authentication. Multi factor authentication adds a layer of security by forcing the users to type a unique authentication code from an approved authentication device when they access AWS websites or services. AWS Best Practices recommend that you enable MFA for privileged IAM users.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Leverage the support search `Create a list of approved AWS service accounts`: run it once every 30 days to create a list of service accounts and validate them.\
This search produces fields (`eventName`,`userIdentity.type`,`userIdentity.arn`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** AWS User ARN, **Field:** userIdentity.arn\
1. \
1. **Label:** AWS User Type, **Field:** userIdentity.type\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure do not have multi factor authentication enabled. Please ignore the service accounts, if triggered and instead add them to the aws_service_accounts.csv file to fine tune the detection. It is also possible that the search detects users in your environment using Single Sign-On systems, since the MFA is not handled by AWS.
action.escu.creation_date = 2018-05-17
action.escu.modification_date = 2018-05-17
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect API activity from users without MFA - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect API activity from users without MFA - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events where a user logged into the AWS account, is making API calls and has not enabled Multi Factor authentication. Multi factor authentication adds a layer of security by forcing the users to type a unique authentication code from an approved authentication device when they access AWS websites or services. AWS Best Practices recommend that you enable MFA for privileged IAM users.
action.notable.param.rule_title = Detect API activity from users without MFA
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` userIdentity.sessionContext.attributes.mfaAuthenticated=false | search NOT [| inputlookup aws_service_accounts | fields identity | rename identity as user]| stats  count min(_time) as firstTime max(_time) as lastTime values(eventName) as eventName by userIdentity.arn userIdentity.type user | `security_content_ctime(firstTime)`  | `security_content_ctime(lastTime)` | `detect_api_activity_from_users_without_mfa_filter`

[ESCU - Detect ARP Poisoning - Rule]
action.escu = 0
action.escu.enabled = 1
description = By enabling Dynamic ARP Inspection as a Layer 2 Security measure on the organization's network devices, we will be able to detect ARP Poisoning attacks in the Infrastructure.
action.escu.mappings = {"cis20": ["CIS 1", "CIS 11"], "kill_chain_phases": ["Reconnaissance", "Delivery", "Actions on Objectives"], "mitre_attack": ["T1200", "T1498", "T1557"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = []
action.escu.eli5 = By enabling Dynamic ARP Inspection as a Layer 2 Security measure on the organization's network devices, we will be able to detect ARP Poisoning attacks in the Infrastructure.
action.escu.how_to_implement = This search uses a standard SPL query on logs from Cisco Network devices. The network devices must be configured with DHCP Snooping (see https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960x/software/15-0_2_EX/security/configuration_guide/b_sec_152ex_2960-x_cg/b_sec_152ex_2960-x_cg_chapter_01101.html) and Dynamic ARP Inspection (see https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960x/software/15-2_2_e/security/configuration_guide/b_sec_1522e_2960x_cg/b_sec_1522e_2960x_cg_chapter_01111.html) and log with a severity level of minimum "5 - notification". The search also requires that the Cisco Networks Add-on for Splunk (https://splunkbase.splunk.com/app/1467) is used to parse the logs from the Cisco network devices.
action.escu.known_false_positives = This search might be prone to high false positives if DHCP Snooping or ARP inspection has been incorrectly configured, or if a device normally sends many ARP packets (unlikely).
action.escu.creation_date = 2020-08-11
action.escu.modification_date = 2020-08-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect ARP Poisoning - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Router and Infrastructure Security"]
cron_schedule = 59 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect ARP Poisoning - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src_interface', 'firstTime', 'lastTime', 'count']
action.notable.param.rule_description = ARP Poisoning has been detected on interface $src_interface$ on host $orig_host$. This may be an indication of a MITM attack.
action.notable.param.rule_title = ARP Poisoning Detected on $orig_host$
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cisco_networks` facility="PM" mnemonic="ERR_DISABLE" disable_cause="arp-inspection" | eval src_interface=src_int_prefix_long+src_int_suffix | stats min(_time) AS firstTime max(_time) AS lastTime count BY host src_interface | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| `detect_arp_poisoning_filter`

[ESCU - Detect AWS API Activities From Unapproved Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for successful CloudTrail activity by user accounts that are not listed in the identity table or `aws_service_accounts.csv`. It returns event names and count, as well as the first and last time a specific user or service is detected, grouped by users.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC", "ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for successful CloudTrail activity by user accounts that are not listed in the identity table or `aws_service_accounts.csv`. It returns event names and count, as well as the first and last time a specific user or service is detected, grouped by users.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You must also populate the `identity_lookup_expanded` lookup shipped with the Asset and Identity framework to be able to look up users in your identity table in Enterprise Security (ES). Leverage the support search called "Create a list of approved AWS service accounts": run it once every 30 days to create and validate a list of service accounts.\
This search produces fields (`eventName`,`firstTime`,`lastTime`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** First Time, **Field:** firstTime\
1. \
1. **Label:** Last Time, **Field:** lastTime\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It's likely that you'll find activity detected by users/service accounts that are not listed in the `identity_lookup_expanded` or ` aws_service_accounts.csv` file. If the user is a legitimate service account, update the `aws_service_accounts.csv` table with that entry.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS API Activities From Unapproved Accounts - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS API Activities From Unapproved Accounts - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for successful CloudTrail activity by user accounts that are not listed in the identity table or `aws_service_accounts.csv`. It returns event names and count, as well as the first and last time a specific user or service is detected, grouped by users.
action.notable.param.rule_title = Detect AWS API Activities From Unapproved Accounts
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` errorCode=success | rename userName as identity | search NOT [| inputlookup identity_lookup_expanded | fields identity] | search NOT [| inputlookup aws_service_accounts | fields identity] | rename identity as user | stats count min(_time) as firstTime max(_time) as lastTime values(eventName) as eventName by user | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `detect_aws_api_activities_from_unapproved_accounts_filter`

[ESCU - Detect AWS Console Login by User from New City - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-04-30
action.escu.modification_date = 2018-04-30
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New City - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS Console Login by User from New City - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.notable.param.rule_title = Detect AWS Console Login by User from New City
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user City | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New City","Previously Seen City") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New City" AND UserData="Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `security_content_ctime(earliestseen)` | table user City userStatus firstTime lastTime earliestseen | `detect_aws_console_login_by_user_from_new_city_filter`

[ESCU - Detect AWS Console Login by User from New Country - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-04-30
action.escu.modification_date = 2018-04-30
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New Country - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS Console Login by User from New Country - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.notable.param.rule_title = Detect AWS Console Login by User from New Country
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user Country | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New Country","Previously Seen Country") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New Country" AND UserData="Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`security_content_ctime(earliestseen)` | table user Country userStatus firstTime lastTime earliestseen | `detect_aws_console_login_by_user_from_new_country_filter`

[ESCU - Detect AWS Console Login by User from New Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-04-30
action.escu.modification_date = 2018-04-30
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New Region - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS Console Login by User from New Region - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.notable.param.rule_title = Detect AWS Console Login by User from New Region
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user Region | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New Region","Previously Seen Region") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New Region" AND UserData="Old User" | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `security_content_ctime(earliestseen)` | table user Region userStatus firstTime lastTime earliestseen | `detect_aws_console_login_by_user_from_new_region_filter`

[ESCU - Detect Activity Related to Pass the Hash Attacks - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific authentication events from the Windows Security Event logs to detect potential attempts at using the Pass-the-Hash technique.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1550.002"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for specific authentication events from the Windows Security Event logs to detect potential attempts at using the Pass-the-Hash technique.
action.escu.how_to_implement = To successfully implement this search, you must ingest your Windows Security Event logs and leverage the latest TA for Windows.
action.escu.known_false_positives = Legitimate logon activity by authorized NTLM systems may be detected by this search. Please investigate as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Activity Related to Pass the Hash Attacks - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Activity Related to Pass the Hash Attacks - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for specific authentication events from the Windows Security Event logs to detect potential attempts at using the Pass-the-Hash technique.
action.notable.param.rule_title = Detect Activity Related to Pass the Hash Attacks
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `wineventlog_security` EventCode=4624 (Logon_Type=3 LogonProcessName=NtLmSsp WorkstationName=WORKSTATION NOT AccountName="ANONYMOUS LOGON") OR (EventCode=4624 Logon_Type=9 LogonProcessName=seclogo) | stats count min(_time) as firstTime max(_time) as lastTime by EventCode, Logon_Type, WorkstationName, user, dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_activity_related_to_pass_the_hash_attacks_filter` 

[ESCU - Detect Credential Dumping through LSASS access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for reading lsass memory consistent with credential dumping.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.001"], "nist": ["PR.IP", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for reading lsass memory consistent with credential dumping.
action.escu.how_to_implement = This search needs Sysmon Logs and a sysmon configuration, which includes EventCode 10 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = The activity may be legitimate. Other tools can access lsass for legitimate reasons, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.
action.escu.creation_date = 2019-12-03
action.escu.modification_date = 2019-12-03
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Credential Dumping through LSASS access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Credential Dumping through LSASS access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for reading lsass memory consistent with credential dumping.
action.notable.param.rule_title = Detect Credential Dumping through LSASS access
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `sysmon` EventCode=10 TargetImage=*lsass.exe (GrantedAccess=0x1010 OR GrantedAccess=0x1410) | stats count min(_time) as firstTime max(_time) as lastTime by Computer, SourceImage, SourceProcessId, TargetImage, TargetProcessId, EventCode, GrantedAccess | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_credential_dumping_through_lsass_access_filter` 

[ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DNS requests for phishing domains that are leveraging EvilGinx tools to mimic websites.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 7"], "kill_chain_phases": ["Delivery", "Command and Control"], "mitre_attack": ["T1566.003"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search looks for DNS requests for phishing domains that are leveraging EvilGinx tools to mimic websites.
action.escu.how_to_implement = You need to ingest data from your DNS logs in the Network_Resolution datamodel. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You will have to add legitimate domain names to the `legit_domains.csv` file shipped with the app. \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called `Lets Encrypt Domain Investigate` can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook link:`https://my.phantom.us/4.2/playbook/lets-encrypt-domain-investigate/`).\

action.escu.known_false_positives = If a known good domain is not listed in the legit_domains.csv file, then the search could give you false postives. Please update that lookup file to filter out DNS requests to legitimate domains.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Common Phishing Frameworks"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search looks for DNS requests for phishing domains that are leveraging EvilGinx tools to mimic websites.
action.notable.param.rule_title = Detect DNS requests to Phishing Sites leveraging EvilGinx2
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(DNS.answer) as answer from datamodel=Network_Resolution.DNS by DNS.dest DNS.src DNS.query host | `drop_dm_object_name(DNS)`| rex field=query ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | stats count values(query) as query by domain dest src answer| search `evilginx_phishlets_amazon` OR `evilginx_phishlets_facebook` OR `evilginx_phishlets_github` OR `evilginx_phishlets_0365` OR `evilginx_phishlets_outlook` OR `evilginx_phishlets_aws` OR `evilginx_phishlets_google` | search NOT [ inputlookup legit_domains.csv | fields domain]| join domain type=outer [| tstats count `security_content_summariesonly` values(Web.url) as url from datamodel=Web.Web by Web.dest Web.site | rename "Web.*" as * | rex field=site ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | table dest domain url] | table count src dest query answer domain url | `detect_dns_requests_to_phishing_sites_leveraging_evilginx2_filter`

[ESCU - Detect Excessive Account Lockouts From Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search identifies endpoints that have caused a relatively high number of account lockouts in a short period.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1078.003"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search identifies endpoints that have caused a relatively high number of account lockouts in a short period.
action.escu.how_to_implement = You must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment. \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called "Excessive Account Lockouts Enrichment and Response" can be configured to run when any results are found by this detection search. The Playbook executes the Contextual and Investigative searches in this Story, conducts additional information gathering on Windows endpoints, and takes a response action to shut down the affected endpoint. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook Link:`https://my.phantom.us/4.1/playbook/excessive-account-lockouts-enrichment-and-response/`).\

action.escu.known_false_positives = It's possible that a widely used system, such as a kiosk, could cause a large number of account lockouts.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Excessive Account Lockouts From Endpoint - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Excessive Account Lockouts From Endpoint - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search identifies endpoints that have caused a relatively high number of account lockouts in a short period.
action.notable.param.rule_title = Detect Excessive Account Lockouts From Endpoint
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.dest All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search count > 5 | `detect_excessive_account_lockouts_from_endpoint_filter`

[ESCU - Detect Excessive User Account Lockouts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects user accounts that have been locked out a relatively high number of times in a short period.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1078.003"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search detects user accounts that have been locked out a relatively high number of times in a short period.
action.escu.how_to_implement = ou must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment.
action.escu.known_false_positives = It is possible that a legitimate user is experiencing an issue causing multiple account login failures leading to lockouts.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Excessive User Account Lockouts - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Excessive User Account Lockouts - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search detects user accounts that have been locked out a relatively high number of times in a short period.
action.notable.param.rule_title = Detect Excessive User Account Lockouts
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.user All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search count > 5 | `detect_excessive_user_account_lockouts_filter`

[ESCU - Detect F5 TMUI RCE CVE-2020-5902 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects remote code exploit attempts on F5 BIG-IP, BIG-IQ, and Traffix SDC devices
action.escu.mappings = {"cis20": ["CIS 8", "CIS 11"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["T1190"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects remote code exploit attempts on F5 BIG-IP, BIG-IQ, and Traffix SDC devices
action.escu.how_to_implement = To consistently detect exploit attempts on F5 devices using the vulnerabilities contained within CVE-2020-5902 it is recommended to ingest logs via syslog.  As many BIG-IP devices will have SSL enabled on their management interfaces, detections via wire data may not pick anything up unless you are decrypting SSL traffic in order to inspect it.  I am using a regex string from a Cloudflare mitigation technique to try and always catch the offending string (..;), along with the other exploit of using (hsqldb;).
action.escu.known_false_positives = unknown
action.escu.creation_date = 2020-08-02
action.escu.modification_date = 2020-08-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect F5 TMUI RCE CVE-2020-5902 - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["F5 TMUI RCE CVE-2020-5902"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect F5 TMUI RCE CVE-2020-5902 - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search detects remote code exploit attempts on F5 BIG-IP, BIG-IQ, and Traffix SDC devices
action.notable.param.rule_title = Detect F5 TMUI RCE CVE-2020-5902
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `f5_bigip_rogue` | regex _raw="(hsqldb;|.*\\.\\.;.*)" | search `detect_f5_tmui_rce_cve_2020_5902_filter`

[ESCU - Detect GCP Storage access from a new IP - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks at GCP Storage bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed a GCP Storage bucket.
action.escu.mappings = {"cis20": ["CIS 13", "CIS 14"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks at GCP Storage bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed a GCP Storage bucket.
action.escu.how_to_implement = This search relies on the Splunk Add-on for Google Cloud Platform, setting up a Cloud Pub/Sub input, along with the relevant GCP PubSub topics and logging sink to capture GCP Storage Bucket events (https://cloud.google.com/logging/docs/routing/overview). In order to capture public GCP Storage Bucket access logs, you must also enable storage bucket logging to your PubSub Topic as per https://cloud.google.com/storage/docs/access-logs.  These logs are deposited into the nominated Storage Bucket on an hourly basis and typically show up by 15 minutes past the hour.  It is recommended to configure any saved searches or correlation searches in Enterprise Security to run on an hourly basis at 30 minutes past the hour (cron definition of 30 * * * *).  A lookup table (previously_seen_gcp_storage_access_from_remote_ip.csv) stores the previously seen access requests, and is used by this search to determine any newly seen IP addresses accessing the Storage Buckets.
action.escu.known_false_positives = GCP Storage buckets can be accessed from any IP (if the ACLs are open to allow it), as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past two hours.
action.escu.creation_date = 2020-08-10
action.escu.modification_date = 2020-08-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect GCP Storage access from a new IP - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious GCP Storage Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect GCP Storage access from a new IP - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks at GCP Storage bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed a GCP Storage bucket.
action.notable.param.rule_title = Detect GCP Storage access from a new IP
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` | multikv | rename sc_status_ as status | rename cs_object_ as bucket_name | rename c_ip_ as remote_ip | rename cs_uri_ as request_uri | rename cs_method_ as operation | search status="\"200\"" | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip operation request_uri | table firstTime, lastTime, bucket_name, remote_ip, operation, request_uri | inputlookup append=t previously_seen_gcp_storage_access_from_remote_ip.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip operation request_uri | outputlookup previously_seen_gcp_storage_access_from_remote_ip.csv | eval newIP=if(firstTime >= relative_time(now(),"-70m@m"), 1, 0) | where newIP=1 | eval first_time=strftime(firstTime,"%m/%d/%y %H:%M:%S") | eval last_time=strftime(lastTime,"%m/%d/%y %H:%M:%S") | table  first_time last_time bucket_name remote_ip operation request_uri | `detect_gcp_storage_access_from_a_new_ip_filter`

[ESCU - Detect Large Outbound ICMP Packets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for outbound ICMP packets with a packet size larger than 1,000 bytes. Various threat actors have been known to use ICMP as a command and control channel for their attack infrastructure. Large ICMP packets from an endpoint to a remote host may be indicative of this activity.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1095"], "nist": ["DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for outbound ICMP packets with a packet size larger than 1,000 bytes. Various threat actors have been known to use ICMP as a command and control channel for their attack infrastructure. Large ICMP packets from an endpoint to a remote host may be indicative of this activity.
action.escu.how_to_implement = In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have a good understanding of how your network segments are designed and that you are able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in the `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model
action.escu.known_false_positives = ICMP packets are used in a variety of ways to help troubleshoot networking issues and ensure the proper flow of traffic. As such, it is possible that a large ICMP packet could be perfectly legitimate. If large ICMP packets are associated with command and control traffic, there will typically be a large number of these packets observed over time. If the search is providing a large number of false positives, you can modify the search to adjust the byte threshold or whitelist specific IP addresses, as necessary.
action.escu.creation_date = 2018-06-01
action.escu.modification_date = 2018-06-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Large Outbound ICMP Packets - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Large Outbound ICMP Packets - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for outbound ICMP packets with a packet size larger than 1,000 bytes. Various threat actors have been known to use ICMP as a command and control channel for their attack infrastructure. Large ICMP packets from an endpoint to a remote host may be indicative of this activity.
action.notable.param.rule_title = Detect Large Outbound ICMP Packets
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as firstTime latest(_time) as lastTime values(All_Traffic.action) values(All_Traffic.bytes) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.protocol=icmp OR All_Traffic.transport=icmp) All_Traffic.bytes > 1000 by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | `detect_large_outbound_icmp_packets_filter`

[ESCU - Detect Long DNS TXT Record Response - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect attempts to use DNS tunneling, by calculating the length of responses to DNS TXT queries. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting unusually large volumes of DNS traffic.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12", "CIS 13"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1071.004"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search is used to detect attempts to use DNS tunneling, by calculating the length of responses to DNS TXT queries. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting unusually large volumes of DNS traffic.
action.escu.how_to_implement = To successfully implement this search you need to ingest data from your DNS logs, or monitor DNS traffic using Stream, Bro or something similar. Specifically, this query requires that the DNS data model is populated with information regarding the DNS record type that is being returned as well as the data in the answer section of the protocol.
action.escu.known_false_positives = It's possible that legitimate TXT record responses can be long enough to trigger this search. You can modify the packet threshold for this search to help mitigate false positives.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Long DNS TXT Record Response - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious DNS Traffic", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Long DNS TXT Record Response - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search is used to detect attempts to use DNS tunneling, by calculating the length of responses to DNS TXT queries. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting unusually large volumes of DNS traffic.
action.notable.param.rule_title = Detect Long DNS TXT Record Response
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Resolution where DNS.message_type=response AND DNS.record_type=TXT by DNS.src DNS.dest DNS.answer DNS.record_type |  `drop_dm_object_name("DNS")` | eval anslen=len(answer) | search anslen>100 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename src as "Source IP", dest as "Destination IP", answer as "DNS Answer" anslen as "Answer Length" record_type as "DNS Record Type" firstTime as "First Time" lastTime as "Last Time" count as Count | table "Source IP" "Destination IP" "DNS Answer" "DNS Record Type"  "Answer Length" Count "First Time" "Last Time" | `detect_long_dns_txt_record_response_filter`

[ESCU - Detect Mimikatz Using Loaded Images - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for reading loaded Images unique to credential dumping with Mimikatz.
action.escu.mappings = {"cis20": ["CIS 6", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.001"], "nist": ["DE.AE", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for reading loaded Images unique to credential dumping with Mimikatz.
action.escu.how_to_implement = This search needs Sysmon Logs and a sysmon configuration, which includes EventCode 7 with powershell.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Other tools can import the same DLLs. These tools should be part of a whtelist.
action.escu.creation_date = 2019-12-03
action.escu.modification_date = 2019-12-03
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Mimikatz Using Loaded Images - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Mimikatz Using Loaded Images - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for reading loaded Images unique to credential dumping with Mimikatz.
action.notable.param.rule_title = Detect Mimikatz Using Loaded Images
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `sysmon` EventCode=7 | stats values(ImageLoaded) as ImageLoaded values(ProcessId) as ProcessId by Computer, Image | search ImageLoaded=*WinSCard.dll ImageLoaded=*cryptdll.dll ImageLoaded=*hid.dll ImageLoaded=*samlib.dll ImageLoaded=*vaultcli.dll | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_mimikatz_using_loaded_images_filter`

[ESCU - Detect Mimikatz Via PowerShell And EventCode 4703 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell requesting privileges consistent with credential dumping.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.001"], "nist": ["PR.IP", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for PowerShell requesting privileges consistent with credential dumping.
action.escu.how_to_implement = You must be ingesting Windows Security logs. You must also enable the account change auditing here: http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata. Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.
action.escu.known_false_positives = The activity may be legitimate. PowerShell is often used by administrators to perform various tasks, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.
action.escu.creation_date = 2019-02-27
action.escu.modification_date = 2019-02-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Mimikatz Via PowerShell And EventCode 4703 - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Mimikatz Via PowerShell And EventCode 4703 - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for PowerShell requesting privileges consistent with credential dumping.
action.notable.param.rule_title = Detect Mimikatz Via PowerShell And EventCode 4703
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `wineventlog_security` signature_id=4703 Process_Name=*powershell.exe | rex field=Message "Enabled Privileges:\s+(?<privs>\w+)\s+Disabled Privileges:" | where privs="SeDebugPrivilege" | stats count min(_time) as firstTime max(_time) as lastTime by dest, Process_Name, privs, Process_ID, Message | rename privs as "Enabled Privilege" | rename Process_Name as process |  `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_mimikatz_via_powershell_and_eventcode_4703_filter`

[ESCU - Detect New Local Admin account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for newly created accounts that have been elevated to local administrators.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "mitre_attack": ["T1136.001"], "nist": ["PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for newly created accounts that have been elevated to local administrators.
action.escu.how_to_implement = none
action.escu.known_false_positives = The activity may be legitimate. For this reason, it's best to verify the account with an administrator and ask whether there was a valid service request for the account creation. If your local administrator group name is not "Administrators", this search may generate an excessive number of false positives
action.escu.creation_date = 2020-07-08
action.escu.modification_date = 2020-07-08
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect New Local Admin account - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect New Local Admin account - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for newly created accounts that have been elevated to local administrators.
action.notable.param.rule_title = Detect New Local Admin account
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `wineventlog_security` EventID=4720 OR (EventID=4732 Group_Name=Administrators) | transaction MemberSid connected=false maxspan=180m | rename MemberSid as user | stats count min(_time) as firstTime max(_time) as lastTime by user dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_new_local_admin_account_filter`

[ESCU - Detect New Login Attempts to Routers - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.
action.escu.how_to_implement = To successfully implement this search, you must ensure the network router devices are categorized as "router" in the Assets and identity table. You must also populate the Authentication data model with logs related to users authenticating to routing infrastructure.
action.escu.known_false_positives = Legitimate router connections may appear as new connections
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect New Login Attempts to Routers - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Router and Infrastructure Security"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect New Login Attempts to Routers - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.
action.notable.param.rule_title = Detect New Login Attempts to Routers
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as earliest latest(_time) as latest from datamodel=Authentication where Authentication.dest_category=router by Authentication.dest Authentication.user| eval isOutlier=if(earliest >= relative_time(now(), "-30d@d"), 1, 0) | where isOutlier=1| `security_content_ctime(earliest)`| `security_content_ctime(latest)` | `drop_dm_object_name("Authentication")` | `detect_new_login_attempts_to_routers_filter`

[ESCU - Detect New Open GCP Storage Buckets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for GCP PubSub events where a user has created an open/public GCP Storage bucket.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for GCP PubSub events where a user has created an open/public GCP Storage bucket.
action.escu.how_to_implement = This search relies on the Splunk Add-on for Google Cloud Platform, setting up a Cloud Pub/Sub input, along with the relevant GCP PubSub topics and logging sink to capture GCP Storage Bucket events (https://cloud.google.com/logging/docs/routing/overview).
action.escu.known_false_positives = While this search has no known false positives, it is possible that a GCP admin has legitimately created a public bucket for a specific purpose. That said, GCP strongly advises against granting full control to the "allUsers" group.
action.escu.creation_date = 2020-08-05
action.escu.modification_date = 2020-08-05
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect New Open GCP Storage Buckets - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious GCP Storage Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect New Open GCP Storage Buckets - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'src']
action.notable.param.rule_description = This search looks for GCP PubSub events where a user has created an open/public GCP Storage bucket.
action.notable.param.rule_title = Detect New Open GCP Storage Buckets
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` data.resource.type=gcs_bucket data.protoPayload.methodName=storage.setIamPermissions | spath output=action path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.action | spath output=user path=data.protoPayload.authenticationInfo.principalEmail | spath output=location path=data.protoPayload.resourceLocation.currentLocations{} | spath output=src path=data.protoPayload.requestMetadata.callerIp | spath output=bucketName path=data.protoPayload.resourceName | spath output=role path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.role | spath output=member path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.member | search (member=allUsers AND action=ADD) | table  _time, bucketName, src, user, location, action, role, member | search `detect_new_open_gcp_storage_buckets_filter`

[ESCU - Detect New Open S3 buckets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), and then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.
action.escu.creation_date = 2018-07-25
action.escu.modification_date = 2018-07-25
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect New Open S3 buckets - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect New Open S3 buckets - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
action.notable.param.rule_title = Detect New Open S3 buckets
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` AllUsers eventName=PutBucketAcl | spath output=userIdentityArn path=userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | spath output=aclControlList path=requestParameters.AccessControlPolicy.AccessControlList | spath input=aclControlList output=grantee path=Grant{} | mvexpand grantee | spath input=grantee | search Grantee.URI=*AllUsers | rename userIdentityArn as user| table _time, src,awsRegion Permission, Grantee.URI, bucketName, user | `detect_new_open_s3_buckets_filter`

[ESCU - Detect Oulook exe writing a  zip file - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for execution of process `outlook.exe` where the process is writing a `.zip` file to the disk.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["T1566.001"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for execution of process `outlook.exe` where the process is writing a `.zip` file to the disk.
action.escu.how_to_implement = You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.
action.escu.known_false_positives = It is not uncommon for outlook to write legitimate zip files to the disk.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Oulook exe writing a  zip file - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Phishing Payloads"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Oulook exe writing a  zip file - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for execution of process `outlook.exe` where the process is writing a `.zip` file to the disk.
action.notable.param.rule_title = Detect Oulook exe writing a  zip file
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly`  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name=outlook.exe OR Processes.process_name=explorer.exe by _time span=5m Processes.parent_process_id Processes.process_id Processes.dest Processes.process_name Processes.parent_process_name Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename process_id as malicious_id| rename parent_process_id as outlook_id| join malicious_id type=inner[| tstats `security_content_summariesonly` count values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name  FROM datamodel=Endpoint.Filesystem where (Filesystem.file_path=*zip*   OR Filesystem.file_name=*.lnk ) AND (Filesystem.file_path=C:\\Users* OR Filesystem.file_path=*Local\\Temp*) by  _time span=5m Filesystem.process_id Filesystem.file_hash Filesystem.dest  | `drop_dm_object_name(Filesystem)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename process_id as malicious_id| fields malicious_id outlook_id dest file_path file_name file_hash count file_id] | table firstTime lastTime user malicious_id outlook_id process_name parent_process_name file_name  file_path | where file_name != "" | `detect_oulook_exe_writing_a__zip_file_filter` 

[ESCU - Detect Outbound SMB Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for outbound SMB connections made by hosts within your network to the Internet. SMB traffic is used for Windows file-sharing activity. One of the techniques often used by attackers involves retrieving the credential hash using an SMB request made to a compromised server controlled by the threat actor.
action.escu.mappings = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "mitre_attack": ["T1071.002"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for outbound SMB connections made by hosts within your network to the Internet. SMB traffic is used for Windows file-sharing activity. One of the techniques often used by attackers involves retrieving the credential hash using an SMB request made to a compromised server controlled by the threat actor.
action.escu.how_to_implement = In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have good understanding of how your network segments are designed, and be able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model
action.escu.known_false_positives = It is likely that the outbound Server Message Block (SMB) traffic is legitimate, if the company's internal networks are not well-defined in the Assets and Identity Framework. Categorize the internal CIDR blocks as `internal` in the lookup file to avoid creating notable events for traffic destined to those CIDR blocks. Any other network connection that is going out to the Internet should be investigated and blocked. Best practices suggest preventing external communications of all SMB versions and related protocols at the network boundary.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Outbound SMB Traffic - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Hidden Cobra Malware", "DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Outbound SMB Traffic - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for outbound SMB connections made by hosts within your network to the Internet. SMB traffic is used for Windows file-sharing activity. One of the techniques often used by attackers involves retrieving the credential hash using an SMB request made to a compromised server controlled by the threat actor.
action.notable.param.rule_title = Detect Outbound SMB Traffic
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as earliest latest(_time) as latest values(All_Traffic.action) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb) by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | `security_content_ctime(earliest)`| `security_content_ctime(latest)` | `detect_outbound_smb_traffic_filter` 

[ESCU - Detect Path Interception By Creation Of program exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = The detection Detect Path Interception By Creation Of program exe is detecting the abuse of unquoted service paths, which is a popular technique for privilege escalation. 
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1574.009"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The detection Detect Path Interception By Creation Of program exe is detecting the abuse of unquoted service paths, which is a popular technique for privilege escalation. 
action.escu.how_to_implement = none
action.escu.known_false_positives = unknown
action.escu.creation_date = 2020-07-03
action.escu.modification_date = 2020-07-03
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Path Interception By Creation Of program exe - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Path Interception By Creation Of program exe - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The detection Detect Path Interception By Creation Of program exe is detecting the abuse of unquoted service paths, which is a popular technique for privilege escalation. 
action.notable.param.rule_title = Detect Path Interception By Creation Of program exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name=services.exe by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | rex field=process "^.*\\\\(?<service_process>.*\.(?:exe|bat|com|ps1))" | eval process_name = lower(process_name) | eval service_process = lower(service_process)| where process_name != service_process | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_path_interception_by_creation_of_program_exe_filter`

[ESCU - Detect Prohibited Applications Spawning cmd exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and that does not typically launch cmd.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["T1059.003"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and that does not typically launch cmd.exe.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts and populates the Endpoint data model with the resultant dataset. This search includes a lookup file, `prohibited_apps_launching_cmd.csv`, that contains a list of processes that should not be spawning cmd.exe. You can modify this lookup to better suit your environment.
action.escu.known_false_positives = There are circumstances where an application may legitimately execute and interact with the Windows command-line interface. Investigate and modify the lookup file, as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Prohibited Applications Spawning cmd exe - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Suspicious Zoom Child Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Prohibited Applications Spawning cmd exe - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and that does not typically launch cmd.exe.
action.notable.param.rule_title = Detect Prohibited Applications Spawning cmd exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe by Processes.parent_process_name Processes.process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |search [`prohibited_apps_launching_cmd`] | `detect_prohibited_applications_spawning_cmd_exe_filter`

[ESCU - Detect PsExec With accepteula Flag - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for events where `PsExec.exe` is run with the `accepteula` flag in the command line. PsExec is a built-in Windows utility that enables you to execute processes on other systems. It is fully interactive for console applications. This tool is widely used for launching interactive command prompts on remote systems. Threat actors leverage this extensively for executing code on compromised systems. If an attacker is running PsExec for the first time, they will be prompted to accept the end-user license agreement (EULA), which can be passed as the argument `accepteula` within the command line.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1059.003", "T1059.001"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for events where `PsExec.exe` is run with the `accepteula` flag in the command line. PsExec is a built-in Windows utility that enables you to execute processes on other systems. It is fully interactive for console applications. This tool is widely used for launching interactive command prompts on remote systems. Threat actors leverage this extensively for executing code on compromised systems. If an attacker is running PsExec for the first time, they will be prompted to accept the end-user license agreement (EULA), which can be passed as the argument `accepteula` within the command line.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators can leverage PsExec for accessing remote systems and might pass `accepteula` as an argument if they are running this tool for the first time. However, it is not likely that you'd see multiple occurrences of this event on a machine
action.escu.creation_date = 2019-02-26
action.escu.modification_date = 2019-02-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect PsExec With accepteula Flag - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware", "DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect PsExec With accepteula Flag - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for events where `PsExec.exe` is run with the `accepteula` flag in the command line. PsExec is a built-in Windows utility that enables you to execute processes on other systems. It is fully interactive for console applications. This tool is widely used for launching interactive command prompts on remote systems. Threat actors leverage this extensively for executing code on compromised systems. If an attacker is running PsExec for the first time, they will be prompted to accept the end-user license agreement (EULA), which can be passed as the argument `accepteula` within the command line.
action.notable.param.rule_title = Detect PsExec With accepteula Flag
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = PsExec.exe Processes.process = "*accepteula*" by Processes.process_name Processes.dest  Processes.parent_process_name | `drop_dm_object_name(Processes)`| `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_psexec_with_accepteula_flag_filter`

[ESCU - Detect Rare Executables - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will return a table of rare processes, the names of the systems running them, and the users who initiated each process.
action.escu.mappings = {"cis20": ["CIS 2", "CIS 8"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "nist": ["ID.AM", "PR.PT", "PR.DS", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search will return a table of rare processes, the names of the systems running them, and the users who initiated each process.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts and populating the endpoint data model with the resultant dataset. The macro `filter_rare_process_whitelist` searches two lookup files to whitelist your processes.  These consist of `rare_process_whitelist_default.csv` and `rare_process_whitelist_local.csv`. To add your own processes to the whitelist, add them to `rare_process_whitelist_local.csv`. If you wish to remove an entry from the default lookup file, you will have to modify the macro itself to set the whitelist value for that process to false. You can modify the limit parameter and search scheduling to better suit your environment.
action.escu.known_false_positives = Some legitimate processes may be only rarely executed in your environment. As these are identified, update `rare_process_whitelist_local.csv` to filter them out of your search results.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Rare Executables - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Rare Executables - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search will return a table of rare processes, the names of the systems running them, and the users who initiated each process.
action.notable.param.rule_title = Detect Rare Executables
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.dest) as dest values(Processes.user) as user min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.process_name  | rename Processes.process_name as process | rex field=user "(?<user_domain>.*)\\\\(?<user_name>.*)" | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search [| tstats count from datamodel=Endpoint.Processes by Processes.process_name | rare Processes.process_name limit=30 | rename Processes.process_name as process| `filter_rare_process_whitelist`| table process ] | `detect_rare_executables_filter` 

[ESCU - Detect Rogue DHCP Server - Rule]
action.escu = 0
action.escu.enabled = 1
description = By enabling DHCP Snooping as a Layer 2 Security measure on the organization's network devices, we will be able to detect unauthorized DHCP servers handing out DHCP leases to devices on the network (Man in the Middle attack).
action.escu.mappings = {"cis20": ["CIS 1", "CIS 11"], "kill_chain_phases": ["Reconnaissance", "Delivery", "Actions on Objectives"], "mitre_attack": ["T1200", "T1498", "T1557"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = []
action.escu.eli5 = By enabling DHCP Snooping as a Layer 2 Security measure on the organization's network devices, we will be able to detect unauthorized DHCP servers handing out DHCP leases to devices on the network (Man in the Middle attack).
action.escu.how_to_implement = This search uses a standard SPL query on logs from Cisco Network devices. The network devices must be configured with DHCP Snooping enabled (see https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960x/software/15-0_2_EX/security/configuration_guide/b_sec_152ex_2960-x_cg/b_sec_152ex_2960-x_cg_chapter_01101.html) and log with a severity level of minimum "5 - notification". The search also requires that the Cisco Networks Add-on for Splunk (https://splunkbase.splunk.com/app/1467) is used to parse the logs from the Cisco network devices.
action.escu.known_false_positives = This search might be prone to high false positives if DHCP Snooping has been incorrectly configured or in the unlikely event that the DHCP server has been moved to another network interface.
action.escu.creation_date = 2020-08-11
action.escu.modification_date = 2020-08-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Rogue DHCP Server - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Router and Infrastructure Security"]
cron_schedule = 59 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Rogue DHCP Server - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src_mac', 'firstTime', 'lastTime', 'count', 'message_type']
action.notable.param.rule_description = DHCP Snooping has detected a Rogue DHCP Server on $orig_host$ from $src_mac$. This may be an indication of a MITM attack.
action.notable.param.rule_title = Rogue DHCP Server Detected on $orig_host$
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cisco_networks` facility="DHCP_SNOOPING" mnemonic="DHCP_SNOOPING_UNTRUSTED_PORT" | stats min(_time) AS firstTime max(_time) AS lastTime count values(message_type) AS message_type values(src_mac) AS src_mac BY host | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| `detect_rogue_dhcp_server_filter`

[ESCU - Detect S3 access from a new IP - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks at S3 bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed an S3 bucket.
action.escu.mappings = {"cis20": ["CIS 13", "CIS 14"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks at S3 bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed an S3 bucket.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access logs' inputs. This search works best when you run the "Previously Seen S3 Bucket Access by Remote IP" support search once to create a history of previously seen remote IPs and bucket names.
action.escu.known_false_positives = S3 buckets can be accessed from any IP, as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past hour
action.escu.creation_date = 2018-06-28
action.escu.modification_date = 2018-06-28
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect S3 access from a new IP - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect S3 access from a new IP - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks at S3 bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed an S3 bucket.
action.notable.param.rule_title = Detect S3 access from a new IP
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_s3_accesslogs` http_status=200  [search `aws_s3_accesslogs` http_status=200 | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip | inputlookup append=t previously_seen_S3_access_from_remote_ip.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip.csv | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | table bucket_name remote_ip]| iplocation remote_ip |rename remote_ip as src_ip | table _time bucket_name src_ip City Country operation request_uri | `detect_s3_access_from_a_new_ip_filter`

[ESCU - Detect Spike in AWS API Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes of API activity in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.data_models = []
action.escu.eli5 = This search will detect users creating spikes of API activity in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.\
This search produces fields (`eventName`,`numberOfApiCalls`,`uniqueApisCalled`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** Number of API Calls, **Field:** numberOfApiCalls\
1. \
1. **Label:** Unique API Calls, **Field:** uniqueApisCalled\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = 
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in AWS API Activity - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in AWS API Activity - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search will detect users creating spikes of API activity in your AWS environment.  It will also update the cache file that factors in the latest data.
action.notable.param.rule_title = Detect Spike in AWS API Activity
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventType=AwsApiCall [search `cloudtrail` eventType=AwsApiCall | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup api_call_by_user_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_aws_api_activity_filter`

[ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals
action.escu.mappings = {"cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.
action.escu.known_false_positives = None
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Security Hub Alerts"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals
action.notable.param.rule_title = Detect Spike in AWS Security Hub Alerts for EC2 Instance
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_securityhub_firehose` "findings{}.Resources{}.Type"=AWSEC2Instance | rex field=findings{}.Resources{}.Id .*instance/(?<instance>.*) | rename instance as dest | bucket span=4h _time | stats count AS alerts by _time dest | eventstats avg(alerts) as total_launched_avg, stdev(alerts) as total_launched_stdev | eval threshold_value = 4 | eval isOutlier=if(alerts > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 | table _time dest alerts|`detect_spike_in_aws_security_hub_alerts_for_ec2_instance_filter`

[ESCU - Detect Spike in AWS Security Hub Alerts for User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for a spike in number of of AWS security Hub alerts for an AWS IAM User in 4 hours intervals.
action.escu.mappings = {"cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for a spike in number of of AWS security Hub alerts for an AWS IAM User in 4 hours intervals.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.
action.escu.known_false_positives = None
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in AWS Security Hub Alerts for User - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Security Hub Alerts"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in AWS Security Hub Alerts for User - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for a spike in number of of AWS security Hub alerts for an AWS IAM User in 4 hours intervals.
action.notable.param.rule_title = Detect Spike in AWS Security Hub Alerts for User
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_securityhub_firehose` "findings{}.Resources{}.Type"= AwsIamUser | rename findings{}.Resources{}.Id as user | bucket span=4h _time | stats count AS alerts by _time user | eventstats avg(alerts) as total_launched_avg, stdev(alerts) as total_launched_stdev | eval threshold_value = 2 | eval isOutlier=if(alerts > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 | table _time user alerts |`detect_spike_in_aws_security_hub_alerts_for_user_filter`

[ESCU - Detect Spike in Network ACL Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes in API activity related to network access-control lists (ACLs)in your AWS environment.
action.escu.mappings = {"cis20": ["CIS 12", "CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.data_models = []
action.escu.eli5 = This search will detect users creating spikes in API activity related to network access-control lists (ACLs)in your AWS environment.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Network ACL Activity by ARN" support search once to create a lookup file of previously seen Network ACL Activity. To add or remove API event names related to network ACLs, edit the macro `network_acl_events`.
action.escu.known_false_positives = The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Please modify this according the your environment.
action.escu.creation_date = 2018-05-21
action.escu.modification_date = 2018-05-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in Network ACL Activity - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in Network ACL Activity - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search will detect users creating spikes in API activity related to network access-control lists (ACLs)in your AWS environment.
action.notable.param.rule_title = Detect Spike in Network ACL Activity
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` `network_acl_events` [search `cloudtrail` `network_acl_events` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup network_acl_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_network_acl_activity_filter`

[ESCU - Detect Spike in S3 Bucket deletion - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects users creating spikes in API activity related to deletion of S3 buckets in your AWS environment. It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.data_models = []
action.escu.eli5 = This search detects users creating spikes in API activity related to deletion of S3 buckets in your AWS environment. It will also update the cache file that factors in the latest data.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of S3 Bucket deletion activity by ARN" support search once to create a baseline of previously seen S3 bucket-deletion activity.
action.escu.known_false_positives = Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.
action.escu.creation_date = 2018-11-27
action.escu.modification_date = 2018-11-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in S3 Bucket deletion - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in S3 Bucket deletion - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search detects users creating spikes in API activity related to deletion of S3 buckets in your AWS environment. It will also update the cache file that factors in the latest data.
action.notable.param.rule_title = Detect Spike in S3 Bucket deletion
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=DeleteBucket [search `cloudtrail` eventName=DeleteBucket | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup s3_deletion_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | stats values(bucketName) as bucketName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_s3_bucket_deletion_filter`

[ESCU - Detect Spike in Security Group Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes in API activity related to security groups in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.data_models = []
action.escu.eli5 = This search will detect users creating spikes in API activity related to security groups in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.This search works best when you run the "Baseline of Security Group Activity by ARN" support search once to create a history of previously seen Security Group Activity. To add or remove API event names for security groups, edit the macro `security_group_api_calls`.
action.escu.known_false_positives = Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.
action.escu.creation_date = 2018-04-18
action.escu.modification_date = 2018-04-18
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in Security Group Activity - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in Security Group Activity - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search will detect users creating spikes in API activity related to security groups in your AWS environment.  It will also update the cache file that factors in the latest data.
action.notable.param.rule_title = Detect Spike in Security Group Activity
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` `security_group_api_calls` [search `cloudtrail` `security_group_api_calls` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup security_group_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_security_group_activity_filter`

[ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "nist": ["DE.AE", "DE.CM", "PR.AC"]}
action.escu.data_models = []
action.escu.eli5 = This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your VPC Flow logs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the number of data points required to meet the definition of "spike." The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Blocked Outbound Connection" support search once to create a history of previously seen blocked outbound connections.
action.escu.known_false_positives = The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Additionally, false positives may result when AWS administrators roll out policies enforcing network blocks, causing sudden increases in the number of blocked outbound connections.
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Network ACL Activity", "Suspicious AWS Traffic", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.
action.notable.param.rule_title = Detect Spike in blocked Outbound Traffic from your AWS
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  [search  `cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  | stats count as numberOfBlockedConnections by src_ip | inputlookup baseline_blocked_outbound_connections append=t | fields - latestCount | stats values(*) as * by src_ip | rename numberOfBlockedConnections as latestCount | eval newAvgBlockedConnections=avgBlockedConnections + (latestCount-avgBlockedConnections)/720 | eval newStdevBlockedConnections=sqrt(((pow(stdevBlockedConnections, 2)*719 + (latestCount-newAvgBlockedConnections)*(latestCount-avgBlockedConnections))/720)) | eval avgBlockedConnections=coalesce(newAvgBlockedConnections, avgBlockedConnections), stdevBlockedConnections=coalesce(newStdevBlockedConnections, stdevBlockedConnections), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | eval dataPointThreshold = 5, deviationThreshold = 3 | eval isSpike=if((latestCount > avgBlockedConnections+deviationThreshold*stdevBlockedConnections) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | table src_ip] | stats values(dest_ip) as "Blocked Destination IPs", values(interface_id) as "resourceId" count as numberOfBlockedConnections, dc(dest_ip) as uniqueDestConnections by src_ip | `detect_spike_in_blocked_outbound_traffic_from_your_aws_filter`

[ESCU - Detect USB device insertion - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to detect hosts that generate Windows Event ID 4663 for successful attempts to write to or read from a removable storage and Event ID 4656 for failures, which occurs when a USB drive is plugged in. In this scenario we are querying the Change_Analysis data model to look for Windows Event ID 4656 or 4663 where the priority of the affected host is marked as high in the ES Assets and Identity Framework.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "nist": ["PR.PT", "PR.DS"]}
action.escu.data_models = ["Change_Analysis"]
action.escu.eli5 = The search is used to detect hosts that generate Windows Event ID 4663 for successful attempts to write to or read from a removable storage and Event ID 4656 for failures, which occurs when a USB drive is plugged in. In this scenario we are querying the Change_Analysis data model to look for Windows Event ID 4656 or 4663 where the priority of the affected host is marked as high in the ES Assets and Identity Framework.
action.escu.how_to_implement = To successfully implement this search, you must ingest Windows Security Event logs and track event code 4663 and 4656. Ensure that the field from the event logs is being mapped to the result_id field in the Change_Analysis data model. To minimize the alert volume, this search leverages the Assets and Identity framework to filter out events from those assets not marked high priority in the Enterprise Security Assets and Identity Framework.
action.escu.known_false_positives = Legitimate USB activity will also be detected. Please verify and investigate as appropriate.
action.escu.creation_date = 2017-11-27
action.escu.modification_date = 2017-11-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect USB device insertion - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Data Protection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect USB device insertion - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search is used to detect hosts that generate Windows Event ID 4663 for successful attempts to write to or read from a removable storage and Event ID 4656 for failures, which occurs when a USB drive is plugged in. In this scenario we are querying the Change_Analysis data model to look for Windows Event ID 4656 or 4663 where the priority of the affected host is marked as high in the ES Assets and Identity Framework.
action.notable.param.rule_title = Detect USB device insertion
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) AS earliest latest(_time) AS latest from datamodel=Change_Analysis where (nodename = All_Changes) All_Changes.result="Removable Storage device" (All_Changes.result_id=4663 OR All_Changes.result_id=4656) (All_Changes.src_priority=high) by All_Changes.dest | `drop_dm_object_name("All_Changes")`| `security_content_ctime(earliest)`| `security_content_ctime(latest)`  | `detect_usb_device_insertion_filter`

[ESCU - Detect Unauthorized Assets by MAC address - Rule]
action.escu = 0
action.escu.enabled = 1
description = By populating the organization's assets within the assets_by_str.csv, we will be able to detect unauthorized devices that are trying to connect with the organization's network by inspecting DHCP request packets, which are issued by devices when they attempt to obtain an IP address from the DHCP server. The MAC address associated with the source of the DHCP request is checked against the list of known devices, and reports on those that are not found.
action.escu.mappings = {"cis20": ["CIS 1"], "kill_chain_phases": ["Reconnaissance", "Delivery", "Actions on Objectives"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Network_Sessions"]
action.escu.eli5 = By populating the organization's assets within the assets_by_str.csv, we will be able to detect unauthorized devices that are trying to connect with the organization's network by inspecting DHCP request packets, which are issued by devices when they attempt to obtain an IP address from the DHCP server. The MAC address associated with the source of the DHCP request is checked against the list of known devices, and reports on those that are not found.
action.escu.how_to_implement = This search uses the Network_Sessions data model shipped with Enterprise Security. It leverages the Assets and Identity framework to populate the assets_by_str.csv file located in SA-IdentityManagement, which will contain a list of known authorized organizational assets including their MAC addresses. Ensure that all inventoried systems have their MAC address populated.
action.escu.known_false_positives = This search might be prone to high false positives. Please consider this when conducting analysis or investigations. Authorized devices may be detected as unauthorized. If this is the case, verify the MAC address of the system responsible for the false positive and add it to the Assets and Identity framework with the proper information.
action.escu.creation_date = 2017-09-13
action.escu.modification_date = 2017-09-13
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Unauthorized Assets by MAC address - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Asset Tracking"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Unauthorized Assets by MAC address - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = By populating the organization's assets within the assets_by_str.csv, we will be able to detect unauthorized devices that are trying to connect with the organization's network by inspecting DHCP request packets, which are issued by devices when they attempt to obtain an IP address from the DHCP server. The MAC address associated with the source of the DHCP request is checked against the list of known devices, and reports on those that are not found.
action.notable.param.rule_title = Detect Unauthorized Assets by MAC address
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST by All_Sessions.src_ip All_Sessions.src_mac | dedup All_Sessions.src_mac| `drop_dm_object_name("Network_Sessions")`|`drop_dm_object_name("All_Sessions")` | search NOT [| inputlookup asset_lookup_by_str |rename mac as src_mac | fields + src_mac] | `detect_unauthorized_assets_by_mac_address_filter`

[ESCU - Detect Use of cmd exe to Launch Script Interpreters - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the execution of the cscript.exe or wscript.exe processes, with a parent of cmd.exe. The search will return the count, the first and last time this execution was seen on a machine, the user, and the destination of the machine
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["T1059.003"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of the cscript.exe or wscript.exe processes, with a parent of cmd.exe. The search will return the count, the first and last time this execution was seen on a machine, the user, and the destination of the machine
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Some legitimate applications may exhibit this behavior.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Use of cmd exe to Launch Script Interpreters - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Suspicious Command-Line Executions"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Use of cmd exe to Launch Script Interpreters - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for the execution of the cscript.exe or wscript.exe processes, with a parent of cmd.exe. The search will return the count, the first and last time this execution was seen on a machine, the user, and the destination of the machine
action.notable.param.rule_title = Detect Use of cmd exe to Launch Script Interpreters
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name="cmd.exe" (Processes.process_name=cscript.exe OR Processes.process_name =wscript.exe) by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | `detect_use_of_cmd_exe_to_launch_script_interpreters_filter`

[ESCU - Detect Windows DNS SIGRed via Splunk Stream - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects SIGRed via Splunk Stream.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["T1203"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects SIGRed via Splunk Stream.
action.escu.how_to_implement = You must be ingesting Splunk Stream DNS and Splunk Stream TCP. We are detecting SIG and KEY records via stream:dns and TCP payload over 65KB in size via stream:tcp.  Replace the macro definitions ('stream:dns' and 'stream:tcp') with configurations for your Splunk environment.
action.escu.known_false_positives = unknown
action.escu.creation_date = 2020-07-28
action.escu.modification_date = 2020-07-28
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Windows DNS SIGRed via Splunk Stream - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows DNS SIGRed CVE-2020-1350"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Windows DNS SIGRed via Splunk Stream - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search detects SIGRed via Splunk Stream.
action.notable.param.rule_title = Detect Windows DNS SIGRed via Splunk Stream
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `stream_dns` | spath "query_type{}" | search "query_type{}" IN (SIG,KEY) | spath protocol_stack | search protocol_stack="ip:tcp:dns" | append [search `stream_tcp` bytes_out>65000] | `detect_windows_dns_sigred_via_splunk_stream_filter` | stats count by flow_id | where count>1 | fields - count

[ESCU - Detect Windows DNS SIGRed via Zeek - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects SIGRed via Zeek DNS and Zeek Conn data.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["T1203"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search detects SIGRed via Zeek DNS and Zeek Conn data.
action.escu.how_to_implement = You must be ingesting Zeek DNS and Zeek Conn data into Splunk. Zeek data should also be getting ingested in JSON format.  We are detecting SIG and KEY records via bro:dns:json and TCP payload over 65KB in size via bro:conn:json.  The Network Resolution and Network Traffic datamodels are in use for this search.
action.escu.known_false_positives = unknown
action.escu.creation_date = 2020-07-28
action.escu.modification_date = 2020-07-28
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Windows DNS SIGRed via Zeek - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows DNS SIGRed CVE-2020-1350"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Windows DNS SIGRed via Zeek - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search detects SIGRed via Zeek DNS and Zeek Conn data.
action.notable.param.rule_title = Detect Windows DNS SIGRed via Zeek
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution where DNS.query_type IN (SIG,KEY) by DNS.flow_id | rename DNS.flow_id as flow_id | append [| tstats  `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.bytes_in>65000 by All_Traffic.flow_id | rename All_Traffic.flow_id as flow_id] | `detect_windows_dns_sigred_via_zeek_filter` | stats count by flow_id | where count>1 | fields - count 

[ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific GET or HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers. JexBoss is described as the exploit tool of choice for this malicious activity.
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"], "mitre_attack": ["T1082"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for specific GET or HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers. JexBoss is described as the exploit tool of choice for this malicious activity.
action.escu.how_to_implement = You must be ingesting data from the web server or network traffic that contains web specific information, and populating the Web data model.
action.escu.known_false_positives = It's possible for legitimate HTTP requests to be made to URLs containing the suspicious paths.
action.escu.creation_date = 2017-09-23
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["JBoss Vulnerability", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for specific GET or HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers. JexBoss is described as the exploit tool of choice for this malicious activity.
action.notable.param.rule_title = Detect attackers scanning for vulnerable JBoss servers
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") AND (Web.url="*/web-console/ServerInfo.jsp*" OR Web.url="*web-console*" OR Web.url="*jmx-console*" OR Web.url = "*invoker*") by Web.http_method, Web.url, Web.src, Web.dest | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `detect_attackers_scanning_for_vulnerable_jboss_servers_filter`

[ESCU - Detect hosts connecting to dynamic domain providers - Rule]
action.escu = 0
action.escu.enabled = 1
description = Malicious actors often abuse legitimate Dynamic DNS services to host malicious payloads or interactive command and control nodes. Attackers will automate domain resolution changes by routing dynamic domains to countless IP addresses to circumvent firewall blocks, blacklists as well as frustrate a network defenders analytic and investigative processes. This search will look for DNS queries made from within your infrastructure to suspicious dynamic domains.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12", "CIS 13"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Malicious actors often abuse legitimate Dynamic DNS services to host malicious payloads or interactive command and control nodes. Attackers will automate domain resolution changes by routing dynamic domains to countless IP addresses to circumvent firewall blocks, blacklists as well as frustrate a network defenders analytic and investigative processes. This search will look for DNS queries made from within your infrastructure to suspicious dynamic domains.
action.escu.how_to_implement = First, you'll need to ingest data from your DNS operations. This can be done by ingesting logs from your server or data, collected passively by Splunk Stream or a similar solution. Specifically, data that contains the domain that is being queried and the IP of the host originating the request must be populating the `Network_Resolution` data model. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of Dynamic DNS providers. Please consider updating the local lookup periodically by adding new domains to the list of `dynamic_dns_providers_local.csv`.\
This search produces fields (query, answer, isDynDNS) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable event. To see the additional metadata, add the following fields, if not already present, to Incident Review. Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** DNS Query, **Field:** query\
1. \
1. **Label:** DNS Answer, **Field:** answer\
1. \
1. **Label:** IsDynamicDNS, **Field:** isDynDNS\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = Some users and applications may leverage Dynamic DNS to reach out to some domains on the Internet since dynamic DNS by itself is not malicious, however this activity must be verified.
action.escu.creation_date = 2020-01-16
action.escu.modification_date = 2020-01-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect hosts connecting to dynamic domain providers - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Data Protection", "Prohibited Traffic Allowed or Protocol Mismatch", "DNS Hijacking", "Suspicious DNS Traffic", "Dynamic DNS", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect hosts connecting to dynamic domain providers - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = Malicious actors often abuse legitimate Dynamic DNS services to host malicious payloads or interactive command and control nodes. Attackers will automate domain resolution changes by routing dynamic domains to countless IP addresses to circumvent firewall blocks, blacklists as well as frustrate a network defenders analytic and investigative processes. This search will look for DNS queries made from within your infrastructure to suspicious dynamic domains.
action.notable.param.rule_title = Detect hosts connecting to dynamic domain providers
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(DNS.answer) as answer min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `security_content_ctime(firstTime)` | `dynamic_dns_providers` | `detect_hosts_connecting_to_dynamic_domain_providers_filter`

[ESCU - Detect malicious requests to exploit JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect malicious HTTP requests crafted to exploit jmx-console in JBoss servers. The malicious requests have a long URL length, as the payload is embedded in the URL.
action.escu.mappings = {"cis20": ["CIS 12", "CIS 4", "CIS 18"], "kill_chain_phases": ["Delivery"], "nist": ["ID.RA", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search is used to detect malicious HTTP requests crafted to exploit jmx-console in JBoss servers. The malicious requests have a long URL length, as the payload is embedded in the URL.
action.escu.how_to_implement = You must ingest data from the web server or capture network data that contains web specific information with solutions such as Bro or Splunk Stream, and populating the Web data model
action.escu.known_false_positives = No known false positives for this detection.
action.escu.creation_date = 2017-09-23
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect malicious requests to exploit JBoss servers - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["JBoss Vulnerability", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect malicious requests to exploit JBoss servers - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search is used to detect malicious HTTP requests crafted to exploit jmx-console in JBoss servers. The malicious requests have a long URL length, as the payload is embedded in the URL.
action.notable.param.rule_title = Detect malicious requests to exploit JBoss servers
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") by Web.http_method, Web.url,Web.url_length Web.src, Web.dest | search Web.url="*jmx-console/HtmlAdaptor?action=invokeOpByName&name=jboss.admin*import*" AND Web.url_length > 200 | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table src, dest_ip, http_method, url, firstTime, lastTime | `detect_malicious_requests_to_exploit_jboss_servers_filter`

[ESCU - Detect mshta exe running scripts in command-line arguments - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the execution of "mshta.exe" with command-line arguments that launch a script. The search will return the first time and last time these command-line arguments were used for these executions, as well as the target system, the user, process "mshta.exe" and its parent process.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["T1059.003"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of "mshta.exe" with command-line arguments that launch a script. The search will return the first time and last time these command-line arguments were used for these executions, as well as the target system, the user, process "mshta.exe" and its parent process.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with the process name, parent process, and command-line executions from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Although unlikely, some legitimate applications may exhibit this behavior, triggering a false positive.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect mshta exe running scripts in command-line arguments - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious MSHTA Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect mshta exe running scripts in command-line arguments - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for the execution of "mshta.exe" with command-line arguments that launch a script. The search will return the first time and last time these command-line arguments were used for these executions, as well as the target system, the user, process "mshta.exe" and its parent process.
action.notable.param.rule_title = Detect mshta exe running scripts in command-line arguments
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=mshta.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search (process=*vbscript* OR process=*javascript*) | `detect_mshta_exe_running_scripts_in_command_line_arguments_filter`

[ESCU - Detect new API calls from user roles - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects new API calls that have either never been seen before or that have not been seen in the previous hour, where the identity type is `AssumedRole`.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects new API calls that have either never been seen before or that have not been seen in the previous hour, where the identity type is `AssumedRole`.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously seen API call per user roles in CloudTrail" support search once to create a history of previously seen user roles.
action.escu.known_false_positives = It is possible that there are legitimate user roles making new or infrequently used API calls in your infrastructure, causing the search to trigger.
action.escu.creation_date = 2018-04-16
action.escu.modification_date = 2018-04-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect new API calls from user roles - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect new API calls from user roles - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search detects new API calls that have either never been seen before or that have not been seen in the previous hour, where the identity type is `AssumedRole`.
action.notable.param.rule_title = Detect new API calls from user roles
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole [search `cloudtrail` eventType=AwsApiCall errorCode=success  userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName |  inputlookup append=t previously_seen_api_calls_from_user_roles | stats min(earliest) as earliest, max(latest) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles| eval newApiCallfromUserRole=if(earliest>=relative_time(now(), "-70m@m"), 1, 0) | where newApiCallfromUserRole=1 | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | table eventName userName]  |rename userName as user| stats values(eventName) earliest(_time) as earliest latest(_time) as latest by user | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | `detect_new_api_calls_from_user_roles_filter`

[ESCU - Detect new user AWS Console Login - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect new user AWS Console Login - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect new user AWS Console Login - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.notable.param.rule_title = Detect new user AWS Console Login
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=ConsoleLogin | rename userIdentity.arn as user | stats earliest(_time) as firstTime latest(_time) as lastTime by user | inputlookup append=t previously_seen_users_console_logins.csv  | stats min(firstTime) as firstTime max(lastTime) as lastTime by user | eval userStatus=if(firstTime >= relative_time(now(), "-70m@m"), "First Time Logging into AWS Console","Previously Seen User") | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| where userStatus ="First Time Logging into AWS Console"  | `detect_new_user_aws_console_login_filter`

[ESCU - Detect new user AWS Console Login - DM - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2020-05-28
action.escu.modification_date = 2020-05-28
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect new user AWS Console Login - DM - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect new user AWS Console Login - DM - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.notable.param.rule_title = Detect new user AWS Console Login - DM
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user | `drop_dm_object_name(Authentication)` | inputlookup append=t previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user | eval userStatus=if(firstTime >=relative_time(now(), '-70m@m'), 'First Time Logging into AWS Console','Previously Seen User')| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `detect_new_user_aws_console_login___dm_filter`

[ESCU - Detect processes used for System Network Configuration Discovery - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for fast execution of processes used for system network configuration discovery on the endpoint.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for fast execution of processes used for system network configuration discovery on the endpoint.
action.escu.how_to_implement = You must be ingesting data that records registry activity from your hosts to populate the Endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report reads and writes to the registry or that are populated via Windows event logs, after enabling process tracking in your Windows audit settings.
action.escu.known_false_positives = It is uncommon for normal users to execute a series of commands used for network discovery. System administrators often use scripts to execute these commands. These can generate false positives.
action.escu.creation_date = 2018-11-20
action.escu.modification_date = 2018-11-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect processes used for System Network Configuration Discovery - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect processes used for System Network Configuration Discovery - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for fast execution of processes used for system network configuration discovery on the endpoint.
action.notable.param.rule_title = Detect processes used for System Network Configuration Discovery
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.process_name Processes.user _time | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | search `system_network_configuration_discovery_tools` | transaction dest connected=false maxpause=5m |where eventcount>=5 | table firstTime lastTime dest user process_name process parent_process eventcount | `detect_processes_used_for_system_network_configuration_discovery_filter`

[ESCU - Detect web traffic to dynamic domain providers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for web connections to dynamic DNS providers.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1071.001"], "nist": ["PR.IP", "DE.DP"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for web connections to dynamic DNS providers.
action.escu.how_to_implement = This search requires you to be ingesting web-traffic logs. You can obtain these logs from indexing data from a web proxy or by using a network-traffic-analysis tool, such as Bro or Splunk Stream. The web data model must contain the URL being requested, the IP address of the host initiating the request, and the destination IP. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of dynamic DNS providers. Consider periodically updating this local lookup file with new domains.\
This search produces fields (`isDynDNS`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** IsDynamicDNS, **Field:** isDynDNS\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It is possible that list of dynamic DNS providers is outdated and/or that the URL being requested is legitimate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect web traffic to dynamic domain providers - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Dynamic DNS"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect web traffic to dynamic domain providers - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search looks for web connections to dynamic DNS providers.
action.notable.param.rule_title = Detect web traffic to dynamic domain providers
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Web.url) as url min(_time) as firstTime from datamodel=Web where Web.status=200 by Web.src Web.dest Web.status | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `dynamic_dns_web_traffic` | `detect_web_traffic_to_dynamic_domain_providers_filter`

[ESCU - Detection of DNS Tunnels - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect DNS tunneling, by calculating the sum of the length of DNS queries and DNS answers. The search also filters out potential false positives by filtering out queries made to internal systems and the queries originating from internal DNS, Web, and Email servers. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting an unusually large volume of DNS traffic.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1071.004"], "nist": ["PR.PT", "PR.DS"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search is used to detect DNS tunneling, by calculating the sum of the length of DNS queries and DNS answers. The search also filters out potential false positives by filtering out queries made to internal systems and the queries originating from internal DNS, Web, and Email servers. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting an unusually large volume of DNS traffic.
action.escu.how_to_implement = To successfully implement this search, we must ensure that DNS data is being ingested and mapped to the appropriate fields in the Network_Resolution data model. Fields like src_category are automatically provided by the Assets and Identity Framework shipped with Splunk Enterprise Security. You will need to ensure you are using the Assets and Identity Framework and populating the src_category field. You will also need to enable the `cim_corporate_web_domain_search()` macro which will essentially filter out the DNS queries made to the corporate web domains to reduce alert fatigue.
action.escu.known_false_positives = It's possible that normal DNS traffic will exhibit this behavior. If an alert is generated, please investigate and validate as appropriate. The threshold can also be modified to better suit your environment.
action.escu.creation_date = 2017-09-18
action.escu.modification_date = 2017-09-18
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detection of DNS Tunnels - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Data Protection", "Suspicious DNS Traffic", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detection of DNS Tunnels - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src']
action.notable.param.rule_description = This search is used to detect DNS tunneling, by calculating the sum of the length of DNS queries and DNS answers. The search also filters out potential false positives by filtering out queries made to internal systems and the queries originating from internal DNS, Web, and Email servers. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting an unusually large volume of DNS traffic.
action.notable.param.rule_title = Detection of DNS Tunnels
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` dc("DNS.query") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.query" | rename "DNS.src" as src  "DNS.query" as message | eval length=len(message) | stats sum(length) as length by src | append [ tstats `security_content_summariesonly` dc("DNS.answer") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.answer" | rename "DNS.src" as src  "DNS.answer" as message | eval message=if(message=="unknown","", message) | eval length=len(message) | stats sum(length) as length by src ] | stats sum(length) as length by src | where length > 10000 | `detection_of_dns_tunnels_filter`

[ESCU - Detection of tools built by NirSoft - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific command-line arguments that may indicate the execution of tools made by Nirsoft, which are legitimate, but may be abused by attackers.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["T1072"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for specific command-line arguments that may indicate the execution of tools made by Nirsoft, which are legitimate, but may be abused by attackers.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = While legitimate, these NirSoft tools are prone to abuse. You should verfiy that the tool was used for a legitimate purpose.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detection of tools built by NirSoft - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A "]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detection of tools built by NirSoft - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for specific command-line arguments that may indicate the execution of tools made by Nirsoft, which are legitimate, but may be abused by attackers.
action.notable.param.rule_title = Detection of tools built by NirSoft
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process="* /stext *" OR Processes.process="* /scomma *" ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `detection_of_tools_built_by_nirsoft_filter`

[ESCU - Disabling Remote User Account Control - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to registry keys that control the enforcement of Windows User Account Control (UAC).
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1112"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for modifications to registry keys that control the enforcement of Windows User Account Control (UAC).
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.
action.escu.known_false_positives = This registry key may be modified via administrators to implement a change in system policy. This type of change should be a very rare occurrence.
action.escu.creation_date = 2020-03-02
action.escu.modification_date = 2020-03-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Disabling Remote User Account Control - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Suspicious Windows Registry Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Disabling Remote User Account Control - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = The search looks for modifications to registry keys that control the enforcement of Windows User Account Control (UAC).
action.notable.param.rule_title = Disabling Remote User Account Control
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.registry_path="*Windows\\CurrentVersion\\Policies\\System\\LocalAccountTokenFilterPolicy" by Registry.dest, Registry.registry_key_name Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)` | `disabling_remote_user_account_control_filter`

[ESCU - Dump LSASS via comsvcs DLL - Rule]
action.escu = 0
action.escu.enabled = 1
description = Detect the usage of comsvcs.dll for dumping the lsass process.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.001"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Detect the usage of comsvcs.dll for dumping the lsass process.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2020-02-21
action.escu.modification_date = 2020-02-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Dump LSASS via comsvcs DLL - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Dump LSASS via comsvcs DLL - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Detect the usage of comsvcs.dll for dumping the lsass process.
action.notable.param.rule_title = Dump LSASS via comsvcs DLL
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=rundll32.exe Processes.process=*comsvcs.dll* Processes.process=*MiniDump* by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `dump_lsass_via_comsvcs_dll_filter`

[ESCU - EC2 Instance Modified With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being modified by users who have not previously modified them.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for EC2 instances being modified by users who have not previously modified them.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
action.escu.known_false_positives = It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - EC2 Instance Modified With Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - EC2 Instance Modified With Previously Unseen User - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for EC2 instances being modified by users who have not previously modified them.
action.notable.param.rule_title = EC2 Instance Modified With Previously Unseen User
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` `ec2_modification_api_calls` [search `cloudtrail` `ec2_modification_api_calls` errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_modifications_by_user | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=dest responseElements.instancesSet.items{}.instanceId | spath output=user userIdentity.arn | table _time, user, dest | `ec2_instance_modified_with_previously_unseen_user_filter`

[ESCU - EC2 Instance Started In Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where an instance is started in a particular region in the last one hour and then compares it to a lookup file of previously seen regions where an instance was started
action.escu.mappings = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where an instance is started in a particular region in the last one hour and then compares it to a lookup file of previously seen regions where an instance was started
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen AWS Regions" support search only once to create of baseline of previously seen regions.
action.escu.known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
action.escu.creation_date = 2018-02-23
action.escu.modification_date = 2018-02-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - EC2 Instance Started In Previously Unseen Region - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - EC2 Instance Started In Previously Unseen Region - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for CloudTrail events where an instance is started in a particular region in the last one hour and then compares it to a lookup file of previously seen regions where an instance was started
action.notable.param.rule_title = EC2 Instance Started In Previously Unseen Region
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` earliest=-1h StartInstances | stats earliest(_time) as earliest latest(_time) as latest by awsRegion | inputlookup append=t previously_seen_aws_regions.csv | stats min(earliest) as earliest max(latest) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | eval regionStatus=if(earliest >= relative_time(now(),"-1d@d"), "Instance Started in a New Region","Previously Seen Region") | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | where regionStatus="Instance Started in a New Region" | `ec2_instance_started_in_previously_unseen_region_filter`

[ESCU - EC2 Instance Started With Previously Unseen AMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created with previously unseen AMIs.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for EC2 instances being created with previously unseen AMIs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 AMIs" support search once to create a history of previously seen AMIs.
action.escu.known_false_positives = After a new AMI is created, the first systems created with that AMI will cause this alert to fire.  Verify that the AMI being used was created by a legitimate user.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen AMI - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - EC2 Instance Started With Previously Unseen AMI - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for EC2 instances being created with previously unseen AMIs.
action.notable.param.rule_title = EC2 Instance Started With Previously Unseen AMI
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=RunInstances [search `cloudtrail` eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by requestParameters.instancesSet.items{}.imageId | rename requestParameters.instancesSet.items{}.imageId as amiID | inputlookup append=t previously_seen_ec2_amis.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by amiID | outputlookup previously_seen_ec2_amis.csv | eval newAMI=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | where newAMI=1 | rename amiID as requestParameters.instancesSet.items{}.imageId | table requestParameters.instancesSet.items{}.imageId] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as arn, requestParameters.instancesSet.items{}.imageId as amiID | table firstTime, lastTime, arn, amiID, dest, instanceType | `ec2_instance_started_with_previously_unseen_ami_filter`

[ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created with previously unseen instance types.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for EC2 instances being created with previously unseen instance types.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Instance Types" support search once to create a history of previously seen instance types.
action.escu.known_false_positives = It is possible that an admin will create a new system using a new instance type never used before. Verify with the creator that they intended to create the system with the new instance type.
action.escu.creation_date = 2020-02-07
action.escu.modification_date = 2020-02-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for EC2 instances being created with previously unseen instance types.
action.notable.param.rule_title = EC2 Instance Started With Previously Unseen Instance Type
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=RunInstances [search `cloudtrail` eventName=RunInstances errorCode=success | fillnull value="m1.small" requestParameters.instanceType | stats earliest(_time) as earliest latest(_time) as latest by requestParameters.instanceType | rename requestParameters.instanceType as instanceType | inputlookup append=t previously_seen_ec2_instance_types.csv | stats min(earliest) as earliest max(latest) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | eval newType=if(earliest >= relative_time(now(), "-70m@m"), 1, 0) | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | where newType=1 | rename instanceType as requestParameters.instanceType | table requestParameters.instanceType] | spath output=user userIdentity.arn | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest | table _time, user, dest, instanceType | `ec2_instance_started_with_previously_unseen_instance_type_filter`

[ESCU - EC2 Instance Started With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created by users who have not created them before.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for EC2 instances being created by users who have not created them before.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs.
action.escu.known_false_positives = It's possible that a user will start to create EC2 instances when they haven't before for any number of reasons. Verify with the user that is launching instances that this is the intended behavior.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - EC2 Instance Started With Previously Unseen User - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for EC2 instances being created by users who have not created them before.
action.notable.param.rule_title = EC2 Instance Started With Previously Unseen User
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=RunInstances [search `cloudtrail` eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_launches_by_user.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as user | table _time, user, dest, instanceType | `ec2_instance_started_with_previously_unseen_user_filter`

[ESCU - Email Attachments With Lots Of Spaces - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attackers often use spaces as a means to obfuscate an attachment's file extension. This search looks for messages with email attachments that have many spaces within the file names.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "nist": ["PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = Attackers often use spaces as a means to obfuscate an attachment's file extension. This search looks for messages with email attachments that have many spaces within the file names.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. The threshold ratio is set to 10%, but this value can be configured to suit each environment. \
 **Splunk Phantom Playbook Integration**\
If Splunk Phantom is also configured in your environment, a playbook called "Suspicious Email Attachment Investigate and Delete" can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/` and add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search. The notable event will be sent to Phantom and the playbook will gather further information about the file attachment and its network behaviors. If Phantom finds malicious behavior and an analyst approves of the results, the email will be deleted from the user's inbox.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-09-19
action.escu.modification_date = 2017-09-19
action.escu.confidence = high
action.escu.full_search_name = ESCU - Email Attachments With Lots Of Spaces - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Email Attachments With Lots Of Spaces - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = Attackers often use spaces as a means to obfuscate an attachment's file extension. This search looks for messages with email attachments that have many spaces within the file names.
action.notable.param.rule_title = Email Attachments With Lots Of Spaces
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(All_Email.recipient) as recipient_address min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Email")` | eval space_ratio = (mvcount(split(file_name," "))-1)/len(file_name) | search space_ratio >= 0.1 |  rex field=recipient_address "(?<recipient_user>.*)@" | `email_attachments_with_lots_of_spaces_filter`

[ESCU - Email files written outside of the Outlook directory - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks at the change-analysis data model and detects email files created outside the normal Outlook directory.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.001"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks at the change-analysis data model and detects email files created outside the normal Outlook directory.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = Administrators and users sometimes prefer backing up their email data by moving the email files into a different folder. These attempts will be detected by the search.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Email files written outside of the Outlook directory - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Email files written outside of the Outlook directory - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search looks at the change-analysis data model and detects email files created outside the normal Outlook directory.
action.notable.param.rule_title = Email files written outside of the Outlook directory
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Filesystem where (Filesystem.file_name=*.pst OR Filesystem.file_name=*.ost) Filesystem.file_path != "C:\\Users\\*\\My Documents\\Outlook Files\\*"  Filesystem.file_path!="C:\\Users\\*\\AppData\\Local\\Microsoft\\Outlook*" by Filesystem.action Filesystem.process_id Filesystem.file_name Filesystem.dest | `drop_dm_object_name("Filesystem")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `email_files_written_outside_of_the_outlook_directory_filter` 

[ESCU - Email servers sending high volume traffic to hosts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.002"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Email servers sending high volume traffic to hosts - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Email servers sending high volume traffic to hosts - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.notable.param.rule_title = Email servers sending high volume traffic to hosts
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` sum(All_Traffic.bytes_out) as bytes_out from datamodel=Network_Traffic where All_Traffic.src_category=email_server by All_Traffic.dest_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_out) as avg_bytes_out stdev(bytes_out) as stdev_bytes_out | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_avg_bytes_out stdev(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_stdev_bytes_out by dest_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_out > (avg_bytes_out + (deviation_threshold * stdev_bytes_out)) AND bytes_out > (per_source_avg_bytes_out + (deviation_threshold * per_source_stdev_bytes_out)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_out - avg_bytes_out) / stdev_bytes_out, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_out - per_source_avg_bytes_out) / per_source_stdev_bytes_out, 2) | table dest_ip, _time, bytes_out, avg_bytes_out, per_source_avg_bytes_out, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average | `email_servers_sending_high_volume_traffic_to_hosts_filter`

[ESCU - Excessive DNS Failures - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success, and trigger on more than 50 occurrences.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1071.004"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success, and trigger on more than 50 occurrences.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = It is possible legitimate traffic can trigger this rule. Please investigate as appropriate. The threshold for generating an event can also be customized to better suit your environment.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Excessive DNS Failures - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious DNS Traffic", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Excessive DNS Failures - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success, and trigger on more than 50 occurrences.
action.notable.param.rule_title = Excessive DNS Failures
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values("DNS.query") as queries from datamodel=Network_Resolution where nodename=DNS "DNS.reply_code"!="No Error" "DNS.reply_code"!="NoError" DNS.reply_code!="unknown" NOT "DNS.query"="*.arpa" "DNS.query"="*.*" by "DNS.src","DNS.query"| `drop_dm_object_name("DNS")`| lookup cim_corporate_web_domain_lookup domain as query OUTPUT domain| where isnull(domain)| lookup update=true alexa_lookup_by_str domain as query OUTPUT rank| where isnull(rank)| stats sum(count) as count mode(queries) as queries by src| `get_asset(src)`| where count>50 | `excessive_dns_failures_filter`

[ESCU - Execution of File With Spaces Before Extension - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched from files with at least five spaces in the name before the extension. This is typically done to obfuscate the file extension by pushing it outside of the default view.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1036"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for processes launched from files with at least five spaces in the name before the extension. This is typically done to obfuscate the file extension by pushing it outside of the default view.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Execution of File With Spaces Before Extension - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Execution of File With Spaces Before Extension - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for processes launched from files with at least five spaces in the name before the extension. This is typically done to obfuscate the file extension by pushing it outside of the default view.
action.notable.param.rule_title = Execution of File With Spaces Before Extension
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process_path) as process_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = "*     .*" by Processes.dest Processes.user Processes.process Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `execution_of_file_with_spaces_before_extension_filter`

[ESCU - Execution of File with Multiple Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched from files that have double extensions in the file name. This is typically done to obscure the "real" file extension and make it appear as though the file being accessed is a data file, as opposed to executable content.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1036"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for processes launched from files that have double extensions in the file name. This is typically done to obscure the "real" file extension and make it appear as though the file being accessed is a data file, as opposed to executable content.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Execution of File with Multiple Extensions - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Execution of File with Multiple Extensions - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for processes launched from files that have double extensions in the file name. This is typically done to obscure the "real" file extension and make it appear as though the file being accessed is a data file, as opposed to executable content.
action.notable.param.rule_title = Execution of File with Multiple Extensions
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = *.doc.exe OR Processes.process = *.htm.exe OR Processes.process = *.html.exe OR Processes.process = *.txt.exe OR Processes.process = *.pdf.exe OR Processes.process = *.doc.exe by Processes.dest Processes.user Processes.process Processes.parent_process | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `execution_of_file_with_multiple_extensions_filter`

[ESCU - Extended Period Without Successful Netbackup Backups - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search returns a list of hosts that have not successfully completed a backup in over a week.
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search returns a list of hosts that have not successfully completed a backup in over a week.
action.escu.how_to_implement = To successfully implement this search you need to first obtain data from your backup solution, either from the backup logs on your hosts, or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your backup solution. Depending on how often you backup your systems, you may want to modify how far in the past to look for a successful backup, other than the default of seven days.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Extended Period Without Successful Netbackup Backups - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Monitor Backup Solution"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Extended Period Without Successful Netbackup Backups - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search returns a list of hosts that have not successfully completed a backup in over a week.
action.notable.param.rule_title = Extended Period Without Successful Netbackup Backups
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `netbackup` MESSAGE="Disk/Partition backup completed successfully." | stats latest(_time) as latestTime by COMPUTERNAME | `security_content_ctime(latestTime)` | rename COMPUTERNAME as dest | eval isOutlier=if(latestTime <= relative_time(now(), "-7d@d"), 1, 0) | search isOutlier=1 | table latestTime, dest | `extended_period_without_successful_netbackup_backups_filter`

[ESCU - File with Samsam Extension - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for file writes with extensions consistent with a SamSam ransomware attack.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Installation"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for file writes with extensions consistent with a SamSam ransomware attack.
action.escu.how_to_implement = You must be ingesting data that records file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Because these extensions are not typically used in normal operations, you should investigate all results.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - File with Samsam Extension - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - File with Samsam Extension - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The search looks for file writes with extensions consistent with a SamSam ransomware attack.
action.notable.param.rule_title = File with Samsam Extension
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_extension=.stubbin OR file_extension=.berkshire OR file_extension=.satoshi OR file_extension=.sophos OR file_extension=.keyxml | `file_with_samsam_extension_filter`

[ESCU - First Time Seen Child Process of Zoom - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for child processes spawned by zoom.exe or zoom.us that has not previously been seen.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1068"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for child processes spawned by zoom.exe or zoom.us that has not previously been seen.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You should run the baseline search `Previously Seen Zoom Child Processes - Initial` to build the initial table of child processes and hostnames for this search to work. You should also schedule at the same interval as this search the second baseline search `Previously Seen Zoom Child Processes - Update` to keep this table up to date and to age out old child processes. Please update the `previously_seen_zoom_child_processes_window` macro to adjust the time window.
action.escu.known_false_positives = A new child process of zoom isn't malicious by that fact alone. Further investigation of the actions of the child process is needed to verify any malicious behavior is taken.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - First Time Seen Child Process of Zoom - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Zoom Child Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - First Time Seen Child Process of Zoom - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for child processes spawned by zoom.exe or zoom.us that has not previously been seen.
action.notable.param.rule_title = First Time Seen Child Process of Zoom
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime values(Processes.parent_process_name) as parent_process_name values(Processes.parent_process_id) as parent_process_id values(Processes.process_name) as process_name values(Processes.process) as process from datamodel=Endpoint.Processes where (Processes.parent_process_name=zoom.exe OR Processes.parent_process_name=zoom.us) by Processes.process_id Processes.dest | `drop_dm_object_name(Processes)` | lookup zoom_first_time_child_process dest as dest process_name as process_name OUTPUT firstTimeSeen | where isnull(firstTimeSeen) OR firstTimeSeen > relative_time(now(), "`previously_seen_zoom_child_processes_window`") | `security_content_ctime(firstTime)` | table firstTime dest, process_id, process_name, parent_process_id, parent_process_name |`first_time_seen_child_process_of_zoom_filter`

[ESCU - First Time Seen Running Windows Service - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the first and last time a Windows service is seen running in your environment. This table is then cached.
action.escu.mappings = {"cis20": ["CIS 2", "CIS 9"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["T1569.002"], "nist": ["ID.AM", "PR.DS", "PR.AC", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for the first and last time a Windows service is seen running in your environment. This table is then cached.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows system event logs in order for this search to execute successfully. You should run the baseline search `Previously Seen Running Windows Services - Initial` to build the initial table of child processes and hostnames for this search to work. You should also schedule at the same interval as this search the second baseline search `Previously Seen Running Windows Services - Update` to keep this table up to date and to age out old Windows Services. Please update the `previously_seen_windows_service_window` macro to adjust the time window. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.
action.escu.known_false_positives = A previously unseen service is not necessarily malicious. Verify that the service is legitimate and that was installed by a legitimate process.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - First Time Seen Running Windows Service - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Service Abuse", "Orangeworm Attack Group"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - First Time Seen Running Windows Service - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for the first and last time a Windows service is seen running in your environment. This table is then cached.
action.notable.param.rule_title = First Time Seen Running Windows Service
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `wineventlog_system` EventCode=7036 | rex field=Message "The (?<service>[-\(\)\s\w]+) service entered the (?<state>\w+) state" | where state="running" | lookup previously_seen_running_windows_services service as service OUTPUT firstTimeSeen | where isnull(firstTimeSeen) OR firstTimeSeen > relative_time(now(), "`previously_seen_windows_service_window`") | table _time dest service | `first_time_seen_running_windows_service_filter`

[ESCU - First time seen command line argument - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for command-line arguments that use a `/c` parameter to execute a command that has not previously been seen.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1059.001", "T1059.003"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for command-line arguments that use a `/c` parameter to execute a command that has not previously been seen.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model. Please make sure you run the support search "Previously seen command line arguments,"&#151;which creates a lookup file called `previously_seen_cmd_line_arguments.csv`&#151;a historical baseline of all command-line arguments. You must also validate this list. For the search to do accurate calculation, ensure the search scheduling is the same value as the `relative_time` evaluation function.
action.escu.known_false_positives = Legitimate programs can also use command-line arguments to execute. Please verify the command-line arguments to check what command/program is being executed. We recommend customizing the `first_time_seen_cmd_line_filter` macro to exclude legitimate parent_process_name
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - First time seen command line argument - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DHS Report TA18-074A", "Suspicious Command-Line Executions", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Hidden Cobra Malware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - First time seen command line argument - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for command-line arguments that use a `/c` parameter to execute a command that has not previously been seen.
action.notable.param.rule_title = First time seen command line argument
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process Processes.process_name Processes.parent_process_name Processes.dest| `drop_dm_object_name(Processes)`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process | `drop_dm_object_name(Processes)` | inputlookup append=t previously_seen_cmd_line_arguments | stats min(firstTime) as firstTime, max(lastTime) as lastTime by process | outputlookup previously_seen_cmd_line_arguments | eval newCmdLineArgument=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCmdLineArgument=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table process] | `first_time_seen_command_line_argument_filter` 

[ESCU - GCP GCR container uploaded - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search show information on uploaded containers including source user, account, action, bucket name event name, http user agent, message and destination path.
action.escu.mappings = {"mitre_attack": ["T1525"]}
action.escu.data_models = []
action.escu.eli5 = This search show information on uploaded containers including source user, account, action, bucket name event name, http user agent, message and destination path.
action.escu.how_to_implement = You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a subpub subscription to be imported to Splunk. You must also install Cloud Infrastructure data model. Please also customize the `container_implant_gcp_detection_filter` macro to filter out the false positives.
action.escu.known_false_positives = Uploading container is a normal behavior from developers or users with access to container registry. GCP GCR registers container upload as a Storage event, this search must be considered under the context of CONTAINER upload creation which automatically generates a bucket entry for destination path.
action.escu.creation_date = 2020-02-20
action.escu.modification_date = 2020-02-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - GCP GCR container uploaded - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Container Implantation Monitoring and Investigation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - GCP GCR container uploaded - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search show information on uploaded containers including source user, account, action, bucket name event name, http user agent, message and destination path.
action.notable.param.rule_title = GCP GCR container uploaded
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = |tstats count min(_time) as firstTime max(_time) as lastTime  FROM datamodel=Cloud_Infrastructure.Storage where Storage.event_name=storage.objects.create by Storage.src_user Storage.account Storage.action Storage.bucket_name Storage.event_name Storage.http_user_agent Storage.msg Storage.object_path | `drop_dm_object_name("Storage")`  | `gcp_gcr_container_uploaded_filter` 

[ESCU - GCP Kubernetes cluster pod scan detection - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster's pods
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"], "mitre_attack": ["T1526"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster's pods
action.escu.how_to_implement = You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a Pub/Sub subscription to be imported to Splunk.
action.escu.known_false_positives = Not all unauthenticated requests are malicious, but frequency, User Agent, source IPs and pods  will provide context.
action.escu.creation_date = 2020-07-17
action.escu.modification_date = 2020-07-17
action.escu.confidence = high
action.escu.full_search_name = ESCU - GCP Kubernetes cluster pod scan detection - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - GCP Kubernetes cluster pod scan detection - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster's pods
action.notable.param.rule_title = GCP Kubernetes cluster pod scan detection
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` category=kube-audit |spath input=properties.log |search responseStatus.code=401 |table sourceIPs{} userAgent verb requestURI responseStatus.reason properties.pod | `gcp_kubernetes_cluster_pod_scan_detection_filter`

[ESCU - GCP Kubernetes cluster scan detection - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"], "mitre_attack": ["T1526"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster
action.escu.how_to_implement = You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a Pub/Sub subscription to be imported to Splunk. You must also install Cloud Infrastructure data model.Customize the macro kubernetes_gcp_scan_fingerprint_attack_detection to filter out FPs.
action.escu.known_false_positives = Not all unauthenticated requests are malicious, but frequency, User Agent and source IPs will provide context.
action.escu.creation_date = 2020-04-15
action.escu.modification_date = 2020-04-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - GCP Kubernetes cluster scan detection - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - GCP Kubernetes cluster scan detection - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster
action.notable.param.rule_title = GCP Kubernetes cluster scan detection
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` data.protoPayload.requestMetadata.callerIp!=127.0.0.1 data.protoPayload.requestMetadata.callerIp!=::1 "data.labels.authorization.k8s.io/decision"=forbid "data.protoPayload.status.message"=PERMISSION_DENIED data.protoPayload.authenticationInfo.principalEmail="system:anonymous" | rename data.protoPayload.requestMetadata.callerIp as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(data.protoPayload.methodName) as method_name values(data.protoPayload.resourceName) as resource_name values(data.protoPayload.requestMetadata.callerSuppliedUserAgent) as http_user_agent by src_ip data.resource.labels.cluster_name | rename data.resource.labels.cluster_name as cluster_name| `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`  | `gcp_kubernetes_cluster_scan_detection_filter` 

[ESCU - Hiding Files And Directories With Attrib exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attackers leverage an existing Windows binary, attrib.exe, to mark specific as hidden by using specific flags so that the victim does not see the file.  The search looks for specific command-line arguments to detect the use of attrib.exe to hide files.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1222.001"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers leverage an existing Windows binary, attrib.exe, to mark specific as hidden by using specific flags so that the victim does not see the file.  The search looks for specific command-line arguments to detect the use of attrib.exe to hide files.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Some applications and users may legitimately use attrib.exe to interact with the files. 
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Hiding Files And Directories With Attrib exe - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Hiding Files And Directories With Attrib exe - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Attackers leverage an existing Windows binary, attrib.exe, to mark specific as hidden by using specific flags so that the victim does not see the file.  The search looks for specific command-line arguments to detect the use of attrib.exe to hide files.
action.notable.param.rule_title = Hiding Files And Directories With Attrib exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=attrib.exe (Processes.process=*+h*) by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| `hiding_files_and_directories_with_attrib_exe_filter` 

[ESCU - Hosts receiving high volume of network traffic from email server - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.002"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Hosts receiving high volume of network traffic from email server - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Hosts receiving high volume of network traffic from email server - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.notable.param.rule_title = Hosts receiving high volume of network traffic from email server
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` sum(All_Traffic.bytes_in) as bytes_in from datamodel=Network_Traffic where All_Traffic.dest_category=email_server by All_Traffic.src_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_in) as avg_bytes_in stdev(bytes_in) as stdev_bytes_in | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_avg_bytes_in stdev(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_stdev_bytes_in by src_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_in > (avg_bytes_in + (deviation_threshold * stdev_bytes_in)) AND bytes_in > (per_source_avg_bytes_in + (deviation_threshold * per_source_stdev_bytes_in)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_in - avg_bytes_in) / stdev_bytes_in, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_in - per_source_avg_bytes_in) / per_source_stdev_bytes_in, 2) | table src_ip, _time, bytes_in, avg_bytes_in, per_source_avg_bytes_in, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average | `hosts_receiving_high_volume_of_network_traffic_from_email_server_filter`

[ESCU - Identify New User Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This detection search will help profile user accounts in your environment by identifying newly created accounts that have been added to your network in the past week.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1078.002"], "nist": ["PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This detection search will help profile user accounts in your environment by identifying newly created accounts that have been added to your network in the past week.
action.escu.how_to_implement = To successfully implement this search, you need to be populating the Enterprise Security Identity_Management data model in the assets and identity framework.
action.escu.known_false_positives = If the Identity_Management data model is not updated regularly, this search could give you false positive alerts. Please consider this and investigate appropriately.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Identify New User Accounts - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Identify New User Accounts - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This detection search will help profile user accounts in your environment by identifying newly created accounts that have been added to your network in the past week.
action.notable.param.rule_title = Identify New User Accounts
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | from datamodel Identity_Management.All_Identities  | eval empStatus=case((now()-startDate)<604800, "Accounts created in last week") | search empStatus="Accounts created in last week"| `security_content_ctime(endDate)` | `security_content_ctime(startDate)`| table identity empStatus endDate startDate | `identify_new_user_accounts_filter`

[ESCU - Kerberoasting spn request with RC4 encryption - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects a potential kerberoasting attack via service principal name requests
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1558.003"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects a potential kerberoasting attack via service principal name requests
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, and include the windows security event logs that contain kerberos
action.escu.known_false_positives = Older systems that support kerberos RC4 by default NetApp may generate false positives
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kerberoasting spn request with RC4 encryption - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kerberoasting spn request with RC4 encryption - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search detects a potential kerberoasting attack via service principal name requests
action.notable.param.rule_title = Kerberoasting spn request with RC4 encryption
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `wineventlog_security` EventID=4769 TicketOptions=0x40810000 TicketEncryptionType=0x17 | stats count min(_time) as firstTime max(_time) as lastTime values(ServiceName) values(TargetUserName) values(user)  by TargetDomainName | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `kerberoasting_spn_request_with_rc4_encryption_filter`

[ESCU - Kubernetes AWS detect RBAC authorization by account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs
action.escu.known_false_positives = Not all RBAC Authorications are malicious. RBAC authorizations can uncover malicious activity specially if sensitive Roles have been granted.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes AWS detect RBAC authorization by account - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes AWS detect RBAC authorization by account - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences
action.notable.param.rule_title = Kubernetes AWS detect RBAC authorization by account
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` annotations.authorization.k8s.io/reason=* | table sourceIPs{} user.username userAgent annotations.authorization.k8s.io/reason | stats count by user.username annotations.authorization.k8s.io/reason | rare user.username annotations.authorization.k8s.io/reason |`kubernetes_aws_detect_rbac_authorization_by_account_filter`

[ESCU - Kubernetes AWS detect most active service accounts by pod - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs
action.escu.known_false_positives = Not all service accounts interactions are malicious. Analyst must consider IP, verb and decision context when trying to detect maliciousness.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes AWS detect most active service accounts by pod - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes AWS detect most active service accounts by pod - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision
action.notable.param.rule_title = Kubernetes AWS detect most active service accounts by pod
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` user.groups{}=system:serviceaccounts  objectRef.resource=pods | table  sourceIPs{} user.username userAgent verb annotations.authorization.k8s.io/decision  | top  sourceIPs{} user.username verb annotations.authorization.k8s.io/decision |`kubernetes_aws_detect_most_active_service_accounts_by_pod_filter`

[ESCU - Kubernetes AWS detect sensitive role access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.
action.escu.known_false_positives = Sensitive role resource access is necessary for cluster operation, however source IP, namespace and user group may indicate possible malicious use. 
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes AWS detect sensitive role access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes AWS detect sensitive role access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.notable.param.rule_title = Kubernetes AWS detect sensitive role access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` objectRef.resource=clusterroles OR clusterrolebindings sourceIPs{}!=::1 sourceIPs{}!=127.0.0.1  | table sourceIPs{} user.username user.groups{} objectRef.namespace requestURI annotations.authorization.k8s.io/reason | dedup user.username user.groups{} |`kubernetes_aws_detect_sensitive_role_access_filter`

[ESCU - Kubernetes AWS detect service accounts forbidden failure access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.
action.escu.known_false_positives = This search can give false positives as there might be inherent issues with authentications and permissions at cluster.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes AWS detect service accounts forbidden failure access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes AWS detect service accounts forbidden failure access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI
action.notable.param.rule_title = Kubernetes AWS detect service accounts forbidden failure access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` user.groups{}=system:serviceaccounts responseStatus.status = Failure | table sourceIPs{} user.username userAgent verb responseStatus.status requestURI | `kubernetes_aws_detect_service_accounts_forbidden_failure_access_filter`

[ESCU - Kubernetes AWS detect suspicious kubectl calls - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.
action.escu.known_false_positives = Kubectl calls are not malicious by nature. However source IP, verb and Object can reveal potential malicious activity, specially anonymous suspicious IPs and sensitive objects such as configmaps or secrets
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes AWS detect suspicious kubectl calls - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes AWS detect suspicious kubectl calls - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context
action.notable.param.rule_title = Kubernetes AWS detect suspicious kubectl calls
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` userAgent=kubectl* sourceIPs{}!=127.0.0.1 sourceIPs{}!=::1 src_user=system:anonymous  | table  src_ip src_user verb userAgent requestURI  | stats  count by src_ip src_user verb userAgent requestURI |`kubernetes_aws_detect_suspicious_kubectl_calls_filter`

[ESCU - Kubernetes Azure detect RBAC authorization by account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding rare or top to see both extremes of RBAC by accounts occurrences
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding rare or top to see both extremes of RBAC by accounts occurrences
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = Not all RBAC Authorications are malicious. RBAC authorizations can uncover malicious activity specially if sensitive Roles have been granted.
action.escu.creation_date = 2020-05-26
action.escu.modification_date = 2020-05-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure detect RBAC authorization by account - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure detect RBAC authorization by account - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding rare or top to see both extremes of RBAC by accounts occurrences
action.notable.param.rule_title = Kubernetes Azure detect RBAC authorization by account
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = sourcetype:mscs:storage:blob:json category=kube-audit | spath input=properties.log | search annotations.authorization.k8s.io/reason=* | table sourceIPs{} user.username userAgent annotations.authorization.k8s.io/reason |stats count by user.username annotations.authorization.k8s.io/reason | rare user.username annotations.authorization.k8s.io/reason |`kubernetes_azure_detect_rbac_authorization_by_account_filter`

[ESCU - Kubernetes Azure detect most active service accounts by pod namespace - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes service accounts,accessing pods and namespaces by IP address and verb
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes service accounts,accessing pods and namespaces by IP address and verb
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = Not all service accounts interactions are malicious. Analyst must consider IP and verb context when trying to detect maliciousness.
action.escu.creation_date = 2020-05-26
action.escu.modification_date = 2020-05-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure detect most active service accounts by pod namespace - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure detect most active service accounts by pod namespace - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes service accounts,accessing pods and namespaces by IP address and verb
action.notable.param.rule_title = Kubernetes Azure detect most active service accounts by pod namespace
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `kubernetes_azure` category=kube-audit | spath input=properties.log | search user.groups{}=system:serviceaccounts* OR user.username=system.anonymous OR annotations.authorization.k8s.io/decision=allow  | table  sourceIPs{} user.username userAgent verb responseStatus.reason responseStatus.status properties.pod objectRef.namespace | top sourceIPs{} user.username verb responseStatus.status properties.pod objectRef.namespace |`kubernetes_azure_detect_most_active_service_accounts_by_pod_namespace_filter`

[ESCU - Kubernetes Azure detect sensitive object access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = Sensitive object access is not necessarily malicious but user and object context can provide guidance for detection.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure detect sensitive object access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure detect sensitive object access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.notable.param.rule_title = Kubernetes Azure detect sensitive object access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `kubernetes_azure` category=kube-audit | spath input=properties.log| search objectRef.resource=secrets OR configmaps user.username=system.anonymous OR annotations.authorization.k8s.io/decision=allow  |table user.username user.groups{} objectRef.resource objectRef.namespace objectRef.name annotations.authorization.k8s.io/reason |dedup user.username user.groups{} |`kubernetes_azure_detect_sensitive_object_access_filter`

[ESCU - Kubernetes Azure detect sensitive role access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = Sensitive role resource access is necessary for cluster operation, however source IP, namespace and user group may indicate possible malicious use. 
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure detect sensitive role access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure detect sensitive role access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.notable.param.rule_title = Kubernetes Azure detect sensitive role access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `kubernetes_azure` category=kube-audit | spath input=properties.log| search objectRef.resource=clusterroles OR clusterrolebindings | table sourceIPs{} user.username user.groups{} objectRef.namespace requestURI annotations.authorization.k8s.io/reason | dedup user.username user.groups{} |`kubernetes_azure_detect_sensitive_role_access_filter`

[ESCU - Kubernetes Azure detect service accounts forbidden failure access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes service accounts with failure or forbidden access status
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes service accounts with failure or forbidden access status
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = This search can give false positives as there might be inherent issues with authentications and permissions at cluster.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure detect service accounts forbidden failure access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure detect service accounts forbidden failure access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on Kubernetes service accounts with failure or forbidden access status
action.notable.param.rule_title = Kubernetes Azure detect service accounts forbidden failure access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `kubernetes_azure` category=kube-audit | spath input=properties.log | search user.groups{}=system:serviceaccounts*  responseStatus.reason=Forbidden | table  sourceIPs{} user.username userAgent verb responseStatus.reason responseStatus.status properties.pod objectRef.namespace  |`kubernetes_azure_detect_service_accounts_forbidden_failure_access_filter`

[ESCU - Kubernetes Azure detect suspicious kubectl calls - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on rare Kubectl calls with IP, verb namespace and object access context
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on rare Kubectl calls with IP, verb namespace and object access context
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = Kubectl calls are not malicious by nature. However source IP, verb and Object can reveal potential malicious activity, specially suspicious IPs and sensitive objects such as configmaps or secrets
action.escu.creation_date = 2020-05-26
action.escu.modification_date = 2020-05-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure detect suspicious kubectl calls - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure detect suspicious kubectl calls - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information on rare Kubectl calls with IP, verb namespace and object access context
action.notable.param.rule_title = Kubernetes Azure detect suspicious kubectl calls
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `kubernetes_azure` category=kube-audit | spath input=properties.log | spath input=responseObject.metadata.annotations.kubectl.kubernetes.io/last-applied-configuration | search userAgent=kubectl* sourceIPs{}!=127.0.0.1 sourceIPs{}!=::1 | table sourceIPs{} verb userAgent user.groups{} objectRef.resource objectRef.namespace requestURI | rare sourceIPs{} verb userAgent user.groups{} objectRef.resource objectRef.namespace requestURI|`kubernetes_azure_detect_suspicious_kubectl_calls_filter`

[ESCU - Kubernetes Azure pod scan fingerprint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster pod in Azure
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster pod in Azure
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = Not all unauthenticated requests are malicious, but source IPs, userAgent, verb, request URI and response status will provide context.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure pod scan fingerprint - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure pod scan fingerprint - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster pod in Azure
action.notable.param.rule_title = Kubernetes Azure pod scan fingerprint
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `kubernetes_azure` category=kube-audit | spath input=properties.log | search responseStatus.code=401 | table  sourceIPs{} userAgent verb requestURI responseStatus.reason properties.pod |`kubernetes_azure_pod_scan_fingerprint_filter`

[ESCU - Kubernetes Azure scan fingerprint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster in Azure
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"], "mitre_attack": ["T1526"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster in Azure
action.escu.how_to_implement = You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics
action.escu.known_false_positives = Not all unauthenticated requests are malicious, but source IPs, userAgent, verb, request URI and response status will provide context.
action.escu.creation_date = 2020-05-19
action.escu.modification_date = 2020-05-19
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes Azure scan fingerprint - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes Azure scan fingerprint - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster in Azure
action.notable.param.rule_title = Kubernetes Azure scan fingerprint
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `kubernetes_azure` category=kube-audit | spath input=properties.log | search responseStatus.code=401 | table  sourceIPs{} userAgent verb requestURI responseStatus.reason |`kubernetes_azure_scan_fingerprint_filter`

[ESCU - Kubernetes GCP detect RBAC authorizations by account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences
action.escu.how_to_implement = You must install splunk AWS add on for GCP. This search works with pubsub messaging service logs
action.escu.known_false_positives = Not all RBAC Authorications are malicious. RBAC authorizations can uncover malicious activity specially if sensitive Roles have been granted.
action.escu.creation_date = 2020-07-11
action.escu.modification_date = 2020-07-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes GCP detect RBAC authorizations by account - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes GCP detect RBAC authorizations by account - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences
action.notable.param.rule_title = Kubernetes GCP detect RBAC authorizations by account
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` data.labels.authorization.k8s.io/reason=ClusterRoleBinding OR Clusterrole  | table src_ip src_user data.labels.authorization.k8s.io/decision data.labels.authorization.k8s.io/reason | rare src_user data.labels.authorization.k8s.io/reason |`kubernetes_gcp_detect_rbac_authorizations_by_account_filter`

[ESCU - Kubernetes GCP detect most active service accounts by pod - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision
action.escu.how_to_implement = You must install splunk GCP add on. This search works with pubsub messaging service logs
action.escu.known_false_positives = Not all service accounts interactions are malicious. Analyst must consider IP, verb and decision context when trying to detect maliciousness.
action.escu.creation_date = 2020-07-10
action.escu.modification_date = 2020-07-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes GCP detect most active service accounts by pod - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes GCP detect most active service accounts by pod - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision
action.notable.param.rule_title = Kubernetes GCP detect most active service accounts by pod
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message  data.protoPayload.request.spec.group{}=system:serviceaccounts | table src_ip src_user http_user_agent data.protoPayload.request.spec.nonResourceAttributes.verb data.labels.authorization.k8s.io/decision data.protoPayload.response.spec.resourceAttributes.resource | top src_ip src_user http_user_agent data.labels.authorization.k8s.io/decision data.protoPayload.response.spec.resourceAttributes.resource |`kubernetes_gcp_detect_most_active_service_accounts_by_pod_filter`

[ESCU - Kubernetes GCP detect sensitive object access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets
action.escu.how_to_implement = You must install splunk add on for GCP . This search works with pubsub messaging service logs.
action.escu.known_false_positives = Sensitive object access is not necessarily malicious but user and object context can provide guidance for detection.
action.escu.creation_date = 2020-07-11
action.escu.modification_date = 2020-07-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes GCP detect sensitive object access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes GCP detect sensitive object access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets
action.notable.param.rule_title = Kubernetes GCP detect sensitive object access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` data.protoPayload.authorizationInfo{}.resource=configmaps OR secrets  | table data.protoPayload.requestMetadata.callerIp src_user data.resource.labels.cluster_name data.protoPayload.request.metadata.namespace data.labels.authorization.k8s.io/decision | dedup data.protoPayload.requestMetadata.callerIp src_user data.resource.labels.cluster_name |`kubernetes_gcp_detect_sensitive_object_access_filter`

[ESCU - Kubernetes GCP detect sensitive role access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.escu.how_to_implement = You must install splunk add on for GCP. This search works with pubsub messaging servicelogs.
action.escu.known_false_positives = Sensitive role resource access is necessary for cluster operation, however source IP, user agent, decision and reason may indicate possible malicious use. 
action.escu.creation_date = 2020-07-11
action.escu.modification_date = 2020-07-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes GCP detect sensitive role access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Role Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes GCP detect sensitive role access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets
action.notable.param.rule_title = Kubernetes GCP detect sensitive role access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` data.labels.authorization.k8s.io/reason=ClusterRoleBinding OR Clusterrole dest=apis/rbac.authorization.k8s.io/v1 src_ip!=::1  | table src_ip src_user http_user_agent data.labels.authorization.k8s.io/decision data.labels.authorization.k8s.io/reason | dedup src_ip src_user |`kubernetes_gcp_detect_sensitive_role_access_filter`

[ESCU - Kubernetes GCP detect service accounts forbidden failure access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI
action.escu.how_to_implement = You must install splunk add on for GCP. This search works with pubsub messaging service logs.
action.escu.known_false_positives = This search can give false positives as there might be inherent issues with authentications and permissions at cluster.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes GCP detect service accounts forbidden failure access - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes GCP detect service accounts forbidden failure access - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI
action.notable.param.rule_title = Kubernetes GCP detect service accounts forbidden failure access
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` system:serviceaccounts data.protoPayload.response.status.allowed!=* | table src_ip src_user http_user_agent data.protoPayload.response.spec.resourceAttributes.namespace data.resource.labels.cluster_name data.protoPayload.response.spec.resourceAttributes.verb  data.protoPayload.request.status.allowed data.protoPayload.response.status.reason data.labels.authorization.k8s.io/decision | dedup src_ip src_user | `kubernetes_gcp_detect_service_accounts_forbidden_failure_access_filter`

[ESCU - Kubernetes GCP detect suspicious kubectl calls - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"]}
action.escu.data_models = []
action.escu.eli5 = This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context
action.escu.how_to_implement = You must install splunk add on for GCP. This search works with pubsub messaging logs.
action.escu.known_false_positives = Kubectl calls are not malicious by nature. However source IP, source user, user agent, object path, and authorization context can reveal potential malicious activity, specially anonymous suspicious IPs and sensitive objects such as configmaps or secrets
action.escu.creation_date = 2020-07-11
action.escu.modification_date = 2020-07-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Kubernetes GCP detect suspicious kubectl calls - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Kubernetes Sensitive Object Access Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Kubernetes GCP detect suspicious kubectl calls - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context
action.notable.param.rule_title = Kubernetes GCP detect suspicious kubectl calls
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `google_gcp_pubsub_message` data.protoPayload.requestMetadata.callerSuppliedUserAgent=kubectl* src_user=system:unsecured OR src_user=system:anonymous | table src_ip src_user data.protoPayload.requestMetadata.callerSuppliedUserAgent data.protoPayload.authorizationInfo{}.granted object_path |dedup src_ip src_user |`kubernetes_gcp_detect_suspicious_kubectl_calls_filter`

[ESCU - Large Volume of DNS ANY Queries - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
action.escu.mappings = {"cis20": ["CIS 11", "CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1498.002"], "nist": ["PR.PT", "DE.AE", "PR.IP"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = Legitimate ANY requests may trigger this search, however it is unusual to see a large volume of them under typical circumstances. You may modify the threshold in the search to better suit your environment.
action.escu.creation_date = 2017-09-20
action.escu.modification_date = 2017-09-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Large Volume of DNS ANY Queries - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DNS Amplification Attacks"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Large Volume of DNS ANY Queries - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
action.notable.param.rule_title = Large Volume of DNS ANY Queries
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution where nodename=DNS "DNS.message_type"="QUERY" "DNS.record_type"="ANY" by "DNS.dest" | `drop_dm_object_name("DNS")` | where count>200 | `large_volume_of_dns_any_queries_filter`

[ESCU - MacOS - Re-opened Applications - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes referencing the plist files that determine which applications are re-opened when a user reboots their machine.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Installation", "Command and Control"], "nist": ["DE.DP", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for processes referencing the plist files that determine which applications are re-opened when a user reboots their machine.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest process data from your osquery deployed agents with the [splunk.conf](https://github.com/splunk/TA-osquery/blob/master/config/splunk.conf) pack enabled. Also the [TA-OSquery](https://github.com/splunk/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the data populate the Endpoint data model.
action.escu.known_false_positives = At this stage, there are no known false positives. During testing, no process events refering the com.apple.loginwindow.plist files were observed during normal operation of re-opening applications on reboot. Therefore, it can be asumed that any occurences of this in the process events would be worth investigating. In the event that the legitimate modification by the system of these files is in fact logged to the process log, then the process_name of that process can be whitelisted.
action.escu.creation_date = 2020-02-07
action.escu.modification_date = 2020-02-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - MacOS - Re-opened Applications - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - MacOS - Re-opened Applications - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for processes referencing the plist files that determine which applications are re-opened when a user reboots their machine.
action.notable.param.rule_title = MacOS - Re-opened Applications
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process="*com.apple.loginwindow*" by Processes.user Processes.process_name Processes.parent_process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `macos___re_opened_applications_filter`

[ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with parameters to modify the execution policy of the run, run in a hidden window, and connect to the Internet. This combination of command-line options is suspicious because it's overriding the default PowerShell execution policy, attempts to hide its activity from the user, and connects to the Internet.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1059.001"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes started with parameters to modify the execution policy of the run, run in a hidden window, and connect to the Internet. This combination of command-line options is suspicious because it's overriding the default PowerShell execution policy, attempts to hide its activity from the user, and connects to the Internet.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Malicious PowerShell", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for PowerShell processes started with parameters to modify the execution policy of the run, run in a hidden window, and connect to the Internet. This combination of command-line options is suspicious because it's overriding the default PowerShell execution policy, attempts to hide its activity from the user, and connects to the Internet.
action.notable.param.rule_title = Malicious PowerShell Process - Connect To Internet With Hidden Window
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process="*-Exec*" process="*-WindowStyle*" process="*hidden*" process="*New-Object*" process="*System.Net.WebClient*" | `malicious_powershell_process___connect_to_internet_with_hidden_window_filter`

[ESCU - Malicious PowerShell Process - Encoded Command - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes that have encoded the script within the command-line. Malware has been seen using this parameter, as it obfuscates the code and makes it relatively easy to pass a script on the command-line.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1027"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that have encoded the script within the command-line. Malware has been seen using this parameter, as it obfuscates the code and makes it relatively easy to pass a script on the command-line.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = System administrators may use this option, but it's not common.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Encoded Command - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Malicious PowerShell Process - Encoded Command - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for PowerShell processes that have encoded the script within the command-line. Malware has been seen using this parameter, as it obfuscates the code and makes it relatively easy to pass a script on the command-line.
action.notable.param.rule_title = Malicious PowerShell Process - Encoded Command
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = powershell.exe (Processes.process=*-EncodedCommand* OR Processes.process=*-enc*) by Processes.user Processes.process_name Processes.process Processes.parent_process_name Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `malicious_powershell_process___encoded_command_filter`

[ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with parameters used to bypass the local execution policy for scripts. These parameters are often observed in attacks leveraging PowerShell scripts as they override the default PowerShell execution policy.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1059.001"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes started with parameters used to bypass the local execution policy for scripts. These parameters are often observed in attacks leveraging PowerShell scripts as they override the default PowerShell execution policy.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = There may be legitimate reasons to bypass the PowerShell execution policy. The PowerShell script being run with this parameter should be validated to ensure that it is legitimate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for PowerShell processes started with parameters used to bypass the local execution policy for scripts. These parameters are often observed in attacks leveraging PowerShell scripts as they override the default PowerShell execution policy.
action.notable.param.rule_title = Malicious PowerShell Process - Execution Policy Bypass
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process_id) as process_id, values(Processes.parent_process_id) as parent_process_id values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe AND (Processes.process="* -ex*" OR Processes.process="* bypass *") by Processes.process_id, Processes.user, Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `malicious_powershell_process___execution_policy_bypass_filter`

[ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with a base64 encoded command-line passed to it, with parameters to modify the execution policy for the process, and those that prevent the display of an interactive prompt to the user. This combination of command-line options is suspicious because it overrides the default PowerShell execution policy, attempts to hide itself from the user, and passes an encoded script to be run on the command-line.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1059.001"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes started with a base64 encoded command-line passed to it, with parameters to modify the execution policy for the process, and those that prevent the display of an interactive prompt to the user. This combination of command-line options is suspicious because it overrides the default PowerShell execution policy, attempts to hide itself from the user, and passes an encoded script to be run on the command-line.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for PowerShell processes started with a base64 encoded command-line passed to it, with parameters to modify the execution policy for the process, and those that prevent the display of an interactive prompt to the user. This combination of command-line options is suspicious because it overrides the default PowerShell execution policy, attempts to hide itself from the user, and passes an encoded script to be run on the command-line.
action.notable.param.rule_title = Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search (process=*-EncodedCommand* OR process=*-enc*) process=*-Exec* AND process=*-NonI* | `malicious_powershell_process___multiple_suspicious_command_line_arguments_filter`

[ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes launched with arguments that have characters indicative of obfuscation on the command-line.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["T1059.001"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes launched with arguments that have characters indicative of obfuscation on the command-line.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = These characters might be legitimately on the command-line, but it is not common.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for PowerShell processes launched with arguments that have characters indicative of obfuscation on the command-line.
action.notable.param.rule_title = Malicious PowerShell Process With Obfuscation Techniques
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest Processes.process | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| eval num_obfuscation = (mvcount(split(process, "`"))-1) + (mvcount(split(process, "^"))-1) | `malicious_powershell_process_with_obfuscation_techniques_filter` | search num_obfuscation > 0

[ESCU - Monitor DNS For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DNS requests for faux domains similar to the domains that you want to have monitored for abuse.
action.escu.mappings = {"kill_chain_phases": ["Delivery", "Actions on Objectives"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search looks for DNS requests for faux domains similar to the domains that you want to have monitored for abuse.
action.escu.how_to_implement = You need to ingest data from your DNS logs. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-09-23
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor DNS For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Brand Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Monitor DNS For Brand Abuse - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for DNS requests for faux domains similar to the domains that you want to have monitored for abuse.
action.notable.param.rule_title = Monitor DNS For Brand Abuse
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(DNS.answer) as IPs min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `security_content_ctime(firstTime)`| `brand_abuse_dns` | `monitor_dns_for_brand_abuse_filter`

[ESCU - Monitor Email For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for emails claiming to be sent from a domain similar to one that you want to have monitored for abuse.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "nist": ["PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks for emails claiming to be sent from a domain similar to one that you want to have monitored for abuse.
action.escu.how_to_implement = You need to ingest email header data. Specifically the sender's address (src_user) must be populated.  You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2018-01-05
action.escu.modification_date = 2018-01-05
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor Email For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Monitor Email For Brand Abuse - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for emails claiming to be sent from a domain similar to one that you want to have monitored for abuse.
action.notable.param.rule_title = Monitor Email For Brand Abuse
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(All_Email.recipient) as recipients, min(_time) as firstTime, max(_time) as lastTime from datamodel=Email by All_Email.src_user, All_Email.message_id | `drop_dm_object_name("All_Email")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | eval temp=split(src_user, "@") | eval email_domain=mvindex(temp, 1) | lookup update=true brandMonitoring_lookup domain as email_domain OUTPUT domain_abuse | search domain_abuse=true | table message_id, src_user, email_domain, recipients, firstTime, lastTime | `monitor_email_for_brand_abuse_filter`

[ESCU - Monitor Registry Keys for Print Monitors - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for registry activity associated with modifications to the registry key `HKLM\SYSTEM\CurrentControlSet\Control\Print\Monitors`. In this scenario, an attacker can load an arbitrary .dll into the print-monitor registry by giving the full path name to the after.dll. The system will execute the .dll with elevated (SYSTEM) permissions and will persist after reboot.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.CM", "PR.AC"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for registry activity associated with modifications to the registry key `HKLM\SYSTEM\CurrentControlSet\Control\Print\Monitors`. In this scenario, an attacker can load an arbitrary .dll into the print-monitor registry by giving the full path name to the after.dll. The system will execute the .dll with elevated (SYSTEM) permissions and will persist after reboot.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.
action.escu.known_false_positives = You will encounter noise from legitimate print-monitor registry entries.
action.escu.creation_date = 2018-11-02
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor Registry Keys for Print Monitors - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Monitor Registry Keys for Print Monitors - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for registry activity associated with modifications to the registry key `HKLM\SYSTEM\CurrentControlSet\Control\Print\Monitors`. In this scenario, an attacker can load an arbitrary .dll into the print-monitor registry by giving the full path name to the after.dll. The system will execute the .dll with elevated (SYSTEM) permissions and will persist after reboot.
action.notable.param.rule_title = Monitor Registry Keys for Print Monitors
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.action=modified AND Registry.registry_path="*CurrentControlSet\\Control\\Print\\Monitors*" by Registry.dest, Registry.registry_key_name Registry.status Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)` | `monitor_registry_keys_for_print_monitors_filter`

[ESCU - Monitor Web Traffic For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Web requests to faux domains similar to the one that you want to have monitored for abuse.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "nist": ["PR.IP"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for Web requests to faux domains similar to the one that you want to have monitored for abuse.
action.escu.how_to_implement = You need to ingest data from your web traffic. This can be accomplished by indexing data from a web proxy, or using a network traffic analysis tool, such as Bro or Splunk Stream. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-09-23
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor Web Traffic For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Brand Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Monitor Web Traffic For Brand Abuse - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src']
action.notable.param.rule_description = This search looks for Web requests to faux domains similar to the one that you want to have monitored for abuse.
action.notable.param.rule_title = Monitor Web Traffic For Brand Abuse
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Web.url) as urls min(_time) as firstTime from datamodel=Web by Web.src | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `brand_abuse_web` | `monitor_web_traffic_for_brand_abuse_filter`

[ESCU - Multiple Okta Users With Invalid Credentails From The Same IP - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects Okta login failures due to bad credentials for multiple users originating from the same ip address.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1078.001"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects Okta login failures due to bad credentials for multiple users originating from the same ip address.
action.escu.how_to_implement = This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.
action.escu.known_false_positives = A single public IP address servicing multiple legitmate users may trigger this search. In addition, the threshold of 5 distinct users may be too low for your needs. You may modify the included filter macro XXXXXXXXXXXXX to raise the threshold or except specific IP adresses from triggering this search.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Multiple Okta Users With Invalid Credentails From The Same IP - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Okta Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Multiple Okta Users With Invalid Credentails From The Same IP - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search detects Okta login failures due to bad credentials for multiple users originating from the same ip address.
action.notable.param.rule_title = Multiple Okta Users With Invalid Credentails From The Same IP
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `okta` outcome.reason=INVALID_CREDENTIALS | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | stats min(_time) as firstTime max(_time) as lastTime dc(user) as distinct_users values(user) as users by src_ip, displayMessage, outcome.reason, country, state, city  | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |  search distinct_users > 5| `multiple_okta_users_with_invalid_credentails_from_the_same_ip_filter` 

[ESCU - New container uploaded to AWS ECR - Rule]
action.escu = 0
action.escu.enabled = 1
description = This searches show information on uploaded containers including source user, image id, source IP user type, http user agent, region, first time, last time of operation (PutImage). These searches are based on Cloud Infrastructure Data Model.
action.escu.mappings = {"mitre_attack": ["T1525"]}
action.escu.data_models = []
action.escu.eli5 = This searches show information on uploaded containers including source user, image id, source IP user type, http user agent, region, first time, last time of operation (PutImage). These searches are based on Cloud Infrastructure Data Model.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You must also install Cloud Infrastructure data model. Please also customize the `container_implant_aws_detection_filter` macro to filter out the false positives.
action.escu.known_false_positives = Uploading container is a normal behavior from developers or users with access to container registry.
action.escu.creation_date = 2020-02-20
action.escu.modification_date = 2020-02-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - New container uploaded to AWS ECR - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Container Implantation Monitoring and Investigation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - New container uploaded to AWS ECR - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'src']
action.notable.param.rule_description = This searches show information on uploaded containers including source user, image id, source IP user type, http user agent, region, first time, last time of operation (PutImage). These searches are based on Cloud Infrastructure Data Model.
action.notable.param.rule_title = New container uploaded to AWS ECR
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Cloud_Infrastructure.Compute where Compute.user_type!="AssumeRole" AND Compute.http_user_agent="AWS Internal" AND Compute.event_name="PutImage" by Compute.image_id Compute.src_user Compute.src Compute.region Compute.msg Compute.user_type | `drop_dm_object_name("Compute")` | `new_container_uploaded_to_aws_ecr_filter` 

[ESCU - No Windows Updates in a time frame - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Windows endpoints that have not generated an event indicating a successful Windows update in the last 60 days. Windows updates are typically released monthly and applied shortly thereafter. An endpoint that has not successfully applied an update in this time frame indicates the endpoint is not regularly being patched for some reason.
action.escu.mappings = {"cis20": ["CIS 18"], "nist": ["PR.PT", "PR.MA"]}
action.escu.data_models = ["Updates"]
action.escu.eli5 = This search looks for Windows endpoints that have not generated an event indicating a successful Windows update in the last 60 days. Windows updates are typically released monthly and applied shortly thereafter. An endpoint that has not successfully applied an update in this time frame indicates the endpoint is not regularly being patched for some reason.
action.escu.how_to_implement = To successfully implement this search, it requires that the 'Update' data model is being populated. This can be accomplished by ingesting Windows events or the Windows Update log via a universal forwarder on the Windows endpoints you wish to monitor. The Windows add-on should be also be installed and configured to properly parse Windows events in Splunk. There may be other data sources which can populate this data model, including vulnerability management systems.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-09-15
action.escu.modification_date = 2017-09-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - No Windows Updates in a time frame - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Monitor for Updates"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - No Windows Updates in a time frame - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for Windows endpoints that have not generated an event indicating a successful Windows update in the last 60 days. Windows updates are typically released monthly and applied shortly thereafter. An endpoint that has not successfully applied an update in this time frame indicates the endpoint is not regularly being patched for some reason.
action.notable.param.rule_title = No Windows Updates in a time frame
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` max(_time) as lastTime from datamodel=Updates where Updates.status=Installed Updates.vendor_product="Microsoft Windows" by Updates.dest Updates.status Updates.vendor_product | rename Updates.dest as Host | rename Updates.status as "Update Status" | rename Updates.vendor_product as Product | eval isOutlier=if(lastTime <= relative_time(now(), "-60d@d"), 1, 0)  | `security_content_ctime(lastTime)`  | search isOutlier=1 | rename lastTime as "Last Update Time", | table Host, "Update Status", Product, "Last Update Time" | `no_windows_updates_in_a_time_frame_filter`

[ESCU - Okta Account Lockout Events - Rule]
action.escu = 0
action.escu.enabled = 1
description = Detect Okta user lockout events
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1078.001"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = Detect Okta user lockout events
action.escu.how_to_implement = This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.
action.escu.known_false_positives = None. Account lockouts should be followed up on to determine if the actual user was the one who caused the lockout, or if it was an unauthorized actor.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Okta Account Lockout Events - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Okta Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Okta Account Lockout Events - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = Detect Okta user lockout events
action.notable.param.rule_title = Okta Account Lockout Events
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `okta` displayMessage="Max sign in attempts exceeded" | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, country, state, city, src_ip | `okta_account_lockout_events_filter` 

[ESCU - Okta Failed SSO Attempts - Rule]
action.escu = 0
action.escu.enabled = 1
description = Detect failed Okta SSO events
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1078.001"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = Detect failed Okta SSO events
action.escu.how_to_implement = This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.
action.escu.known_false_positives = There may be a faulty config preventing legitmate users from accessing apps they should have access to.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Okta Failed SSO Attempts - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Okta Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Okta Failed SSO Attempts - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = Detect failed Okta SSO events
action.notable.param.rule_title = Okta Failed SSO Attempts
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `okta` displayMessage="User attempted unauthorized access to app" | stats  min(_time) as firstTime max(_time) as lastTime values(app) as Apps count by user, result ,displayMessage, src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `okta_failed_sso_attempts_filter` 

[ESCU - Okta User Logins From Multiple Cities - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects logins from the same user from different states in a 24 hour period.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1078.001"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects logins from the same user from different states in a 24 hour period.
action.escu.how_to_implement = This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.
action.escu.known_false_positives = Users in your enviornment may legitmately be travelling and loggin in from different locations. This search is useful for those users that should *not* be travelling for some reason, such as the COVID-19 pandemic. The search also relies on the geographical information being populated in the Okta logs. It is also possible that a connection from another region may be attributed to a login from a remote VPN endpoint.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Okta User Logins From Multiple Cities - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Okta Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Okta User Logins From Multiple Cities - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search detects logins from the same user from different states in a 24 hour period.
action.notable.param.rule_title = Okta User Logins From Multiple Cities
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `okta` displayMessage="User login to Okta" client.geographicalContext.city!=null | stats min(_time) as firstTime max(_time) as lastTime dc(client.geographicalContext.city) as locations values(client.geographicalContext.city) as cities values(client.geographicalContext.state) as states by user | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `okta_user_logins_from_multiple_cities_filter` | search locations > 1

[ESCU - Open Redirect in Splunk Web - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to look for evidence of exploitation for CVE-2016-4859, the Splunk Open Redirect Vulnerability.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 4", "CIS 18"], "kill_chain_phases": ["Delivery"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.AC", "PR.IP", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search allows you to look for evidence of exploitation for CVE-2016-4859, the Splunk Open Redirect Vulnerability.
action.escu.how_to_implement = No extra steps needed to implement this search.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-09-19
action.escu.modification_date = 2017-09-19
action.escu.confidence = high
action.escu.full_search_name = ESCU - Open Redirect in Splunk Web - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Splunk Enterprise Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Open Redirect in Splunk Web - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search allows you to look for evidence of exploitation for CVE-2016-4859, the Splunk Open Redirect Vulnerability.
action.notable.param.rule_title = Open Redirect in Splunk Web
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = index=_internal sourcetype=splunk_web_access return_to="/%09/*" | `open_redirect_in_splunk_web_filter`

[ESCU - Osquery pack - ColdRoot detection - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for ColdRoot events from the osx-attacks osquery pack.
action.escu.mappings = {"cis20": ["CIS 4", "CIS 8"], "kill_chain_phases": ["Installation", "Command and Control"], "nist": ["DE.DP", "DE.CM", "PR.PT"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for ColdRoot events from the osx-attacks osquery pack.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model
action.escu.known_false_positives = There are no known false positives.
action.escu.creation_date = 2019-01-29
action.escu.modification_date = 2019-01-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Osquery pack - ColdRoot detection - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["ColdRoot MacOS RAT"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Osquery pack - ColdRoot detection - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for ColdRoot events from the osx-attacks osquery pack.
action.notable.param.rule_title = Osquery pack - ColdRoot detection
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | from datamodel Alerts.Alerts | search app=osquery:results (name=pack_osx-attacks_OSX_ColdRoot_RAT_Launchd OR name=pack_osx-attacks_OSX_ColdRoot_RAT_Files) | rename columns.path as path | bucket _time span=30s | stats count(path) by _time, host, user, path | `osquery_pack___coldroot_detection_filter`

[ESCU - Overwriting Accessibility Binaries - Rule]
action.escu = 0
action.escu.enabled = 1
description = Microsoft Windows contains accessibility features that can be launched with a key combination before a user has logged in. An adversary can modify or replace these programs so they can get a command prompt or backdoor without logging in to the system. This search looks for modifications to these binaries.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1546.008"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Microsoft Windows contains accessibility features that can be launched with a key combination before a user has logged in. An adversary can modify or replace these programs so they can get a command prompt or backdoor without logging in to the system. This search looks for modifications to these binaries.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Microsoft may provide updates to these binaries. Verify that these changes do not correspond with your normal software update cycle.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Overwriting Accessibility Binaries - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Overwriting Accessibility Binaries - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Microsoft Windows contains accessibility features that can be launched with a key combination before a user has logged in. An adversary can modify or replace these programs so they can get a command prompt or backdoor without logging in to the system. This search looks for modifications to these binaries.
action.notable.param.rule_title = Overwriting Accessibility Binaries
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem where (Filesystem.file_path=*\\Windows\\System32\\sethc.exe* OR Filesystem.file_path=*\\Windows\\System32\\utilman.exe* OR Filesystem.file_path=*\\Windows\\System32\\osk.exe* OR Filesystem.file_path=*\\Windows\\System32\\Magnify.exe* OR Filesystem.file_path=*\\Windows\\System32\\Narrator.exe* OR Filesystem.file_path=*\\Windows\\System32\\DisplaySwitch.exe* OR Filesystem.file_path=*\\Windows\\System32\\AtBroker.exe*) by Filesystem.file_name Filesystem.dest | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `overwriting_accessibility_binaries_filter`

[ESCU - Process Execution via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched via WMI.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1047"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for processes launched via WMI.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Although unlikely, administrators may use wmi to execute commands for legitimate purposes.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Process Execution via WMI - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Process Execution via WMI - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for processes launched via WMI.
action.notable.param.rule_title = Process Execution via WMI
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.parent_process_name = *WmiPrvSE.exe by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `process_execution_via_wmi_filter` 

[ESCU - Processes Tapping Keyboard Events - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes in an MacOS system that is tapping keyboard events in MacOS, and essentially monitoring all keystrokes made by a user. This is a common technique used by RATs to log keystrokes from a victim, although it can also be used by legitimate processes like Siri to react on human input
action.escu.mappings = {"cis20": ["CIS 4", "CIS 8"], "kill_chain_phases": ["Command and Control"], "nist": ["DE.DP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for processes in an MacOS system that is tapping keyboard events in MacOS, and essentially monitoring all keystrokes made by a user. This is a common technique used by RATs to log keystrokes from a victim, although it can also be used by legitimate processes like Siri to react on human input
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model.
action.escu.known_false_positives = There might be some false positives as keyboard event taps are used by processes like Siri and Zoom video chat, for some good examples of processes to exclude please see [this](https://github.com/facebook/osquery/pull/5345#issuecomment-454639161) comment.
action.escu.creation_date = 2019-01-25
action.escu.modification_date = 2019-01-25
action.escu.confidence = high
action.escu.full_search_name = ESCU - Processes Tapping Keyboard Events - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["ColdRoot MacOS RAT"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Processes Tapping Keyboard Events - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for processes in an MacOS system that is tapping keyboard events in MacOS, and essentially monitoring all keystrokes made by a user. This is a common technique used by RATs to log keystrokes from a victim, although it can also be used by legitimate processes like Siri to react on human input
action.notable.param.rule_title = Processes Tapping Keyboard Events
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | from datamodel Alerts.Alerts | search app=osquery:results name=pack_osx-attacks_Keyboard_Event_Taps | rename columns.cmdline as cmd, columns.name as process_name, columns.pid as process_id| dedup host,process_name | table host,process_name, cmd, process_id | `processes_tapping_keyboard_events_filter`

[ESCU - Processes created by netsh - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launching netsh.exe to execute various commands via the netsh command-line utility. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper .dll when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe that are executing commands via the command line.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1059.001", "T1059.003"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for processes launching netsh.exe to execute various commands via the netsh command-line utility. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper .dll when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe that are executing commands via the command line.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting logs with the process name, command-line arguments, and parent processes from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = It is unusual for netsh.exe to have any child processes in most environments. It makes sense to investigate the child process and verify whether the process spawned is legitimate. We explicitely exclude "C:\Program Files\rempl\sedlauncher.exe" process path since it is a legitimate process by Mircosoft.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Processes created by netsh - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Netsh Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Processes created by netsh - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for processes launching netsh.exe to execute various commands via the netsh command-line utility. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper .dll when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe that are executing commands via the command line.
action.notable.param.rule_title = Processes created by netsh
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.parent_process="*C:\\Windows\\System32\\netsh.exe*" AND Processes.process_path!="C:\\Program Files\\rempl\\sedlauncher.exe") by Processes.user Processes.dest Processes.parent_process Processes.parent_process_name Processes.process_name | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `processes_created_by_netsh_filter`

[ESCU - Processes launching netsh - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launching netsh.exe. Netsh is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via the command line.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.004"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for processes launching netsh.exe. Netsh is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via the command line.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model
action.escu.known_false_positives = Some VPN applications are known to launch netsh.exe. Outside of these instances, it is unusual for an executable to launch netsh.exe and run commands.
action.escu.creation_date = 2020-07-10
action.escu.modification_date = 2020-07-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Processes launching netsh - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Netsh Abuse", "Disabling Security Tools", "DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Processes launching netsh - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for processes launching netsh.exe. Netsh is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via the command line.
action.notable.param.rule_title = Processes launching netsh
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) AS Processes.process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=netsh.exe by Processes.parent_process_name Processes.parent_process Processes.process_name Processes.user Processes.dest |`drop_dm_object_name("Processes")` |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`processes_launching_netsh_filter`

[ESCU - Prohibited Network Traffic Allowed - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic defined by port and transport layer protocol in the Enterprise Security lookup table "lookup_interesting_ports", that is marked as prohibited, and has an associated 'allow' action in the Network_Traffic data model. This could be indicative of a misconfigured network device.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Delivery", "Command and Control"], "mitre_attack": ["T1048"], "nist": ["DE.AE", "PR.AC"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for network traffic defined by port and transport layer protocol in the Enterprise Security lookup table "lookup_interesting_ports", that is marked as prohibited, and has an associated 'allow' action in the Network_Traffic data model. This could be indicative of a misconfigured network device.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Prohibited Network Traffic Allowed - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Prohibited Network Traffic Allowed - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for network traffic defined by port and transport layer protocol in the Enterprise Security lookup table "lookup_interesting_ports", that is marked as prohibited, and has an associated 'allow' action in the Network_Traffic data model. This could be indicative of a misconfigured network device.
action.notable.param.rule_title = Prohibited Network Traffic Allowed
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.action = allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | lookup update=true interesting_ports_lookup dest_port as All_Traffic.dest_port OUTPUT app is_prohibited note transport | search is_prohibited=true | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `prohibited_network_traffic_allowed_filter`

[ESCU - Prohibited Software On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for applications on the endpoint that you have marked as prohibited.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for applications on the endpoint that you have marked as prohibited.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report process tracking in your Windows audit settings. In addition, you must also have only the `process_name` (not the entire process path) marked as "prohibited" in the Enterprise Security `interesting processes` table. To include the process names marked as "prohibited", which is included with ES Content Updates, run the included search <code>Add Prohibited Processes to Enterprise Security</code>.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2019-10-11
action.escu.modification_date = 2019-10-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Prohibited Software On Endpoint - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Monitor for Unauthorized Software", "Emotet Malware  DHS Report TA18-201A ", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Prohibited Software On Endpoint - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for applications on the endpoint that you have marked as prohibited.
action.notable.param.rule_title = Prohibited Software On Endpoint
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `prohibited_softwares` | `prohibited_software_on_endpoint_filter`

[ESCU - Protocol or Port Mismatch - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic on common ports where a higher layer protocol does not match the port that is being used. For example, this search should identify cases where protocols other than HTTP are running on TCP port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications over ports and protocols that are typically allowed and not well inspected.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1048.003"], "nist": ["DE.AE", "PR.AC"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for network traffic on common ports where a higher layer protocol does not match the port that is being used. For example, this search should identify cases where protocols other than HTTP are running on TCP port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications over ports and protocols that are typically allowed and not well inspected.
action.escu.how_to_implement = Running this search properly requires a technology that can inspect network traffic and identify common protocols. Technologies such as Bro and Palo Alto Networks firewalls are two examples that will identify protocols via inspection, and not just assume a specific protocol based on the transport protocol and ports.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Protocol or Port Mismatch - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Protocol or Port Mismatch - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for network traffic on common ports where a higher layer protocol does not match the port that is being used. For example, this search should identify cases where protocols other than HTTP are running on TCP port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications over ports and protocols that are typically allowed and not well inspected.
action.notable.param.rule_title = Protocol or Port Mismatch
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where (All_Traffic.app=dns NOT All_Traffic.dest_port=53) OR ((All_Traffic.app=web-browsing OR All_Traffic.app=http) NOT (All_Traffic.dest_port=80 OR All_Traffic.dest_port=8080 OR All_Traffic.dest_port=8000)) OR (All_Traffic.app=ssl NOT (All_Traffic.dest_port=443 OR All_Traffic.dest_port=8443)) OR (All_Traffic.app=smtp NOT All_Traffic.dest_port=25) by All_Traffic.src_ip, All_Traffic.dest_ip, All_Traffic.app, All_Traffic.dest_port |`security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `protocol_or_port_mismatch_filter`

[ESCU - Protocols passing authentication in cleartext - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cleartext protocols at risk of leaking credentials. Currently, this consists of legacy protocols such as telnet, POP3, IMAP, and non-anonymous FTP sessions. While some of these protocols can be used over SSL, they typically run on different assigned ports in those cases.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 14"], "kill_chain_phases": ["Reconnaissance", "Actions on Objectives"], "nist": ["PR.PT", "DE.AE", "PR.AC", "PR.DS"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for cleartext protocols at risk of leaking credentials. Currently, this consists of legacy protocols such as telnet, POP3, IMAP, and non-anonymous FTP sessions. While some of these protocols can be used over SSL, they typically run on different assigned ports in those cases.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic, and populating the Network_Traffic data model.
action.escu.known_false_positives = Some networks may use kerberized FTP or telnet servers, however, this is rare.
action.escu.creation_date = 2017-09-15
action.escu.modification_date = 2017-09-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Protocols passing authentication in cleartext - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Use of Cleartext Protocols"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Protocols passing authentication in cleartext - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest', 'src']
action.notable.param.rule_description = This search looks for cleartext protocols at risk of leaking credentials. Currently, this consists of legacy protocols such as telnet, POP3, IMAP, and non-anonymous FTP sessions. While some of these protocols can be used over SSL, they typically run on different assigned ports in those cases.
action.notable.param.rule_title = Protocols passing authentication in cleartext
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.protocol="tcp" AND (All_Traffic.dest_port="23" OR All_Traffic.dest_port="143" OR All_Traffic.dest_port="110" OR (All_Traffic.dest_port="21" AND All_Traffic.user != "anonymous")) groupby All_Traffic.user All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `protocols_passing_authentication_in_cleartext_filter`

[ESCU - Reg exe Manipulating Windows Services Registry Keys - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for reg.exe modifying registry keys that define Windows services and their configurations.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation"], "mitre_attack": ["T1547.001"], "nist": ["PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for reg.exe modifying registry keys that define Windows services and their configurations.
action.escu.how_to_implement = none
action.escu.known_false_positives = It is unusual for a service to be created or modified by directly manipulating the registry. However, there may be legitimate instances of this behavior. It is important to validate and investigate, as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Reg exe Manipulating Windows Services Registry Keys - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Service Abuse", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Reg exe Manipulating Windows Services Registry Keys - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The search looks for reg.exe modifying registry keys that define Windows services and their configurations.
action.notable.param.rule_title = Reg exe Manipulating Windows Services Registry Keys
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name values(Processes.user) as user FROM datamodel=Endpoint.Processes where Processes.process_name=reg.exe Processes.process=*reg* Processes.process=*add* Processes.process=*Services* by Processes.process_id Processes.dest Processes.process | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `reg_exe_manipulating_windows_services_registry_keys_filter`

[ESCU - Reg exe used to hide files directories via registry keys - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for command-line arguments used to hide a file or directory using the reg add command.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for command-line arguments used to hide a file or directory using the reg add command.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None at the moment
action.escu.creation_date = 2019-02-27
action.escu.modification_date = 2019-02-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - Reg exe used to hide files directories via registry keys - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Reg exe used to hide files directories via registry keys - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search looks for command-line arguments used to hide a file or directory using the reg add command.
action.notable.param.rule_title = Reg exe used to hide files directories via registry keys
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = reg.exe Processes.process="*add*" Processes.process="*Hidden*" Processes.process="*REG_DWORD*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)`| regex process = "(/d\s+2)" | `reg_exe_used_to_hide_files_directories_via_registry_keys_filter`

[ESCU - Registry Keys Used For Persistence - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to registry keys that can be used to launch an application or service at system startup.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1547.001"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for modifications to registry keys that can be used to launch an application or service at system startup.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that must execute on system startup and will use these registry keys to accomplish that task.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Registry Keys Used For Persistence - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Suspicious MSHTA Activity", "DHS Report TA18-074A", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Windows Persistence Techniques", "Emotet Malware  DHS Report TA18-201A "]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Registry Keys Used For Persistence - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The search looks for modifications to registry keys that can be used to launch an application or service at system startup.
action.notable.param.rule_title = Registry Keys Used For Persistence
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path=*currentversion\\run* OR Registry.registry_path=*currentVersion\\Windows\\Appinit_Dlls* OR Registry.registry_path=CurrentVersion\\Winlogon\\Shell* OR Registry.registry_path=*CurrentVersion\\Winlogon\\Userinit* OR Registry.registry_path=*CurrentVersion\\Winlogon\\VmApplet* OR Registry.registry_path=*currentversion\\policies\\explorer\\run* OR Registry.registry_path=*currentversion\\runservices* OR Registry.registry_path=*\\CurrentControlSet\\Control\\Lsa\\* OR Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*" OR Registry.registry_path=HKLM\\SOFTWARE\\Microsoft\\Netsh\\*) by Registry.dest , Registry.status, Registry.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)` | `registry_keys_used_for_persistence_filter`

[ESCU - Registry Keys Used For Privilege Escalation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for modifications to registry keys that can be used to elevate privileges. The registry keys under "Image File Execution Options" are used to intercept calls to an executable and can be used to attach malicious binaries to benign system binaries.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1547.001"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for modifications to registry keys that can be used to elevate privileges. The registry keys under "Image File Execution Options" are used to intercept calls to an executable and can be used to attach malicious binaries to benign system binaries.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that must execute upon system startup and will use these registry keys to accomplish that task.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Registry Keys Used For Privilege Escalation - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Privilege Escalation", "Suspicious Windows Registry Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Registry Keys Used For Privilege Escalation - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for modifications to registry keys that can be used to elevate privileges. The registry keys under "Image File Execution Options" are used to intercept calls to an executable and can be used to attach malicious binaries to benign system binaries.
action.notable.param.rule_title = Registry Keys Used For Privilege Escalation
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*") AND (Registry.registry_key_name=GlobalFlag OR Registry.registry_key_name=Debugger) by Registry.dest  Registry.user | `security_content_ctime(lastTime)`  | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)` | `registry_keys_used_for_privilege_escalation_filter`

[ESCU - Registry Keys for Creating SHIM Databases - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for registry activity associated with application compatibility shims, which can be leveraged by attackers for various nefarious purposes.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1546.011"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for registry activity associated with application compatibility shims, which can be leveraged by attackers for various nefarious purposes.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that leverage shim databases for compatibility purposes for legacy applications
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Registry Keys for Creating SHIM Databases - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Registry Keys for Creating SHIM Databases - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for registry activity associated with application compatibility shims, which can be leveraged by attackers for various nefarious purposes.
action.notable.param.rule_title = Registry Keys for Creating SHIM Databases
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\Custom*" OR All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\InstalledSDB*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `drop_dm_object_name("All_Changes")` | `registry_keys_for_creating_shim_databases_filter`

[ESCU - Remote Desktop Network Bruteforce - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for RDP application network traffic and filters any source/destination pair generating more than twice the standard deviation of the average traffic.
action.escu.mappings = {"cis20": ["CIS 12", "CIS 9", "CIS 16"], "kill_chain_phases": ["Reconnaissance", "Delivery"], "mitre_attack": ["T1021.001"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for RDP application network traffic and filters any source/destination pair generating more than twice the standard deviation of the average traffic.
action.escu.how_to_implement = You must ensure that your network traffic data is populating the Network_Traffic data model.
action.escu.known_false_positives = RDP gateways may have unusually high amounts of traffic from all other hosts' RDP applications in the network.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Remote Desktop Network Bruteforce - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Remote Desktop Network Bruteforce - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search looks for RDP application network traffic and filters any source/destination pair generating more than twice the standard deviation of the average traffic.
action.notable.param.rule_title = Remote Desktop Network Bruteforce
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=rdp by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | eventstats stdev(count) AS stdev avg(count) AS avg p50(count) AS p50 | where count>(avg + stdev*2) | rename All_Traffic.src AS src All_Traffic.dest AS dest | table firstTime lastTime src dest count avg p50 stdev | `remote_desktop_network_bruteforce_filter`

[ESCU - Remote Desktop Network Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic on TCP/3389, the default port used by remote desktop. While remote desktop traffic is not uncommon on a network, it is usually associated with known hosts. This search allows for whitelisting both source and destination hosts to remove them from the output of the search so you can focus on the uncommon uses of remote desktop on your network.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 9", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1021.001"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for network traffic on TCP/3389, the default port used by remote desktop. While remote desktop traffic is not uncommon on a network, it is usually associated with known hosts. This search allows for whitelisting both source and destination hosts to remove them from the output of the search so you can focus on the uncommon uses of remote desktop on your network.
action.escu.how_to_implement = To successfully implement this search you need to identify systems that commonly originate remote desktop traffic and that commonly receive remote desktop traffic. You can use the included support search "Identify Systems Creating Remote Desktop Traffic" to identify systems that originate the traffic and the search "Identify Systems Receiving Remote Desktop Traffic" to identify systems that receive a lot of remote desktop traffic. After identifying these systems, you will need to add the "common_rdp_source" or "common_rdp_destination" category to that system depending on the usage, using the Enterprise Security Assets and Identities framework.  This can be done by adding an entry in the assets.csv file located in SA-IdentityManagement/lookups.
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.creation_date = 2020-07-07
action.escu.modification_date = 2020-07-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Remote Desktop Network Traffic - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware", "Hidden Cobra Malware", "Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Remote Desktop Network Traffic - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search looks for network traffic on TCP/3389, the default port used by remote desktop. While remote desktop traffic is not uncommon on a network, it is usually associated with known hosts. This search allows for whitelisting both source and destination hosts to remove them from the output of the search so you can focus on the uncommon uses of remote desktop on your network.
action.notable.param.rule_title = Remote Desktop Network Traffic
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.dest_port=3389 AND All_Traffic.dest_category!=common_rdp_destination AND All_Traffic.src_category!=common_rdp_source by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `remote_desktop_network_traffic_filter` 

[ESCU - Remote Desktop Process Running On System - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the remote desktop process mstsc.exe running on systems upon which it doesn't typically run. This is accomplished by filtering out all systems that are noted in the `common_rdp_source category` in the Assets and Identity framework.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 9", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1021.001"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the remote desktop process mstsc.exe running on systems upon which it doesn't typically run. This is accomplished by filtering out all systems that are noted in the `common_rdp_source category` in the Assets and Identity framework.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. The search requires you to identify systems that do not commonly use remote desktop. You can use the included support search "Identify Systems Using Remote Desktop" to identify these systems. After identifying them, you will need to add the "common_rdp_source" category to that system using the Enterprise Security Assets and Identities framework. This can be done by adding an entry in the assets.csv file located in `SA-IdentityManagement/lookups`.
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Remote Desktop Process Running On System - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Remote Desktop Process Running On System - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for the remote desktop process mstsc.exe running on systems upon which it doesn't typically run. This is accomplished by filtering out all systems that are noted in the `common_rdp_source category` in the Assets and Identity framework.
action.notable.param.rule_title = Remote Desktop Process Running On System
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process=*mstsc.exe AND Processes.dest_category!=common_rdp_source by Processes.dest Processes.user Processes.process | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `remote_desktop_process_running_on_system_filter` 

[ESCU - Remote Process Instantiation via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1021.001"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = The wmic.exe utility is a benign Windows application. It may be used legitimately by Administrators with these parameters for remote system administration, but it's relatively uncommon.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Remote Process Instantiation via WMI - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Remote Process Instantiation via WMI - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
action.notable.param.rule_title = Remote Process Instantiation via WMI
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wmic.exe Processes.process="*/node*" Processes.process="*process*" Processes.process="*call*" Processes.process="*create*"   by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `remote_process_instantiation_via_wmi_filter`

[ESCU - Remote Registry Key modifications - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search monitors for remote modifications to registry keys.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search monitors for remote modifications to registry keys.
action.escu.how_to_implement = To successfully implement this search, you must populate the `Endpoint` data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = This technique may be legitimately used by administrators to modify remote registries, so it's important to filter these events out.
action.escu.creation_date = 2020-03-02
action.escu.modification_date = 2020-03-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Remote Registry Key modifications - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Remote Registry Key modifications - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search monitors for remote modifications to registry keys.
action.notable.param.rule_title = Remote Registry Key modifications
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where  Registry.registry_path="\\\\*"  by Registry.dest , Registry.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)` | `remote_registry_key_modifications_filter`

[ESCU - Remote WMI Command Attempt - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for wmic.exe being launched with parameters to operate on remote systems.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1047"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for wmic.exe being launched with parameters to operate on remote systems.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators may use this legitimately to gather info from remote systems.
action.escu.creation_date = 2018-12-03
action.escu.modification_date = 2018-12-03
action.escu.confidence = high
action.escu.full_search_name = ESCU - Remote WMI Command Attempt - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Remote WMI Command Attempt - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for wmic.exe being launched with parameters to operate on remote systems.
action.notable.param.rule_title = Remote WMI Command Attempt
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=wmic.exe  AND Processes.process= */node* by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `remote_wmi_command_attempt_filter`

[ESCU - RunDLL Loading DLL By Ordinal - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2. Calling exported functions by ordinal is not as common as calling by exported name. There was a bug fixed in IDAPro on 2016-08-08 that would not display functions without names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Installation"], "mitre_attack": ["T1218.011"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2. Calling exported functions by ordinal is not as common as calling by exported name. There was a bug fixed in IDAPro on 2016-08-08 that would not display functions without names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = While not common, loading a DLL under %AppData% and calling a function by ordinal is possible by a legitimate process
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - RunDLL Loading DLL By Ordinal - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - RunDLL Loading DLL By Ordinal - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2. Calling exported functions by ordinal is not as common as calling by exported name. There was a bug fixed in IDAPro on 2016-08-08 that would not display functions without names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
action.notable.param.rule_title = RunDLL Loading DLL By Ordinal
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = rundll32.exe Processes.process="*AppData*" Processes.process="*,#2" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `rundll_loading_dll_by_ordinal_filter`

[ESCU - SMB Traffic Spike - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for spikes in the number of Server Message Block (SMB) traffic connections.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1021.002"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for spikes in the number of Server Message Block (SMB) traffic connections.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic logs and populating the `Network_Traffic` data model.
action.escu.known_false_positives = A file server may experience high-demand loads that could cause this analytic to trigger.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - SMB Traffic Spike - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Ransomware", "DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - SMB Traffic Spike - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['src']
action.notable.param.rule_description = This search looks for spikes in the number of Server Message Block (SMB) traffic connections.
action.notable.param.rule_title = SMB Traffic Spike
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | `drop_dm_object_name("All_Traffic")` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-70m@m"), count, null))) as count avg(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as stdev by src | eval upperBound=(avg+stdev*2), isOutlier=if(count > upperBound AND num_data_samples >=50, 1, 0) | where isOutlier=1 | table src count | `smb_traffic_spike_filter` 

[ESCU - SMB Traffic Spike - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search uses the Machine Learning Toolkit (MLTK) to identify spikes in the number of Server Message Block (SMB) connections.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1021.002"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search uses the Machine Learning Toolkit (MLTK) to identify spikes in the number of Server Message Block (SMB) connections.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, the Machine Learning Toolkit (MLTK) version 4.2 or greater must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of SMB Traffic - MLTK" must be executed before this detection search, because it builds a machine-learning (ML) model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.\
This search produces a field (Number of events,count) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. This field contributes additional context to the notable. To see the additional metadata, add the following field, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry): \
1. **Label:** Number of events, **Field:** count\
Detailed documentation on how to create a new field within Incident Review is found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = If you are seeing more results than desired, you may consider reducing the value of the threshold in the search. You should also periodically re-run the support search to re-build the ML model on the latest data. Please update the `smb_traffic_spike_mltk_filter` macro to filter out false positive results
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - SMB Traffic Spike - MLTK - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Ransomware", "DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - SMB Traffic Spike - MLTK - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search uses the Machine Learning Toolkit (MLTK) to identify spikes in the number of Server Message Block (SMB) connections.
action.notable.param.rule_title = SMB Traffic Spike - MLTK
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(All_Traffic.dest_ip) as dest values(All_Traffic.dest_port) as port from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | eval HourOfDay=strftime(_time, "%H") | eval DayOfWeek=strftime(_time, "%A") | `drop_dm_object_name(All_Traffic)` | apply smb_pdfmodel threshold=0.001 | rename "IsOutlier(count)" as isOutlier | search isOutlier > 0 | sort -count | table _time src dest port count | `smb_traffic_spike___mltk_filter` 

[ESCU - SQL Injection with Long URLs - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for long URLs that have several SQL commands visible within them.
action.escu.mappings = {"cis20": ["CIS 4", "CIS 13", "CIS 18"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["T1190"], "nist": ["PR.DS", "ID.RA", "PR.PT", "PR.IP", "DE.CM"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for long URLs that have several SQL commands visible within them.
action.escu.how_to_implement = To successfully implement this search, you need to be monitoring network communications to your web servers or ingesting your HTTP logs and populating the Web data model. You must also identify your web servers in the Enterprise Security assets table.
action.escu.known_false_positives = It's possible that legitimate traffic will have long URLs or long user agent strings and that common SQL commands may be found within the URL. Please investigate as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - SQL Injection with Long URLs - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SQL Injection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - SQL Injection with Long URLs - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search looks for long URLs that have several SQL commands visible within them.
action.notable.param.rule_title = SQL Injection with Long URLs
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Web where Web.dest_category=web_server AND (Web.url_length > 1024 OR Web.http_user_agent_length > 200) by Web.src Web.dest Web.url Web.url_length Web.http_user_agent | `drop_dm_object_name("Web")` | eval num_sql_cmds=mvcount(split(url, "alter%20table")) + mvcount(split(url, "between")) + mvcount(split(url, "create%20table")) + mvcount(split(url, "create%20database")) + mvcount(split(url, "create%20index")) + mvcount(split(url, "create%20view")) + mvcount(split(url, "delete")) + mvcount(split(url, "drop%20database")) + mvcount(split(url, "drop%20index")) + mvcount(split(url, "drop%20table")) + mvcount(split(url, "exists")) + mvcount(split(url, "exec")) + mvcount(split(url, "group%20by")) + mvcount(split(url, "having")) + mvcount(split(url, "insert%20into")) + mvcount(split(url, "inner%20join")) + mvcount(split(url, "left%20join")) + mvcount(split(url, "right%20join")) + mvcount(split(url, "full%20join")) + mvcount(split(url, "select")) + mvcount(split(url, "distinct")) + mvcount(split(url, "select%20top")) + mvcount(split(url, "union")) + mvcount(split(url, "xp_cmdshell")) - 24 | where num_sql_cmds > 3 | `sql_injection_with_long_urls_filter`

[ESCU - Samsam Test File Write - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a file named "test.txt" written to the windows system directory tree, which is consistent with Samsam propagation.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Delivery"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for a file named "test.txt" written to the windows system directory tree, which is consistent with Samsam propagation.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = No false positives have been identified.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - Samsam Test File Write - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Samsam Test File Write - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The search looks for a file named "test.txt" written to the windows system directory tree, which is consistent with Samsam propagation.
action.notable.param.rule_title = Samsam Test File Write
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name from datamodel=Endpoint.Filesystem where Filesystem.file_path=*\\windows\\system32\\test.txt by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `samsam_test_file_write_filter`

[ESCU - Sc exe Manipulating Windows Services - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation"], "mitre_attack": ["T1543.003"], "nist": ["PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
action.escu.how_to_implement = none
action.escu.known_false_positives = Using sc.exe to manipulate Windows services is uncommon. However, there may be legitimate instances of this behavior. It is important to validate and investigate as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Sc exe Manipulating Windows Services - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Service Abuse", "DHS Report TA18-074A", "Orangeworm Attack Group", "Windows Persistence Techniques", "Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Sc exe Manipulating Windows Services - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
action.notable.param.rule_title = Sc exe Manipulating Windows Services
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sc.exe (Processes.process="* create *" OR Processes.process="* config *") by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `sc_exe_manipulating_windows_services_filter`

[ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a task name associated with the Dragonfly threat actor was created or deleted.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1053.005"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for flags passed to schtasks.exe on the command-line that indicate a task name associated with the Dragonfly threat actor was created or deleted.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = No known false positives
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate a task name associated with the Dragonfly threat actor was created or deleted.
action.notable.param.rule_title = Scheduled Task Name Used by Dragonfly Threat Actors
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search (process=*delete* OR process=*create*) process=*reset* | `scheduled_task_name_used_by_dragonfly_threat_actors_filter` 

[ESCU - Scheduled tasks used in BadRabbit ransomware - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names related to the execution of Bad Rabbit ransomware were created or deleted.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1053.005"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names related to the execution of Bad Rabbit ransomware were created or deleted.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = No known false positives
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Scheduled tasks used in BadRabbit ransomware - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Scheduled tasks used in BadRabbit ransomware - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names related to the execution of Bad Rabbit ransomware were created or deleted.
action.notable.param.rule_title = Scheduled tasks used in BadRabbit ransomware
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process) as process  from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe (Processes.process= "*create*"  OR Processes.process= "*delete*") by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | search (process=*rhaegal* OR process=*drogon* OR *viserion_*) | `scheduled_tasks_used_in_badrabbit_ransomware_filter`

[ESCU - Schtasks scheduling job on remote system - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1053.005"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators may create jobs on remote systems, but this activity is usually limited to a small set of hosts or users. It is important to validate and investigate as appropriate.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Schtasks scheduling job on remote system - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Schtasks scheduling job on remote system - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
action.notable.param.rule_title = Schtasks scheduling job on remote system
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*/create*" Processes.process="* /s *" by Processes.process_name Processes.process Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `schtasks_scheduling_job_on_remote_system_filter`

[ESCU - Schtasks used for forcing a reboot - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that a forced reboot of system is scheduled.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1053.005"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for flags passed to schtasks.exe on the command-line that indicate that a forced reboot of system is scheduled.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Administrators may create jobs on systems forcing reboots to perform updates, maintenance, etc.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Schtasks used for forcing a reboot - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Persistence Techniques", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Schtasks used for forcing a reboot - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate that a forced reboot of system is scheduled.
action.notable.param.rule_title = Schtasks used for forcing a reboot
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*shutdown*" Processes.process="*/r*" Processes.process="*/f*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `schtasks_used_for_forcing_a_reboot_filter`

[ESCU - Script Execution via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for scripts launched via WMI.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1047"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for scripts launched via WMI.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Although unlikely, administrators may use wmi to launch scripts for legitimate purposes.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Script Execution via WMI - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Script Execution via WMI - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for scripts launched via WMI.
action.notable.param.rule_title = Script Execution via WMI
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = "scrcons.exe" by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `script_execution_via_wmi_filter` 

[ESCU - Shim Database File Creation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for shim database files being written to default directories. The sdbinst.exe application is used to install shim database files (.sdb). According to Microsoft, a shim is a small library that transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1546.011"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for shim database files being written to default directories. The sdbinst.exe application is used to install shim database files (.sdb). According to Microsoft, a shim is a small library that transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Because legitimate shim files are created and used all the time, this event, in itself, is not suspicious. However, if there are other correlating events, it may warrant further investigation.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Shim Database File Creation - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Shim Database File Creation - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for shim database files being written to default directories. The sdbinst.exe application is used to install shim database files (.sdb). According to Microsoft, a shim is a small library that transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.notable.param.rule_title = Shim Database File Creation
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Filesystem.action) values(Filesystem.file_hash) as file_hash values(Filesystem.file_path) as file_path  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_path=*Windows\AppPatch\Custom* by Filesystem.file_name Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` |`drop_dm_object_name(Filesystem)` | `shim_database_file_creation_filter`

[ESCU - Shim Database Installation With Suspicious Parameters - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the process execution and arguments required to silently create a shim database.  The sdbinst.exe application is used to install shim database files (.sdb). A shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1546.011"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search detects the process execution and arguments required to silently create a shim database.  The sdbinst.exe application is used to install shim database files (.sdb). A shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Shim Database Installation With Suspicious Parameters - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Shim Database Installation With Suspicious Parameters - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search detects the process execution and arguments required to silently create a shim database.  The sdbinst.exe application is used to install shim database files (.sdb). A shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.notable.param.rule_title = Shim Database Installation With Suspicious Parameters
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sdbinst.exe Processes.process="*-p*" Processes.process="*-q*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `shim_database_installation_with_suspicious_parameters_filter`

[ESCU - Short Lived Windows Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects accounts that were created and deleted in a short time period.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["T1136.001"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search detects accounts that were created and deleted in a short time period.
action.escu.how_to_implement = This search requires you to have enabled your Group Management Audit Logs in your Local Windows Security Policy and be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/
action.escu.known_false_positives = It is possible that an administrator created and deleted an account in a short time period.  Verifying activity with an administrator is advised.
action.escu.creation_date = 2020-07-06
action.escu.modification_date = 2020-07-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Short Lived Windows Accounts - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Short Lived Windows Accounts - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search detects accounts that were created and deleted in a short time period.
action.notable.param.rule_title = Short Lived Windows Accounts
action.notable.param.security_domain = access
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(All_Changes.result_id) as result_id count min(_time) as firstTime max(_time) as lastTime from datamodel=Change where All_Changes.result_id=4720 OR All_Changes.result_id=4726 by _time span=4h All_Changes.user All_Changes.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("All_Changes")` | search result_id = 4720 result_id=4726 | transaction user connected=false maxspan=240m | table firstTime lastTime count user dest result_id | `short_lived_windows_accounts_filter`

[ESCU - Single Letter Process On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for process names that consist only of a single letter.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for process names that consist only of a single letter.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Single-letter executables are not always malicious. Investigate this activity with your normal incident-response process.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Single Letter Process On Endpoint - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Single Letter Process On Endpoint - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for process names that consist only of a single letter.
action.notable.param.rule_title = Single Letter Process On Endpoint
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest, Processes.user, Processes.process, Processes.process_name | `drop_dm_object_name(Processes)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | eval process_name_length = len(process_name), endExe = if(substr(process_name, -4) == ".exe", 1, 0) | search process_name_length=5 AND endExe=1 | table count, firstTime, lastTime, dest, user, process, process_name | `single_letter_process_on_endpoint_filter`

[ESCU - Spectre and Meltdown Vulnerable Systems - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to detect systems that are still vulnerable to the Spectre and Meltdown vulnerabilities.
action.escu.mappings = {"cis20": ["CIS 4"], "nist": ["ID.RA", "RS.MI", "PR.IP", "DE.CM"]}
action.escu.data_models = ["Vulnerabilities"]
action.escu.eli5 = The search is used to detect systems that are still vulnerable to the Spectre and Meltdown vulnerabilities.
action.escu.how_to_implement = The search requires that you are ingesting your vulnerability-scanner data and that it reports the CVE of the vulnerability identified.
action.escu.known_false_positives = It is possible that your vulnerability scanner is not detecting that the patches have been applied.
action.escu.creation_date = 2017-01-07
action.escu.modification_date = 2017-01-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Spectre and Meltdown Vulnerable Systems - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Spectre and Meltdown Vulnerable Systems - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search is used to detect systems that are still vulnerable to the Spectre and Meltdown vulnerabilities.
action.notable.param.rule_title = Spectre and Meltdown Vulnerable Systems
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Vulnerabilities where Vulnerabilities.cve ="CVE-2017-5753" OR Vulnerabilities.cve ="CVE-2017-5715" OR Vulnerabilities.cve ="CVE-2017-5754" by Vulnerabilities.dest | `drop_dm_object_name(Vulnerabilities)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `spectre_and_meltdown_vulnerable_systems_filter`

[ESCU - Spike in File Writes - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a sharp increase in the number of files written to a particular host
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for a sharp increase in the number of files written to a particular host
action.escu.how_to_implement = In order to implement this search, you must populate the Endpoint file-system data model node. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the file system.
action.escu.known_false_positives = It is important to understand that if you happen to install any new applications on your hosts or are copying a large number of files, you can expect to see a large increase of file modifications.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Spike in File Writes - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["SamSam Ransomware", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Spike in File Writes - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search looks for a sharp increase in the number of files written to a particular host
action.notable.param.rule_title = Spike in File Writes
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Filesystem where Filesystem.action=created by _time span=1h, Filesystem.dest | `drop_dm_object_name(Filesystem)` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-1d@d"), count, null))) as "count" avg(eval(if(_time<relative_time(maxtime, "-1d@d"), count,null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-1d@d"), count, null))) as stdev by "dest" | eval upperBound=(avg+stdev*4), isOutlier=if((count > upperBound) AND num_data_samples >=20, 1, 0) | search isOutlier=1 | `spike_in_file_writes_filter` 

[ESCU - Splunk Enterprise Information Disclosure - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to look for evidence of exploitation for CVE-2018-11409, a Splunk Enterprise Information Disclosure Bug.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 4", "CIS 18"], "kill_chain_phases": ["Delivery"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.AC", "PR.IP", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search allows you to look for evidence of exploitation for CVE-2018-11409, a Splunk Enterprise Information Disclosure Bug.
action.escu.how_to_implement = The REST endpoint that exposes system information is also necessary for the proper operation of Splunk clustering and instrumentation. Whitelisting your Splunk systems will reduce false positives.
action.escu.known_false_positives = Retrieving server information may be a legitimate API request. Verify that the attempt is a valid request for information.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-06-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - Splunk Enterprise Information Disclosure - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Splunk Enterprise Vulnerability CVE-2018-11409"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Splunk Enterprise Information Disclosure - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search allows you to look for evidence of exploitation for CVE-2018-11409, a Splunk Enterprise Information Disclosure Bug.
action.notable.param.rule_title = Splunk Enterprise Information Disclosure
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = index=_internal sourcetype=splunkd_ui_access server-info | search clientip!=127.0.0.1 uri_path="*raw/services/server/info/server-info" | rename clientip as src_ip, splunk_server as dest | stats earliest(_time) as firstTime, latest(_time) as lastTime, values(uri) as uri, values(useragent) as http_user_agent, values(user) as user by src_ip, dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `splunk_enterprise_information_disclosure_filter`

[ESCU - Suspicious Changes to File Associations - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for changes to registry values that control Windows file associations, executed by a process that is not typical for legitimate, routine changes to this area.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1546.001"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for changes to registry values that control Windows file associations, executed by a process that is not typical for legitimate, routine changes to this area.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.
action.escu.known_false_positives = There may be other processes in your environment that users may legitimately use to modify file associations. If this is the case and you are finding false positives, you can modify the search to add those processes as exceptions.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious Changes to File Associations - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious Changes to File Associations - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for changes to registry values that control Windows file associations, executed by a process that is not typical for legitimate, routine changes to this area.
action.notable.param.rule_title = Suspicious Changes to File Associations
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name!=Explorer.exe AND Processes.process_name!=OpenWith.exe by Processes.process_id Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | join [| tstats `security_content_summariesonly` values(Registry.registry_path) as registry_path count  FROM datamodel=Endpoint.Registry where Registry.registry_path=*\\Explorer\\FileExts* by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | table process_id dest registry_path]| `suspicious_changes_to_file_associations_filter` 

[ESCU - Suspicious Email - UBA Anomaly - Rule]
action.escu = 0
action.escu.enabled = 1
description = This detection looks for emails that are suspicious because of their sender, domain rareness, or behavior differences. This is an anomaly generated by Splunk User Behavior Analytics (UBA).
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["T1566"], "nist": ["PR.IP"]}
action.escu.data_models = ["UEBA"]
action.escu.eli5 = This detection looks for emails that are suspicious because of their sender, domain rareness, or behavior differences. This is an anomaly generated by Splunk User Behavior Analytics (UBA).
action.escu.how_to_implement = You must be ingesting data from email logs and have Splunk integrated with UBA. This anomaly is raised by a UBA detection model called  "SuspiciousEmailDetectionModel." Ensure that this model is enabled on your UBA instance.
action.escu.known_false_positives = This detection model will alert on any sender domain that is seen for the first time. This could be a potential false positive. The next step is to investigate and whitelist the URL if you determine that it is a legitimate sender.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious Email - UBA Anomaly - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious Email - UBA Anomaly - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This detection looks for emails that are suspicious because of their sender, domain rareness, or behavior differences. This is an anomaly generated by Splunk User Behavior Analytics (UBA).
action.notable.param.rule_title = Suspicious Email - UBA Anomaly
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = |tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(All_UEBA_Events.category) as category from datamodel=UEBA where nodename=All_UEBA_Events.UEBA_Anomalies All_UEBA_Events.UEBA_Anomalies.uba_model = "SuspiciousEmailDetectionModel" by All_UEBA_Events.description All_UEBA_Events.severity All_UEBA_Events.user All_UEBA_Events.uba_event_type All_UEBA_Events.link All_UEBA_Events.signature All_UEBA_Events.url All_UEBA_Events.UEBA_Anomalies.uba_model | `drop_dm_object_name(All_UEBA_Events)` | `drop_dm_object_name(UEBA_Anomalies)`| `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `suspicious_email___uba_anomaly_filter`

[ESCU - Suspicious Email Attachment Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for emails that have attachments with suspicious file extensions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 12"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["T1566.001"], "nist": ["DE.AE", "PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks for emails that have attachments with suspicious file extensions.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. \
 **Splunk Phantom Playbook Integration**\
If Splunk Phantom is also configured in your environment, a Playbook called "Suspicious Email Attachment Investigate and Delete" can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, and add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search. The notable event will be sent to Phantom and the playbook will gather further information about the file attachment and its network behaviors. If Phantom finds malicious behavior and an analyst approves of the results, the email will be deleted from the user's inbox.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious Email Attachment Extensions - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious Email Attachment Extensions - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for emails that have attachments with suspicious file extensions.
action.notable.param.rule_title = Suspicious Email Attachment Extensions
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Email")` | `suspicious_email_attachments` | `suspicious_email_attachment_extensions_filter` 

[ESCU - Suspicious File Write - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for files created with names that have been linked to malicious activity.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for files created with names that have been linked to malicious activity.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes. In addition, this search leverages an included lookup file that contains the names of the files to watch for, as well as a note to communicate why that file name is being monitored. This lookup file can be edited to add or remove file the file names you want to monitor.
action.escu.known_false_positives = It's possible for a legitimate file to be created with the same name as one noted in the lookup file. Filenames listed in the lookup file should be unique enough that collisions are rare. Looking at the location of the file and the process responsible for the activity can help determine whether or not the activity is legitimate.
action.escu.creation_date = 2019-04-25
action.escu.modification_date = 2019-04-25
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious File Write - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Hidden Cobra Malware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious File Write - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search looks for files created with names that have been linked to malicious activity.
action.notable.param.rule_title = Suspicious File Write
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Filesystem.action) as action values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem by Filesystem.file_name Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Filesystem)` | `suspicious_writes` | `suspicious_file_write_filter`

[ESCU - Suspicious Java Classes - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for suspicious Java classes that are often used to exploit remote command execution in common Java frameworks, such as Apache Struts.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 12"], "kill_chain_phases": ["Exploitation"], "nist": ["DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for suspicious Java classes that are often used to exploit remote command execution in common Java frameworks, such as Apache Struts.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your web-traffic appliances that serve or sit in the path of your Struts application servers. This can be accomplished by indexing data from a web proxy, or by using network traffic-analysis tools, such as Splunk Stream or Bro.
action.escu.known_false_positives = There are no known false positives.
action.escu.creation_date = 2018-12-06
action.escu.modification_date = 2018-12-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious Java Classes - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious Java Classes - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest', 'src']
action.notable.param.rule_description = This search looks for suspicious Java classes that are often used to exploit remote command execution in common Java frameworks, such as Apache Struts.
action.notable.param.rule_title = Suspicious Java Classes
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `stream_http` http_method=POST http_content_length>1 | regex form_data="(?i)java\.lang\.(?:runtime|processbuilder)" | rename src_ip as src | stats count earliest(_time) as firstTime, latest(_time) as lastTime, values(url) as uri, values(status) as status, values(http_user_agent) as http_user_agent by src, dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `suspicious_java_classes_filter`

[ESCU - Suspicious LNK file launching a process - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for a ``*.lnk` file under `C:\User*` or `*\Local\Temp\*` executing a process. This is common behavior used by various spear phishing tools.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["T1566.002"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for a ``*.lnk` file under `C:\User*` or `*\Local\Temp\*` executing a process. This is common behavior used by various spear phishing tools.
action.escu.how_to_implement = You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.
action.escu.known_false_positives = This detection should yield little or no false positive results. It is uncommon for LNK files to execute process from temporary or user directories.
action.escu.creation_date = 2020-07-21
action.escu.modification_date = 2020-07-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious LNK file launching a process - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Phishing Payloads"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious LNK file launching a process - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for a ``*.lnk` file under `C:\User*` or `*\Local\Temp\*` executing a process. This is common behavior used by various spear phishing tools.
action.notable.param.rule_title = Suspicious LNK file launching a process
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_name="*.lnk" AND (Filesystem.file_path="C:\\Users*" OR Filesystem.file_path="*Local\\Temp*")  by _time span=1h Filesystem.process_id Filesystem.file_name Filesystem.file_path Filesystem.file_hash Filesystem.user | `drop_dm_object_name(Filesystem)` | rename process_id as lnk_pid | join lnk_pid, _time [| tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Processes where Processes.process_name=*  by _time span=1h Processes.parent_process_id Processes.process_id Processes.process_name Processes.dest Processes.process_path Processes.process | `drop_dm_object_name(Processes)` | rename parent_process_id as lnk_pid | fields _time lnk_pid process_id dest process_name process_path process] | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime, lastTime, lnk_pid, process_id, user, dest, file_name, file_path, process_name, process, process_path, file_hash | `suspicious_lnk_file_launching_a_process_filter` 

[ESCU - Suspicious Reg exe Process - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for reg.exe being launched from a command prompt not started by the user. When a user launches cmd.exe, the parent process is usually explorer.exe. This search filters out those instances.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1112"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for reg.exe being launched from a command prompt not started by the user. When a user launches cmd.exe, the parent process is usually explorer.exe. This search filters out those instances.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = It's possible for system administrators to write scripts that exhibit this behavior. If this is the case, the search will need to be modified to filter them out.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious Reg exe Process - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Disabling Security Tools", "DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious Reg exe Process - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for reg.exe being launched from a command prompt not started by the user. When a user launches cmd.exe, the parent process is usually explorer.exe. This search filters out those instances.
action.notable.param.rule_title = Suspicious Reg exe Process
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.parent_process_name != explorer.exe Processes.process_name =cmd.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest Processes.process_id Processes.parent_process_id | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Processes where Processes.parent_process_name=cmd.exe Processes.process_name= reg.exe by Processes.parent_process_id Processes.dest Processes.process_name | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename parent_process_id as process_id |dedup process_id| table process_id dest] | `suspicious_reg_exe_process_filter` 

[ESCU - Suspicious wevtutil Usage - Rule]
action.escu = 0
action.escu.enabled = 1
description = The wevtutil.exe application is the windows event log utility. This searches for wevtutil.exe with parameters for clearing the application, security, setup, or system event logs.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 6"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1070.001"], "nist": ["DE.DP", "PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The wevtutil.exe application is the windows event log utility. This searches for wevtutil.exe with parameters for clearing the application, security, setup, or system event logs.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = The wevtutil.exe application is a legitimate Windows event log utility. Administrators may use it to manage Windows event logs.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious wevtutil Usage - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Log Manipulation", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious wevtutil Usage - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The wevtutil.exe application is the windows event log utility. This searches for wevtutil.exe with parameters for clearing the application, security, setup, or system event logs.
action.notable.param.rule_title = Suspicious wevtutil Usage
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wevtutil.exe Processes.process="*cl*" (Processes.process="*System*" OR Processes.process="*Security*" OR Processes.process="*Setup*" OR Processes.process="*Application*") by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `suspicious_wevtutil_usage_filter`

[ESCU - Suspicious writes to System Volume Information - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects writes to the 'System Volume Information' folder by something other than the System process.
action.escu.mappings = {"cis20": ["CIS 8"], "mitre_attack": ["T1036"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects writes to the 'System Volume Information' folder by something other than the System process.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = It is possible that other utilities or system processes may legitimately write to this folder. Investigate and modify the search to include exceptions as appropriate.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious writes to System Volume Information - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious writes to System Volume Information - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search detects writes to the 'System Volume Information' folder by something other than the System process.
action.notable.param.rule_title = Suspicious writes to System Volume Information
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = (`sysmon` OR tag=process) EventCode=11 process_id!=4 file_path=*System\ Volume\ Information* | stats count min(_time) as firstTime max(_time) as lastTime by dest, Image, file_path | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `suspicious_writes_to_system_volume_information_filter`

[ESCU - Suspicious writes to windows Recycle Bin - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects writes to the recycle bin by a process other than explorer.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "mitre_attack": ["T1036"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects writes to the recycle bin by a process other than explorer.exe.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on filesystem and process logs responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Filesystem` nodes.
action.escu.known_false_positives = Because the Recycle Bin is a hidden folder in modern versions of Windows, it would be unusual for a process other than explorer.exe to write to it. Incidents should be investigated as appropriate.
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious writes to windows Recycle Bin - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Suspicious writes to windows Recycle Bin - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search detects writes to the recycle bin by a process other than explorer.exe.
action.notable.param.rule_title = Suspicious writes to windows Recycle Bin
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name FROM datamodel=Endpoint.Filesystem where Filesystem.file_path = "*$Recycle.Bin*" by Filesystem.process_id Filesystem.dest | `drop_dm_object_name("Filesystem")`| search [| tstats `security_content_summariesonly` values(Processes.user) as user values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name != "explorer.exe" by Processes.process_id Processes.dest| `drop_dm_object_name("Processes")` | table process_id dest] | `suspicious_writes_to_windows_recycle_bin_filter`

[ESCU - System Processes Run From Unexpected Locations - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for system processes that normally run out of C:\Windows\System32\ or C:\Windows\SysWOW64 that are not run from that location.  This can indicate a malicious process that is trying to hide as a legitimate process.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1036"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for system processes that normally run out of C:\Windows\System32\ or C:\Windows\SysWOW64 that are not run from that location.  This can indicate a malicious process that is trying to hide as a legitimate process.
action.escu.how_to_implement = To successfully implement this search you need to ingest details about process execution from your hosts. Specifically, this search requires the process name and the full path to the process executable.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2020-02-04
action.escu.modification_date = 2020-02-04
action.escu.confidence = high
action.escu.full_search_name = ESCU - System Processes Run From Unexpected Locations - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Command-Line Executions", "Unusual Processes", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - System Processes Run From Unexpected Locations - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for system processes that normally run out of C:\Windows\System32\ or C:\Windows\SysWOW64 that are not run from that location.  This can indicate a malicious process that is trying to hide as a legitimate process.
action.notable.param.rule_title = System Processes Run From Unexpected Locations
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_path !="C:\\Windows\\System32*" Processes.process_path !="C:\\Windows\\SysWOW64*" by Processes.user Processes.dest Processes.process_name Processes.process_id Processes.process_path Processes.parent_process_name Processes.process_hash| `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `is_windows_system_file` | `system_processes_run_from_unexpected_locations_filter`

[ESCU - TOR Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic identified as The Onion Router (TOR), a benign anonymity network which can be abused for a variety of nefarious purposes.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["T1071.001"], "nist": ["DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for network traffic identified as The Onion Router (TOR), a benign anonymity network which can be abused for a variety of nefarious purposes.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - TOR Traffic - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - TOR Traffic - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for network traffic identified as The Onion Router (TOR), a benign anonymity network which can be abused for a variety of nefarious purposes.
action.notable.param.rule_title = TOR Traffic
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=tor AND All_Traffic.action=allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `tor_traffic_filter`

[ESCU - USN Journal Deletion - Rule]
action.escu = 0
action.escu.enabled = 1
description = The fsutil.exe application is a legitimate Windows utility used to perform tasks related to the file allocation table (FAT) and NTFS file systems. The update sequence number (USN) change journal provides a log of all changes made to the files on the disk. This search looks for fsutil.exe deleting the USN journal.
action.escu.mappings = {"cis20": ["CIS 6", "CIS 8", "CIS 10"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1070"], "nist": ["DE.CM", "PR.PT", "DE.AE", "DE.DP", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The fsutil.exe application is a legitimate Windows utility used to perform tasks related to the file allocation table (FAT) and NTFS file systems. The update sequence number (USN) change journal provides a log of all changes made to the files on the disk. This search looks for fsutil.exe deleting the USN journal.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2018-12-03
action.escu.modification_date = 2018-12-03
action.escu.confidence = high
action.escu.full_search_name = ESCU - USN Journal Deletion - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Log Manipulation", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - USN Journal Deletion - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = The fsutil.exe application is a legitimate Windows utility used to perform tasks related to the file allocation table (FAT) and NTFS file systems. The update sequence number (USN) change journal provides a log of all changes made to the files on the disk. This search looks for fsutil.exe deleting the USN journal.
action.notable.param.rule_title = USN Journal Deletion
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=fsutil.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process="*deletejournal*" AND process="*usn*" | `usn_journal_deletion_filter`

[ESCU - Uncommon Processes On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for applications on the endpoint that you have marked as uncommon.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1204.002"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for applications on the endpoint that you have marked as uncommon.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. This search uses a lookup file `uncommon_processes_default.csv` to track various features of process names that are usually uncommon in most environments. Please consider updating `uncommon_processes_local.csv` to hunt for processes that are uncommon in your environment.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Uncommon Processes On Endpoint - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Privilege Escalation", "Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Uncommon Processes On Endpoint - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = This search looks for applications on the endpoint that you have marked as uncommon.
action.notable.param.rule_title = Uncommon Processes On Endpoint
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `uncommon_processes` |`uncommon_processes_on_endpoint_filter` 

[ESCU - Unload Sysmon Filter Driver - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attackers often disable security tools to avoid detection. This search looks for the usage of process `fltMC.exe` to unload a Sysmon Driver that will stop sysmon from collecting the data.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.001"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers often disable security tools to avoid detection. This search looks for the usage of process `fltMC.exe` to unload a Sysmon Driver that will stop sysmon from collecting the data.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. This search is also shipped with `unload_sysmon_filter_driver_filter` macro, update this macro to filter out false positives.
action.escu.known_false_positives = 
action.escu.creation_date = 2020-07-22
action.escu.modification_date = 2020-07-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unload Sysmon Filter Driver - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Unload Sysmon Filter Driver - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Attackers often disable security tools to avoid detection. This search looks for the usage of process `fltMC.exe` to unload a Sysmon Driver that will stop sysmon from collecting the data.
action.notable.param.rule_title = Unload Sysmon Filter Driver
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=fltMC.exe AND Processes.process=*unload* AND Processes.process=*SysmonDrv*  by Processes.process_name Processes.process_id Processes.parent_process_name Processes.process Processes.dest Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` |`unload_sysmon_filter_driver_filter`| table firstTime lastTime dest user count process_name process_id parent_process_name process

[ESCU - Unsigned Image Loaded by LSASS - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects loading of unsigned images by LSASS.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1003.001"], "nist": ["DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search detects loading of unsigned images by LSASS.
action.escu.how_to_implement = This search needs Sysmon Logs with a sysmon configuration, which includes EventCode 7 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Other tools could load images into LSASS for legitimate reason. But enterprise tools should always use signed DLLs.
action.escu.creation_date = 2019-12-06
action.escu.modification_date = 2019-12-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unsigned Image Loaded by LSASS - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Unsigned Image Loaded by LSASS - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search detects loading of unsigned images by LSASS.
action.notable.param.rule_title = Unsigned Image Loaded by LSASS
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `sysmon` EventID=7 Image=*lsass.exe Signed=false | stats count min(_time) as firstTime max(_time) as lastTime by Computer, Image, ImageLoaded, Signed, SHA1 | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `unsigned_image_loaded_by_lsass_filter` 

[ESCU - Unsuccessful Netbackup backups - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search gives you the hosts where a backup was attempted and then failed.
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search gives you the hosts where a backup was attempted and then failed.
action.escu.how_to_implement = To successfully implement this search you need to obtain data from your backup solution, either from the backup logs on your endpoints or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your specific backup solution.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unsuccessful Netbackup backups - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Monitor Backup Solution"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Unsuccessful Netbackup backups - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search gives you the hosts where a backup was attempted and then failed.
action.notable.param.rule_title = Unsuccessful Netbackup backups
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `netbackup` | stats latest(_time) as latestTime by COMPUTERNAME, MESSAGE | search MESSAGE="An error occurred, failed to backup." | `security_content_ctime(latestTime)` | rename COMPUTERNAME as dest, MESSAGE as signature | table latestTime, dest, signature | `unsuccessful_netbackup_backups_filter`

[ESCU - Unusually Long Command Line - Rule]
action.escu = 0
action.escu.enabled = 1
description = Command lines that are extremely long may be indicative of malicious activity on your hosts.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = Command lines that are extremely long may be indicative of malicious activity on your hosts.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships, from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Some legitimate applications start with long command lines.
action.escu.creation_date = 2020-03-16
action.escu.modification_date = 2020-03-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unusually Long Command Line - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Command-Line Executions", "Unusual Processes", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Unusually Long Command Line - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Command lines that are extremely long may be indicative of malicious activity on your hosts.
action.notable.param.rule_title = Unusually Long Command Line
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`|  eval processlen=len(process) | eventstats stdev(processlen) as stdev, avg(processlen) as avg by dest | stats max(processlen) as maxlen, values(stdev) as stdevperhost, values(avg) as avgperhost by dest, user, process_name, process | `unusually_long_command_line_filter` |eval threshold = 10 | where maxlen > ((threshold*stdevperhost) + avgperhost)

[ESCU - Unusually Long Command Line - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = Command lines that are extremely long may be indicative of malicious activity on your hosts. This search leverages the Machine Learning Toolkit (MLTK) to help identify command lines with lengths that are unusual for a given user.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = Command lines that are extremely long may be indicative of malicious activity on your hosts. This search leverages the Machine Learning Toolkit (MLTK) to help identify command lines with lengths that are unusual for a given user.
action.escu.how_to_implement = You must be ingesting endpoint data that monitors command lines and populates the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model. In addition, MLTK version >= 4.2 must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of Command Line Length - MLTK" must be executed before this detection search, as it builds an ML model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.
action.escu.known_false_positives = Some legitimate applications use long command lines for installs or updates. You should review identified command lines for legitimacy. You may modify the first part of the search to omit legitimate command lines from consideration. If you are seeing more results than desired, you may consider changing the value of threshold in the search to a smaller value. You should also periodically re-run the support search to re-build the ML model on the latest data. You may get unexpected results if the user identified in the results is not present in the data used to build the associated model.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unusually Long Command Line - MLTK - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Command-Line Executions", "Unusual Processes", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Unusually Long Command Line - MLTK - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user', 'dest']
action.notable.param.rule_description = Command lines that are extremely long may be indicative of malicious activity on your hosts. This search leverages the Machine Learning Toolkit (MLTK) to help identify command lines with lengths that are unusual for a given user.
action.notable.param.rule_title = Unusually Long Command Line - MLTK
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| eval processlen=len(process) | search user!=unknown | apply cmdline_pdfmodel threshold=0.01 | rename "IsOutlier(processlen)" as isOutlier | search isOutlier > 0 | table firstTime lastTime user dest process_name process processlen count | `unusually_long_command_line___mltk_filter`

[ESCU - Unusually Long Content-Type Length - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for unusually long strings in the Content-Type http header that the client sends the server.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 4", "CIS 18", "CIS 12"], "kill_chain_phases": ["Delivery"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for unusually long strings in the Content-Type http header that the client sends the server.
action.escu.how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
action.escu.known_false_positives = Very few legitimate Content-Type fields will have a length greater than 100 characters.
action.escu.creation_date = 2017-10-13
action.escu.modification_date = 2017-10-13
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unusually Long Content-Type Length - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Unusually Long Content-Type Length - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for unusually long strings in the Content-Type http header that the client sends the server.
action.notable.param.rule_title = Unusually Long Content-Type Length
action.notable.param.security_domain = network
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `stream_http` | eval cs_content_type_length = len(cs_content_type) | where cs_content_type_length > 100 | table endtime src_ip dest_ip cs_content_type_length cs_content_type url | `unusually_long_content_type_length_filter`

[ESCU - WMI Permanent Event Subscription - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI permanent event subscriptions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1047"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for the creation of WMI permanent event subscriptions.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].
action.escu.known_false_positives = Although unlikely, administrators may use event subscriptions for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - WMI Permanent Event Subscription - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - WMI Permanent Event Subscription - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for the creation of WMI permanent event subscriptions.
action.notable.param.rule_title = WMI Permanent Event Subscription
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `wmi` EventCode=5861 Binding | rex field=Message "Consumer =\s+(?<consumer>[^;|^$]+)" | search consumer!="NTEventLogEventConsumer=\"SCM Event Log Consumer\"" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, consumer, Message | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | rename ComputerName as dest | `wmi_permanent_event_subscription_filter`

[ESCU - WMI Permanent Event Subscription - Sysmon - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI permanent event subscriptions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1047"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for the creation of WMI permanent event subscriptions.
action.escu.how_to_implement = To successfully implement this search, you must be collecting Sysmon data using Sysmon version 6.1 or greater and have Sysmon configured to generate alerts for WMI activity. In addition, you must have at least version 6.0.4 of the Sysmon TA installed to properly parse the fields.
action.escu.known_false_positives = Although unlikely, administrators may use event subscriptions for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - WMI Permanent Event Subscription - Sysmon - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - WMI Permanent Event Subscription - Sysmon - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for the creation of WMI permanent event subscriptions.
action.notable.param.rule_title = WMI Permanent Event Subscription - Sysmon
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `sysmon` EventCode=21 | rename host as dest | table _time, dest, user, Operation, EventType, Query, Consumer, Filter | `wmi_permanent_event_subscription___sysmon_filter`

[ESCU - WMI Temporary Event Subscription - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI temporary event subscriptions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1047"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for the creation of WMI temporary event subscriptions.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].
action.escu.known_false_positives = Some software may create WMI temporary event subscriptions for various purposes. The included search contains an exception for two of these that occur by default on Windows 10 systems. You may need to modify the search to create exceptions for other legitimate events.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - WMI Temporary Event Subscription - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - WMI Temporary Event Subscription - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search looks for the creation of WMI temporary event subscriptions.
action.notable.param.rule_title = WMI Temporary Event Subscription
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `wmi` EventCode=5860 Temporary | rex field=Message "NotificationQuery =\s+(?<query>[^;|^$]+)" | search query!="SELECT * FROM Win32_ProcessStartTrace WHERE ProcessName = 'wsmprovhost.exe'" AND query!="SELECT * FROM __InstanceOperationEvent WHERE TargetInstance ISA 'AntiVirusProduct' OR TargetInstance ISA 'FirewallProduct' OR TargetInstance ISA 'AntiSpywareProduct'" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, query  | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `wmi_temporary_event_subscription_filter`

[ESCU - Web Fraud - Account Harvesting - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to identify the creation of multiple user accounts using the same email domain name.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136"], "nist": ["DE.CM", "DE.DP"]}
action.escu.data_models = []
action.escu.eli5 = This search is used to identify the creation of multiple user accounts using the same email domain name.
action.escu.how_to_implement = We start with a dataset that provides visibility into the email address used for the account creation. In this example, we are narrowing our search down to the single web page that hosts the Magento2 e-commerce platform (via URI) used for account creation, the single http content-type to grab only the user's clicks, and the http field that provides the username (form_data), for performance reasons.  After we have the username and email domain, we look for numerous account creations per email domain.  Common data sources used for this detection are customized Apache logs or Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamolous behavior. This search will need to be customized to fit your environment&#151;improving its fidelity by counting based on something much more specific, such as a device ID that may be present in your dataset. Consideration for whether the large number of registrations are occuring from a first-time seen domain may also be important.  Extending the search window to look further back in time, or even calculating the average per hour/day for each email domain to look for an anomalous spikes, will improve this search.  You can also use Shannon entropy or Levenshtein Distance (both courtesy of URL Toolbox) to consider the randomness or similarity of the email name or email domain, as the names are often machine-generated.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.confidence = high
action.escu.full_search_name = ESCU - Web Fraud - Account Harvesting - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Web Fraud - Account Harvesting - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search is used to identify the creation of multiple user accounts using the same email domain name.
action.notable.param.rule_title = Web Fraud - Account Harvesting
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `stream_http` http_content_type=text* uri="/magento2/customer/account/loginPost/" | rex field=cookie "form_key=(?<SessionID>\w+)" | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | search Username=* | rex field=Username "@(?<email_domain>.*)" | stats dc(Username) as UniqueUsernames list(Username) as src_user by email_domain | where UniqueUsernames> 25 | `web_fraud___account_harvesting_filter`

[ESCU - Web Fraud - Anomalous User Clickspeed - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to examine web sessions to identify those where the clicks are occurring too quickly for a human or are occurring with a near-perfect cadence (high periodicity or low standard deviation), resembling a script driven session.
action.escu.mappings = {"cis20": ["CIS 6"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078"], "nist": ["DE.AE", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search is used to examine web sessions to identify those where the clicks are occurring too quickly for a human or are occurring with a near-perfect cadence (high periodicity or low standard deviation), resembling a script driven session.
action.escu.how_to_implement = Start with a dataset that allows you to see clickstream data for each user click on the website. That data must have a time stamp and must contain a reference to the session identifier being used by the website. This ties the clicks together into clickstreams. This value is usually found in the http cookie. With a bit of tuning, a version of this search could be used in high-volume scenarios, such as scraping, crawling, application DDOS, credit-card testing, account takeover, etc. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosly written detections that simply detect anamoluous behavior.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.confidence = high
action.escu.full_search_name = ESCU - Web Fraud - Anomalous User Clickspeed - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Web Fraud - Anomalous User Clickspeed - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search is used to examine web sessions to identify those where the clicks are occurring too quickly for a human or are occurring with a near-perfect cadence (high periodicity or low standard deviation), resembling a script driven session.
action.notable.param.rule_title = Web Fraud - Anomalous User Clickspeed
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `stream_http` http_content_type=text* | rex field=cookie "form_key=(?<session_id>\w+)" | streamstats window=2 current=1 range(_time) as TimeDelta by session_id | where TimeDelta>0 |stats count stdev(TimeDelta) as ClickSpeedStdDev avg(TimeDelta) as ClickSpeedAvg by session_id | where count>5 AND (ClickSpeedStdDev<.5 OR ClickSpeedAvg<.5) | `web_fraud___anomalous_user_clickspeed_filter`

[ESCU - Web Fraud - Password Sharing Across Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to identify user accounts that share a common password.
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["DE.DP"]}
action.escu.data_models = []
action.escu.eli5 = This search is used to identify user accounts that share a common password.
action.escu.how_to_implement = We need to start with a dataset that allows us to see the values of usernames and passwords that users are submitting to the website hosting the Magento2 e-commerce platform (commonly found in the HTTP form_data field). A tokenized or hashed value of a password is acceptable and certainly preferable to a clear-text password. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamoluous behavior.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.confidence = high
action.escu.full_search_name = ESCU - Web Fraud - Password Sharing Across Accounts - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Web Fraud - Password Sharing Across Accounts - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['user']
action.notable.param.rule_description = This search is used to identify user accounts that share a common password.
action.notable.param.rule_title = Web Fraud - Password Sharing Across Accounts
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `stream_http` http_content_type=text* uri=/magento2/customer/account/loginPost*  | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | rex field=form_data "login\[password\]=(?<Password>[^&|^$]+)" | stats dc(Username) as UniqueUsernames values(Username) as user list(src_ip) as src_ip by Password|where UniqueUsernames>5 | `web_fraud___password_sharing_across_accounts_filter`

[ESCU - Web Servers Executing Suspicious Processes - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for suspicious processes on all systems labeled as web servers.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1082"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for suspicious processes on all systems labeled as web servers.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. In addition, web servers will need to be identified in the Assets and Identity Framework of Enterprise Security.
action.escu.known_false_positives = Some of these processes may be used legitimately on web servers during maintenance or other administrative tasks.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Web Servers Executing Suspicious Processes - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Web Servers Executing Suspicious Processes - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for suspicious processes on all systems labeled as web servers.
action.notable.param.rule_title = Web Servers Executing Suspicious Processes
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest_category="web_server" AND (Processes.process="*whoami*" OR Processes.process="*ping*" OR Processes.process="*iptables*" OR Processes.process="*wget*" OR Processes.process="*service*" OR Processes.process="*curl*") by Processes.process Processes.process_name, Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `web_servers_executing_suspicious_processes_filter`

[ESCU - Windows Event Log Cleared - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Windows events that indicate one of the Windows event logs has been purged.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 6"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1070.001"], "nist": ["DE.DP", "PR.IP", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for Windows events that indicate one of the Windows event logs has been purged.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting Windows event logs from your hosts.
action.escu.known_false_positives = It is possible that these logs may be legitimately cleared by Administrators.
action.escu.creation_date = 2020-07-06
action.escu.modification_date = 2020-07-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Windows Event Log Cleared - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Windows Log Manipulation", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Windows Event Log Cleared - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = This search looks for Windows events that indicate one of the Windows event logs has been purged.
action.notable.param.rule_title = Windows Event Log Cleared
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = (`wineventlog_security` (EventID=1102 OR EventID=1100)) OR (`wineventlog_system` EventID=104) | stats count min(_time) as firstTime max(_time) as lastTime by EventID dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `windows_event_log_cleared_filter`

[ESCU - Windows hosts file modification - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to the hosts file on all Windows endpoints across your environment.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "nist": ["PR.IP", "PR.PT", "PR.AC", "DE.AE", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for modifications to the hosts file on all Windows endpoints across your environment.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = There may be legitimate reasons for system administrators to add entries to this file.
action.escu.creation_date = 2018-11-02
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Windows hosts file modification - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["Host Redirection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Windows hosts file modification - Rule
schedule_window = auto
action.notable = 1
action.notable.param.nes_fields = ['dest']
action.notable.param.rule_description = The search looks for modifications to the hosts file on all Windows endpoints across your environment.
action.notable.param.rule_title = Windows hosts file modification
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem  by Filesystem.file_name Filesystem.file_path Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | search Filesystem.file_name=hosts AND Filesystem.file_path=*Windows\\System32\\* | `drop_dm_object_name(Filesystem)` | `windows_hosts_file_modification_filter`

[ESCU - aws detect attach to role policy - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of an user attaching itself to a different role trust policy. This can be used for lateral movement and escalation of privileges.
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"], "mitre_attack": ["T1078"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of an user attaching itself to a different role trust policy. This can be used for lateral movement and escalation of privileges.
action.escu.how_to_implement = You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs
action.escu.known_false_positives = Attach to policy can create a lot of noise. This search can be adjusted to provide specific values to identify cases of abuse (i.e status=failure). The search can provide context for common users attaching themselves to higher privilege policies or even newly created policies.
action.escu.creation_date = 2020-07-27
action.escu.modification_date = 2020-07-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - aws detect attach to role policy - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - aws detect attach to role policy - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides detection of an user attaching itself to a different role trust policy. This can be used for lateral movement and escalation of privileges.
action.notable.param.rule_title = aws detect attach to role policy
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` attach policy| spath requestParameters.policyArn | table sourceIPAddress user_access_key userIdentity.arn userIdentity.sessionContext.sessionIssuer.arn eventName errorCode errorMessage status action requestParameters.policyArn userIdentity.sessionContext.attributes.mfaAuthenticated userIdentity.sessionContext.attributes.creationDate  | `aws_detect_attach_to_role_policy_filter`

[ESCU - aws detect permanent key creation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of accounts creating permanent keys. Permanent keys are not created by default and they are only needed for programmatic calls. Creation of Permanent key is an important event to monitor.
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"], "mitre_attack": ["T1078"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of accounts creating permanent keys. Permanent keys are not created by default and they are only needed for programmatic calls. Creation of Permanent key is an important event to monitor.
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs
action.escu.known_false_positives = Not all permanent key creations are malicious. If there is a policy of rotating keys this search can be adjusted to provide better context.
action.escu.creation_date = 2020-07-27
action.escu.modification_date = 2020-07-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - aws detect permanent key creation - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - aws detect permanent key creation - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides detection of accounts creating permanent keys. Permanent keys are not created by default and they are only needed for programmatic calls. Creation of Permanent key is an important event to monitor.
action.notable.param.rule_title = aws detect permanent key creation
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` CreateAccessKey | spath eventName | search eventName=CreateAccessKey "userIdentity.type"=IAMUser | table sourceIPAddress userName userIdentity.type userAgent action status responseElements.accessKey.createDate responseElements.accessKey.status responseElements.accessKey.accessKeyId |`aws_detect_permanent_key_creation_filter`

[ESCU - aws detect role creation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of role creation by IAM users. Role creation is an event by itself if user is creating a new role with trust policies different than the available in AWS and it can be used for lateral movement and escalation of privileges.
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"], "mitre_attack": ["T1078"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of role creation by IAM users. Role creation is an event by itself if user is creating a new role with trust policies different than the available in AWS and it can be used for lateral movement and escalation of privileges.
action.escu.how_to_implement = You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs
action.escu.known_false_positives = CreateRole is not very common in common users. This search can be adjusted to provide specific values to identify cases of abuse. In general AWS provides plenty of trust policies that fit most use cases.
action.escu.creation_date = 2020-07-27
action.escu.modification_date = 2020-07-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - aws detect role creation - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - aws detect role creation - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides detection of role creation by IAM users. Role creation is an event by itself if user is creating a new role with trust policies different than the available in AWS and it can be used for lateral movement and escalation of privileges.
action.notable.param.rule_title = aws detect role creation
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` event_name=CreateRole action=created userIdentity.type=AssumedRole requestParameters.description=Allows | table sourceIPAddress userIdentity.principalId userIdentity.arn action event_name awsRegion http_user_agent mfa_auth msg requestParameters.roleName requestParameters.description responseElements.role.arn responseElements.role.createDate | `aws_detect_role_creation_filter`

[ESCU - aws detect sts assume role abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of suspicious use of sts:AssumeRole. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"], "mitre_attack": ["T1078"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of suspicious use of sts:AssumeRole. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs
action.escu.known_false_positives = Sts:AssumeRole can be very noisy as it is a standard mechanism to provide cross account and cross resources access. This search can be adjusted to provide specific values to identify cases of abuse.
action.escu.creation_date = 2020-07-27
action.escu.modification_date = 2020-07-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - aws detect sts assume role abuse - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - aws detect sts assume role abuse - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides detection of suspicious use of sts:AssumeRole. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.
action.notable.param.rule_title = aws detect sts assume role abuse
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` ASIA AssumeRole userIdentity.sessionContext.sessionIssuer.type=Role | table sourceIPAddress userIdentity.arn user_agent user_access_key status action requestParameters.roleName responseElements.role.roleName responseElements.role.createDate | `aws_detect_sts_assume_role_abuse_filter`

[ESCU - aws detect sts get session token abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of suspicious use of sts:GetSessionToken. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.
action.escu.mappings = {"kill_chain_phases": ["Lateral Movement"], "mitre_attack": ["T1550"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of suspicious use of sts:GetSessionToken. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.
action.escu.how_to_implement = You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs
action.escu.known_false_positives = Sts:GetSessionToken can be very noisy as in certain environments numerous calls of this type can be executed. This search can be adjusted to provide specific values to identify cases of abuse. In specific environments the use of field requestParameters.serialNumber will need to be used.
action.escu.creation_date = 2020-07-27
action.escu.modification_date = 2020-07-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - aws detect sts get session token abuse - Rule
action.escu.search_type = detection
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - aws detect sts get session token abuse - Rule
schedule_window = auto
action.notable = 1
action.notable.param.rule_description = This search provides detection of suspicious use of sts:GetSessionToken. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.
action.notable.param.rule_title = aws detect sts get session token abuse
action.notable.param.security_domain = threat
action.notable.param.severity = high
alert.digest_mode = 1
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_cloudwatchlogs_eks` ASIA  userIdentity.type=IAMUser| spath eventName | search eventName=GetSessionToken | table sourceIPAddress eventTime userIdentity.arn userName userAgent user_type status region | `aws_detect_sts_get_session_token_abuse_filter`

### END ESCU DETECTIONS ###


### ESCU BASELINES ###

[ESCU - Add Prohibited Processes to Enterprise Security]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Add Prohibited Processes to Enterprise Security
description = This search takes the existing interesting process table from ES, filters out any existing additions added by ESCU and then updates the table with processes identified by ESCU that should be prohibited on your endpoints.
action.escu.creation_date = 2017-09-15
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Monitor for Unauthorized Software", "SamSam Ransomware"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search takes the existing interesting process table from ES, filters out any existing additions added by ESCU and then updates the table with processes identified by ESCU that should be prohibited on your endpoints.
action.escu.how_to_implement = This search should be run on each new install of ESCU.
disabled = true
is_visible = false
search = | inputlookup interesting_processes_lookup | search note!=ESCU* | inputlookup append=T prohibitedProcesses_lookup | fillnull value=* dest dest_pci_domain | fillnull value=false is_required is_secure | fillnull value=true is_prohibited | outputlookup interesting_processes_lookup | stats count

[ESCU - Baseline of API Calls per User ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of API Calls per User ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventType=AwsApiCall | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | stats count

[ESCU - Baseline of Command Line Length - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Command Line Length - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the command lines observed for each user in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies outliers in the length of the command line.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Unusual Processes"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the command lines observed for each user in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies outliers in the length of the command line.
action.escu.how_to_implement = You must be ingesting endpoint data and populating the Endpoint data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as start_time max(_time) as end_time FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name(Processes)` | search user!=unknown | `security_content_ctime(start_time)`| `security_content_ctime(end_time)`| eval processlen=len(process) | fit DensityFunction processlen by user into cmdline_pdfmodel

[ESCU - Baseline of DNS Query Length - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of DNS Query Length - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the DNS queries for each DNS record type observed in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which uses it to identify outliers in the length of the DNS query.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["Command and Control", "Hidden Cobra Malware", "Suspicious DNS Traffic"]
action.escu.data_models = ["Network_Resolution"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the DNS queries for each DNS record type observed in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which uses it to identify outliers in the length of the DNS query.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type | search DNS.record_type=* | `drop_dm_object_name("DNS")` | eval query_length = len(query) | fit DensityFunction query_length by record_type into dns_query_pdfmodel

[ESCU - Baseline of Excessive AWS Instances Launched by User - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Excessive AWS Instances Launched by User - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many RunInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of RunInstances performed by a user in a small time window.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.analytic_story = ["Cloud Cryptomining", "Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many RunInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of RunInstances performed by a user in a small time window.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success `ec2_excessive_runinstances_mltk_input_filter` | bucket span=10m _time | stats count as instances_launched by _time src_user | fit DensityFunction instances_launched threshold=0.0005 into ec2_excessive_runinstances_v1

[ESCU - Baseline of Excessive AWS Instances Terminated by User - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Excessive AWS Instances Terminated by User - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many TerminateInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of TerminateInstances performed by a user in a small time window.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many TerminateInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of TerminateInstances performed by a user in a small time window.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = `cloudtrail` eventName=TerminateInstances errorCode=success `ec2_excessive_terminateinstances_mltk_input_filter` | bucket span=10m _time | stats count as instances_terminated by _time src_user | fit DensityFunction instances_terminated threshold=0.0005 into ec2_excessive_terminateinstances_v1

[ESCU - Baseline of Network ACL Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Network ACL Activity by ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls that were related to network ACLs made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-05-21
action.escu.modification_date = 2018-05-21
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls that were related to network ACLs made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for network ACLs, edit the macro `network_acl_events`.
disabled = true
is_visible = false
search = `cloudtrail` `network_acl_events` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | stats count

[ESCU - Baseline of S3 Bucket deletion activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of S3 Bucket deletion activity by ARN
description = This search establishes, on a per-hour basis, the average and standard deviation for the number of API calls related to deleting an S3 bucket by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-07-17
action.escu.modification_date = 2018-07-17
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and standard deviation for the number of API calls related to deleting an S3 bucket by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=DeleteBucket | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | stats count

[ESCU - Baseline of SMB Traffic - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of SMB Traffic - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the number of SMB connections observed each hour for every day of week. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search to identify outliers in the number of SMB connections for that hour and day of the week.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Netsh Abuse", "Ransomware"]
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the number of SMB connections observed each hour for every day of week. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search to identify outliers in the number of SMB connections for that hour and day of the week.
action.escu.how_to_implement = You must be ingesting network traffic and populating the Network_Traffic data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. To improve your results, you may consider adding "src" to the by clause, which will build the model for each unique source in your enviornment. However, if you have a large number of hosts in your environment, this search may be very resource intensive. In this case, you may need to raise the value of max_inputs and/or max_groups in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=10m, All_Traffic.src | eval HourOfDay=strftime(_time, "%H") | eval DayOfWeek=strftime(_time, "%A") | `drop_dm_object_name("All_Traffic")` | fit DensityFunction count by "HourOfDay,DayOfWeek" into smb_pdfmodel

[ESCU - Baseline of Security Group Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Security Group Activity by ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-17
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for security groups, edit the macro `security_group_api_calls`.
disabled = true
is_visible = false
search = `cloudtrail` `security_group_api_calls` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | stats count

[ESCU - Baseline of blocked outbound traffic from AWS]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of blocked outbound traffic from AWS
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your `VPC flow logs.`.
disabled = true
is_visible = false
search = `cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | bucket _time span=1h | stats count as numberOfBlockedConnections by _time, src_ip | stats count(numberOfBlockedConnections) as numDataPoints, latest(numberOfBlockedConnections) as latestCount, avg(numberOfBlockedConnections) as avgBlockedConnections, stdev(numberOfBlockedConnections) as stdevBlockedConnections by src_ip | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | stats count

[ESCU - Count of Unique IPs Connecting to Ports]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of Unique IPs Connecting to Ports
description = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
action.escu.creation_date = 2017-09-13
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = []
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting network traffic, and populating the Network_Traffic data model.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count dc(All_Traffic.src) as numberOfUniqueHosts from datamodel=Network_Traffic by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Count of assets by category]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of assets by category
description = This search shows you every asset category you have and the assets that belong to those categories.
action.escu.creation_date = 2017-09-13
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search shows you every asset category you have and the assets that belong to those categories.
action.escu.how_to_implement = To successfully implement this search you must first leverage the Assets and Identity framework in Enterprise Security to populate your assets_by_str.csv file which should then be mapped to the Identity_Management data model. The Identity_Management data model will contain a list of known authorized company assets. Ensure that all inventoried systems are constantly vetted and updated.
disabled = true
is_visible = false
search = | from datamodel Identity_Management.All_Assets | stats count values(nt_host) by category | sort -count

[ESCU - Create a list of approved AWS service accounts]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Create a list of approved AWS service accounts
description = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into `aws_service_accounts.csv` lookup file.
action.escu.creation_date = 2018-12-03
action.escu.modification_date = 2018-12-03
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into `aws_service_accounts.csv` lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the service account entires in `aws_service_accounts.csv`, which is a lookup file created as a result of running this support search. Please remove the entries of service accounts that are not legitimate.
disabled = true
is_visible = false
search = `cloudtrail` errorCode=success | rename userName as identity | search NOT [inputlookup identity_lookup_expanded | fields identity] | stats count by identity | table identity | outputlookup aws_service_accounts | stats count

[ESCU - DNSTwist Domain Names]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - DNSTwist Domain Names
description = This search creates permutations of your existing domains, removes the valid domain names and stores them in a specified lookup file so they can be checked for in the associated detection searches.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search creates permutations of your existing domains, removes the valid domain names and stores them in a specified lookup file so they can be checked for in the associated detection searches.
action.escu.how_to_implement = To successfully implement this search you need to update the file called domains.csv in the DA-ESS-SOC/lookup directory. Or `cim_corporate_email_domains.csv` and `cim_corporate_web_domains.csv` from **Splunk\_SA\_CIM**.
disabled = true
is_visible = false
search = | dnstwist domainlist=domains.csv | `remove_valid_domains` | eval domain_abuse="true" | table domain, domain_abuse | outputlookup brandMonitoring_lookup | stats count

[ESCU - Discover DNS records]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Discover DNS records
description = The search takes corporate and common cloud provider domains configured under `cim_corporate_email_domains.csv`, `cim_corporate_web_domains.csv`, and `cloud_domains.csv` finds their responses across the last 30 days from data in the `Network_Resolution ` datamodel, then stores the output under the `discovered_dns_records.csv` lookup
action.escu.creation_date = 2019-02-14
action.escu.modification_date = 2019-02-14
action.escu.analytic_story = ["DNS Hijacking"]
action.escu.data_models = ["Network_Resolution"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = The search takes corporate and common cloud provider domains configured under `cim_corporate_email_domains.csv`, `cim_corporate_web_domains.csv`, and `cloud_domains.csv` finds their responses across the last 30 days from data in the `Network_Resolution ` datamodel, then stores the output under the `discovered_dns_records.csv` lookup
action.escu.how_to_implement = To successfully implement this search, you must be ingesting DNS logs, and populating the Network_Resolution data model. Also make sure that the cim_corporate_web_domains and cim_corporate_email_domains lookups are populated with the domains owned by your corporation
disabled = true
is_visible = false
search = | inputlookup cim_corporate_email_domains.csv | inputlookup append=T cim_corporate_web_domains.csv | inputlookup append=T cim_cloud_domains.csv | eval domain = trim(replace(domain, "\*", "")) | join domain [|tstats `security_content_summariesonly` count values(DNS.record_type) as type, values(DNS.answer) as answer from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,domain,type,query,answer | outputlookup createinapp=true discovered_dns_records.csv

[ESCU - Identify Systems Creating Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Creating Remote Desktop Traffic
description = This search counts the numbers of times the system has generated remote desktop traffic.
action.escu.creation_date = 2017-09-15
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = []
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search counts the numbers of times the system has generated remote desktop traffic.
action.escu.how_to_implement = To successfully implement this search, you must ingest network traffic and populate the Network_Traffic data model.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Receiving Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Receiving Remote Desktop Traffic
description = This search counts the numbers of times the system has created remote desktop traffic
action.escu.creation_date = 2017-09-15
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = []
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search counts the numbers of times the system has created remote desktop traffic
action.escu.how_to_implement = To successfully implement this search you must ingest network traffic and populate the Network_Traffic data model. If a system receives a lot of remote desktop traffic, you can apply the category common_rdp_destination to it.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.dest | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Using Remote Desktop]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Using Remote Desktop
description = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = []
action.escu.data_models = ["Endpoint"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that records process activity.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Endpoint.Processes where Processes.process_name="*mstsc.exe*" by Processes.dest Processes.process_name | `drop_dm_object_name(Processes)` | sort - count

[ESCU - Monitor Successful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Successful Backups
description = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
disabled = true
is_visible = false
search = `netbackup` "Disk/Partition backup completed successfully." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Monitor Unsuccessful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Unsuccessful Backups
description = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
disabled = true
is_visible = false
search = `netbackup` "An error occurred, failed to backup." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Previously Seen AWS Cross Account Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Cross Account Activity
description = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.creation_date = 2018-06-04
action.escu.modification_date = 2018-06-04
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId!=requestedAccountId | stats earliest(_time) as firstTime latest(_time) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | stats count

[ESCU - Previously Seen AWS Provisioning Activity Sources]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Provisioning Activity Sources
description = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats count

[ESCU - Previously Seen AWS Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Regions
description = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` StartInstances | stats earliest(_time) as earliest latest(_time) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | stats count

[ESCU - Previously Seen Cloud Compute Creations By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Creations By User
description = This search builds a table of previously seen users that have launched a cloud compute instance.
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-15
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen users that have launched a cloud compute instance.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `previously_seen_cloud_compute_creations_by_user_input_filter` by Compute.src_user | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_compute_creations_by_user | stats count

[ESCU - Previously Seen Cloud Compute Images]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Images
description = This search builds a table of previously seen images used to launch cloud compute instances
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen images used to launch cloud compute instances
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `previously_seen_cloud_compute_image_input_filter` by Compute.image_id | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_compute_images | stats count

[ESCU - Previously Seen Cloud Compute Instance Types]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Instance Types
description = This search builds a table of previously seen cloud compute instance types
action.escu.creation_date = 2019-10-03
action.escu.modification_date = 2019-10-03
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen cloud compute instance types
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `previously_seen_cloud_compute_instance_types_input_filter` by Compute.instance_type | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_compute_instance_types | stats count

[ESCU - Previously Seen Cloud Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Regions
description = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
action.escu.creation_date = 2019-10-02
action.escu.modification_date = 2019-10-02
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=start `previously_seen_cloud_regions_input_filter` by Compute.region | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_regions | stats count

[ESCU - Previously Seen EC2 AMIs]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 AMIs
description = This search builds a table of previously seen AMIs used to launch EC2 instances
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen AMIs used to launch EC2 instances
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success | rename requestParameters.instancesSet.items{}.imageId as amiID | stats earliest(_time) as firstTime latest(_time) as lastTime by amiID | outputlookup previously_seen_ec2_amis.csv | stats count

[ESCU - Previously Seen EC2 Instance Types]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Instance Types
description = This search builds a table of previously seen EC2 instance types
action.escu.creation_date = 2018-03-08
action.escu.modification_date = 2018-03-08
action.escu.analytic_story = ["AWS Cryptomining"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen EC2 instance types
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success | rename requestParameters.instanceType as instanceType | fillnull value="m1.small" instanceType | stats earliest(_time) as earliest latest(_time) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | stats count

[ESCU - Previously Seen EC2 Launches By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Launches By User
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-15
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success | rename userIdentity.arn as arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | stats count

[ESCU - Previously Seen EC2 Modifications By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Modifications By User
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-04-05
action.escu.modification_date = 2018-04-05
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
disabled = true
is_visible = false
search = `cloudtrail` `ec2_modification_api_calls` errorCode=success | spath output=arn userIdentity.arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | stats count

[ESCU - Previously Seen Running Windows Services - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Running Windows Services - Initial
description = This collects the services that have been started across your entire enterprise.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.analytic_story = ["Orangeworm Attack Group", "Windows Service Abuse"]
action.escu.data_models = []
cron_schedule = 0 4 * * *
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This collects the services that have been started across your entire enterprise.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.
disabled = true
is_visible = false
search = `wineventlog_system` EventCode=7036 | rex field=Message "The (?<service>[-\(\)\s\w]+) service entered the (?<state>\w+) state" | where state="running" | stats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen by service | outputlookup previously_seen_running_windows_services

[ESCU - Previously Seen Running Windows Services - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Running Windows Services - Update
description = This search returns the first and last time a Windows service was seen across your enterprise within the last hour. It then updates this information with historical data and filters out Windows services pairs that have not been seen within the specified time window. This updated table is then cached.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.analytic_story = ["Orangeworm Attack Group", "Windows Service Abuse"]
action.escu.data_models = []
cron_schedule = 55 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search returns the first and last time a Windows service was seen across your enterprise within the last hour. It then updates this information with historical data and filters out Windows services pairs that have not been seen within the specified time window. This updated table is then cached.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.
disabled = true
is_visible = false
search = `wineventlog_system` EventCode=7036 | rex field=Message "The (?<service>[-\(\)\s\w]+) service entered the (?<state>\w+) state" | where state="running" | stats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen by service | inputlookup previously_seen_running_windows_services append=t | stats min(firstTimeSeen) as firstTimeSeen, max(lastTimeSeen) as lastTimeSeen by service | where lastTimeSeen > relative_time(now(), "`previously_seen_windows_service_forget_window`") | outputlookup previously_seen_running_windows_services

[ESCU - Previously Seen Zoom Child Processes - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Zoom Child Processes - Initial
description = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS). This table is then cached.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.analytic_story = ["Suspicious Zoom Child Processes"]
action.escu.data_models = ["Endpoint"]
cron_schedule = 0 4 * * *
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS). This table is then cached.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTimeSeen max(_time) as lastTimeSeen from datamodel=Endpoint.Processes where (Processes.parent_process_name=zoom.exe OR Processes.parent_process_name=zoom.us) by Processes.process_name Processes.dest| `drop_dm_object_name(Processes)` | table dest, process_name, firstTimeSeen, lastTimeSeen | outputlookup zoom_first_time_child_process

[ESCU - Previously Seen Zoom Child Processes - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Zoom Child Processes - Update
description = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS) within the last hour. It then updates this information with historical data and filters out proces_name and endpoint pairs that have not been seen within the specified time window. This updated table is outputed to disk.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.analytic_story = ["Suspicious Zoom Child Processes"]
action.escu.data_models = ["Endpoint"]
cron_schedule = 55 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS) within the last hour. It then updates this information with historical data and filters out proces_name and endpoint pairs that have not been seen within the specified time window. This updated table is outputed to disk.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTimeSeen max(_time) as lastTimeSeen from datamodel=Endpoint.Processes where (Processes.parent_process_name=zoom.exe OR Processes.parent_process_name=zoom.us) by Processes.process_name Processes.dest| `drop_dm_object_name(Processes)` | table firstTimeSeen, lastTimeSeen, process_name, dest | inputlookup zoom_first_time_child_process append=t | stats min(firstTimeSeen) as firstTimeSeen max(lastTimeSeen) as lastTimeSeen by process_name, dest | where lastTimeSeen > relative_time(now(), "`previously_seen_zoom_child_processes_forget_window`") | outputlookup zoom_first_time_child_process

[ESCU - Previously seen API call per user roles in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen API call per user roles in CloudTrail
description = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset--grouped by user role and name of the API call--that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
action.escu.creation_date = 2018-04-16
action.escu.modification_date = 2018-04-16
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset--grouped by user role and name of the API call--that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user role entries in `previously_seen_api_calls_from_user_roles.csv`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles | stats count

[ESCU - Previously seen S3 bucket access by remote IP]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen S3 bucket access by remote IP
description = This search looks for successful access to S3 buckets from remote IP addresses, then creates a baseline of the earliest and latest times we have encountered this remote IP within the last 30 days. In this support search, we are only looking for S3 access events where the HTTP response code from AWS is "200"
action.escu.creation_date = 2018-06-28
action.escu.modification_date = 2018-06-28
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for successful access to S3 buckets from remote IP addresses, then creates a baseline of the earliest and latest times we have encountered this remote IP within the last 30 days. In this support search, we are only looking for S3 access events where the HTTP response code from AWS is "200"
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access-logs inputs. You must validate the remote IP and bucket name entries in `previously_seen_S3_access_from_remote_ip.csv`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `aws_s3_accesslogs` http_status=200  | stats  earliest(_time) as earliest latest(_time) as latest by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip | stats count

[ESCU - Previously seen command line arguments]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen command line arguments
description = This search looks for command-line arguments where `cmd.exe /c` is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
action.escu.creation_date = 2019-03-01
action.escu.modification_date = 2019-03-01
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Hidden Cobra Malware", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity"]
action.escu.data_models = ["Endpoint"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for command-line arguments where `cmd.exe /c` is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe AND Processes.process="* /c *" by Processes.process | `drop_dm_object_name(Processes)`

[ESCU - Previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen users in CloudTrail
description = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last 30 days.
action.escu.creation_date = 2018-04-30
action.escu.modification_date = 2018-04-30
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last 30 days.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins.csv`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventName=ConsoleLogin | rename userIdentity.arn as user | iplocation src | eval City=if(City LIKE "",src,City),Region=if(Region LIKE "",src,Region) | stats earliest(_time) as firstTime latest(_time) as lastTime by user src City Region Country | outputlookup previously_seen_users_console_logins.csv | stats count

[ESCU - Previously seen users in CloudTrail - DM]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen users in CloudTrail - DM
description = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by username, within the last 30 days.
action.escu.creation_date = 2020-05-28
action.escu.modification_date = 2020-05-28
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.escu.data_models = ["Authentication"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by username, within the last 30 days.
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_users_console_logins.csv`, which is a lookup file created by this support search.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | rename Authentication.user as user Authentication.src as src | table user src City Region Country firstTime lastTime | outputlookup previously_seen_users_console_logins.csv | stats count

[ESCU - Systems Ready for Spectre-Meltdown Windows Patch]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Systems Ready for Spectre-Meltdown Windows Patch
description = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - Update previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Update previously seen users in CloudTrail
description = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last hour.
action.escu.creation_date = 2018-04-30
action.escu.modification_date = 2018-04-30
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last hour.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins.csv`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventName=ConsoleLogin | rename userIdentity.arn as user | iplocation src | eval City=if(City LIKE "",src,City),Region=if(Region LIKE "",src,Region) | stats earliest(_time) AS firstTime latest(_time) AS lastTime by user src City Region Country | inputlookup append=t previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user src City Region Country | outputlookup previously_seen_users_console_logins.csv

[ESCU - Update previously seen users in CloudTrail - DM]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Update previously seen users in CloudTrail - DM
description = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by user, within the last hour.
action.escu.creation_date = 2020-05-28
action.escu.modification_date = 2020-05-28
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.escu.data_models = ["Authentication"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by user, within the last hour.
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_users_console_logins.csv`, which is a lookup file created by this support search.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authenticaiton.src | iplocation Authentication.src | rename Authentication.user as user Authentciation.src as src | table user src City Region Country firstTime lastTime | inputlookup append=t previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user src City Region Country | outputlookup previously_seen_users_console_logins.csv

[ESCU - Windows Updates Install Failures]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Failures
description = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-09-14
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = []
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=failure by _time span=1d

[ESCU - Windows Updates Install Successes]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Successes
description = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-09-14
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = []
action.escu.data_models = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=installed by _time span=1d



### ESCU RESPONSE TASKS ###

[ESCU - AWS Investigate Security Hub alerts by dest - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate Security Hub alerts by dest
description = This search retrieves the all the alerts created by AWS Security Hub for a specific dest(instance_id).
action.escu.creation_date = 2020-06-08
action.escu.modification_date = 2020-06-08
action.escu.analytic_story = ["Cloud Compute Instance", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves the all the alerts created by AWS Security Hub for a specific dest(instance_id).
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="aws:securityhub:firehose" "findings{}.Resources{}.Type"=AWSEC2Instance | rex field=findings{}.Resources{}.Id .*instance/(?<instance>.*) | search instance = $dest$ |rename findings{}.* as * | rename Remediation.Recommendation.Text as Remediation |  table instance Title ProductArn Description FirstObservedAt RecordState Remediation

[ESCU - AWS Investigate User Activities By ARN - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By ARN
description = This search lists all the logged CloudTrail activities by a specific user ARN and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and all the user's identity information.
action.escu.creation_date = 2019-04-30
action.escu.modification_date = 2019-04-30
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "Cloud Cryptomining", "Command and Control", "Suspicious AWS EC2 Activities", "Suspicious AWS Login Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Unusual AWS EC2 Modifications", "AWS Security Hub Alerts"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the logged CloudTrail activities by a specific user ARN and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and all the user's identity information.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.arn=$user$ | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType

[ESCU - AWS Investigate User Activities By AccessKeyId - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By AccessKeyId
description = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific credentials.
action.escu.creation_date = 2018-06-08
action.escu.modification_date = 2018-06-08
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific credentials.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.accessKeyId=$accessKeyId$ | spath output=user path=userIdentity.arn  | rename sourceIPAddress as src_ip | table _time, user, src_ip, awsRegion, eventName, errorCode, errorMessage

[ESCU - AWS Investigate User Activities By Source User - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By Source User
description = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific ARNs.
action.escu.creation_date = 2018-06-08
action.escu.modification_date = 2018-06-08
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific ARNs.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.arn=$src_user$ | spath output=user path=userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, awsRegion, eventName, errorCode, errorMessage

[ESCU - AWS Network ACL Details from ID - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network ACL Details from ID
description = This search queries AWS description logs and returns all the information about a specific network ACL via network ACL ID
action.escu.creation_date = 2017-01-22
action.escu.modification_date = 2017-01-22
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS description logs and returns all the information about a specific network ACL via network ACL ID
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:description id=$networkAclId$ | table id account_id vpc_id network_acl_entries{}.*

[ESCU - AWS Network Interface details via resourceId - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network Interface details via resourceId
description = This search queries AWS configuration logs and returns the information about a specific network interface via network interface ID. The information will include the ARN of the network interface, its relationships with other AWS resources, the public and the private IP associated with the network interface.
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS configuration logs and returns the information about a specific network interface via network interface ID. The information will include the ARN of the network interface, its relationships with other AWS resources, the public and the private IP associated with the network interface.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config resourceId=$resourceId$ | table _time ARN relationships{}.resourceType relationships{}.name relationships{}.resourceId  configuration.privateIpAddresses{}.privateIpAddress configuration.privateIpAddresses{}.association.publicIp

[ESCU - AWS S3 Bucket details via bucketName - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS S3 Bucket details via bucketName
description = This search queries AWS configuration logs and returns the information about a specific S3 bucket. The information returned includes the time the S3 bucket was created, the resource ID, the region it belongs to, the value of action performed, AWS account ID, and configuration values of the access-control lists associated with the bucket.
action.escu.creation_date = 2018-06-26
action.escu.modification_date = 2018-06-26
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS configuration logs and returns the information about a specific S3 bucket. The information returned includes the time the S3 bucket was created, the resource ID, the region it belongs to, the value of action performed, AWS account ID, and configuration values of the access-control lists associated with the bucket.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config resourceId=$bucketName$ | table resourceCreationTime resourceId awsRegion action aws_account_id supplementaryConfiguration.AccessControlList

[ESCU - All backup logs for host - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - All backup logs for host
description = Retrieve the backup logs for the last 2 weeks for a specific host in order to investigate why backups are not completing successfully.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = Retrieve the backup logs for the last 2 weeks for a specific host in order to investigate why backups are not completing successfully.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" dest=$dest$

[ESCU - Amazon EKS Kubernetes activity by src ip - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Amazon EKS Kubernetes activity by src ip
description = This search provides investigation data about requests via user agent, authentication request URI, verb and cluster name data against Kubernetes cluster from a specific IP address
action.escu.creation_date = 2020-04-13
action.escu.modification_date = 2020-04-13
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search provides investigation data about requests via user agent, authentication request URI, verb and cluster name data against Kubernetes cluster from a specific IP address
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="aws:cloudwatchlogs:eks" sourceIPs{}=$src_ip$|rename sourceIPs{} as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(user.username) values(requestURI) values(verb) values(userAgent) by source annotations.authorization.k8s.io/decision src_ip

[ESCU - GCP Kubernetes activity by src ip - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - GCP Kubernetes activity by src ip
description = This search provides investigation data about requests via user agent, authentication request URI, resource path and cluster name data against Kubernetes cluster from a specific IP address
action.escu.creation_date = 2020-04-13
action.escu.modification_date = 2020-04-13
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search provides investigation data about requests via user agent, authentication request URI, resource path and cluster name data against Kubernetes cluster from a specific IP address
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="google:gcp:pubsub:message" data.protoPayload.requestMetadata.callerIp={src_ip} | rename data.protoPayload.requestMetadata.callerIp as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(data.protoPayload.methodName) as method_names values(data.protoPayload.resourceName) as resource_name values(data.protoPayload.requestMetadata.callerSuppliedUserAgent) as http_user_agent values(data.protoPayload.authenticationInfo.principalEmail) as user values(data.protoPayload.status.message) by src_ip data.resource.labels.cluster_name data.resource.type

[ESCU - Get All AWS Activity From City - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From City
description = This search retrieves all the activity from a specific city and will create a table containing the time, city, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific city and will create a table containing the time, city, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search City=$City$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, City, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Country - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Country
description = This search retrieves all the activity from a specific country and will create a table containing the time, country, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific country and will create a table containing the time, country, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Country=$Country$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Country, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From IP Address - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From IP Address
description = This search retrieves all the activity from a specific IP address and will create a table containing the time, ARN, username, the type of user, the IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Network ACL Activity", "AWS Suspicious Provisioning Activities", "Command and Control", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific IP address and will create a table containing the time, ARN, username, the type of user, the IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search sourceIPAddress=$src_ip$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Region - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Region
description = This search retrieves all the activity from a specific geographic region and will create a table containing the time, geographic region, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific geographic region and will create a table containing the time, geographic region, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Region=$Region$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Region, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get Authentication Logs For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Authentication Logs For Endpoint
description = This search returns all users that have attempted to access a particular endpoint.
action.escu.creation_date = 2017-11-01
action.escu.modification_date = 2017-11-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Host Redirection", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router and Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse", "Suspicious Zoom Child Processes"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search returns all users that have attempted to access a particular endpoint.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count from datamodel=Authentication where Authentication.dest=$dest$ by _time, Authentication.dest, Authentication.user, Authentication.app, Authentication.action | `drop_dm_object_name("Authentication")`

[ESCU - Get Backup Logs For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Backup Logs For Endpoint
description = This search will tell you the backup status from your netbackup_logs of a specific endpoint for the last week.
action.escu.creation_date = 2017-09-14
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search will tell you the backup status from your netbackup_logs of a specific endpoint for the last week.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" COMPUTERNAME=$dest$ | rename COMPUTERNAME as dest, MESSAGE as signature | table _time, dest, signature

[ESCU - Get Certificate logs for a domain - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Certificate logs for a domain
description = This search queries the Certificates datamodel and give you all the information for a specific domain. Please note that the certificates issued by "Let's Encrypt" are widely used by attackers.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.analytic_story = ["Common Phishing Frameworks"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the Certificates datamodel and give you all the information for a specific domain. Please note that the certificates issued by "Let's Encrypt" are widely used by attackers.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Certificates.All_Certificates where All_Certificates.SSL.ssl_subject_common_name=*$domain$  by All_Certificates.dest All_Certificates.src All_Certificates.SSL.ssl_issuer_common_name All_Certificates.SSL.ssl_subject_common_name All_Certificates.SSL.ssl_hash | `drop_dm_object_name(All_Certificates)` | `drop_dm_object_name(SSL)` | rename ssl_subject_common_name as domain | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get DNS Server History for a host - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS Server History for a host
description = While investigating any detections it is important to understand which and how many DNS servers a host has connected to in the past. This search uses data that is tagged as DNS and gives you a count and list of DNS servers that a particular host has connected to the previous 24 hours.
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "DNS Hijacking", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Host Redirection", "Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = While investigating any detections it is important to understand which and how many DNS servers a host has connected to in the past. This search uses data that is tagged as DNS and gives you a count and list of DNS servers that a particular host has connected to the previous 24 hours.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search tag=dns src_ip=$src_ip$ dest_port=53 | streamstats time_window=1d count values(dest_ip) as dcip by src_ip | table date_mday src_ip dcip count | sort -count

[ESCU - Get DNS traffic ratio - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS traffic ratio
description = This search calculates the ratio of DNS traffic originating and coming from a host to a list of DNS servers over the last 24 hours. A high value of this ratio could be very useful to quickly understand if a src_ip (host) is sending a high volume of data out via port 53, could be an indicator of data exfiltration via DNS.  
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search calculates the ratio of DNS traffic originating and coming from a host to a list of DNS servers over the last 24 hours. A high value of this ratio could be very useful to quickly understand if a src_ip (host) is sending a high volume of data out via port 53, could be an indicator of data exfiltration via DNS.  
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats allow_old_summaries=true sum(All_Traffic.bytes_out) as "bytes_out" sum(All_Traffic.bytes_in) as "bytes_in" from datamodel=Network_Traffic where nodename=All_Traffic All_Traffic.dest_port=53 All_Traffic.src=$src_ip$ All_Traffic.dest=$dest_ip$ | eval ratio = (bytes_out/bytes_in) | table ratio

[ESCU - Get EC2 Instance Details by instanceId - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Instance Details by instanceId
description = This search queries AWS description logs and returns all the information about a specific instance via the instanceId field
action.escu.creation_date = 2018-02-12
action.escu.modification_date = 2018-02-12
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "Unusual AWS EC2 Modifications", "AWS Security Hub Alerts"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS description logs and returns all the information about a specific instance via the instanceId field
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="aws:description" source="*:ec2_instances"| dedup id sortby -_time | search id=$instanceId$ | spath output=tags path=tags | eval tags=mvzip(key,value," = "), ip_address=if((ip_address == "null"),private_ip_address,ip_address) | table id, tags.Name, aws_account_id, placement, instance_type, key_name, ip_address, launch_time, state, vpc_id, subnet_id, tags | rename aws_account_id as "Account ID", id as ID, instance_type as Type, ip_address as "IP Address", key_name as "Key Pair", launch_time as "Launch Time", placement as "Availability Zone", state as State, subnet_id as Subnet, "tags.Name" as Name, vpc_id as VPC

[ESCU - Get EC2 Launch Details - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Launch Details
description = This search returns some of the launch details for a EC2 instance.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "AWS Security Hub Alerts"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns some of the launch details for a EC2 instance.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail responseElements.instancesSet.items{}.instanceId=$dest$ |rename userIdentity.arn as arn, responseElements.instancesSet.items{}.instanceId as instanceId, responseElements.instancesSet.items{}.privateIpAddress as privateIpAddress, responseElements.instancesSet.items{}.imageId as amiID, responseElements.instancesSet.items{}.architecture as architecture, responseElements.instancesSet.items{}.keyName as keyName | table arn, awsRegion, instanceId, architecture, privateIpAddress, amiID, keyName

[ESCU - Get Email Info - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Email Info
description = This search returns all the information Splunk might have collected a specific email message over the last 2 hours.
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all the information Splunk might have collected a specific email message over the last 2 hours.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search message_id=$message_id$

[ESCU - Get Emails From Specific Sender - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Emails From Specific Sender
description = This search returns all the emails from a specific sender over the last 24 and next hours.
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails", "Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all the emails from a specific sender over the last 24 and next hours.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search src_user=$src_user$

[ESCU - Get First Occurrence and Last Occurrence of a MAC Address - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get First Occurrence and Last Occurrence of a MAC Address
description = This search allows you to gather more context around a notable which has detected a new device connecting to your network. Use this search to determine the first and last occurrences of the suspicious device attempting to connect with your network.
action.escu.creation_date = 2017-09-13
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Network_Sessions"]
action.escu.eli5 = This search allows you to gather more context around a notable which has detected a new device connecting to your network. Use this search to determine the first and last occurrences of the suspicious device attempting to connect with your network.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST All_Sessions.All_Sessions.src_mac= $src_mac$ by All_Sessions.src_ip All_Sessions.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`

[ESCU - Get History Of Email Sources - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get History Of Email Sources
description = This search returns a list of all email sources seen in the 48 hours prior to the notable event to 24 hours after, and the number of emails from each source.
action.escu.creation_date = 2019-02-21
action.escu.modification_date = 2019-02-21
action.escu.analytic_story = []
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Email"]
action.escu.eli5 = This search returns a list of all email sources seen in the 48 hours prior to the notable event to 24 hours after, and the number of emails from each source.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = |tstats `security_content_summariesonly` values(All_Email.dest) as dest values(All_Email.recipient) as recepient  min(_time) as firstTime max(_time) as lastTime count from datamodel=Email.All_Email by All_Email.src |`drop_dm_object_name(All_Email)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Logon Rights Modifications For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For Endpoint
description = This search allows you to retrieve any modifications to logon rights associated with a specific host.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search allows you to retrieve any modifications to logon rights associated with a specific host.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) dest=$dest$ | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Logon Rights Modifications For User - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For User
description = This search allows you to retrieve any modifications to logon rights for a specific user account.
action.escu.creation_date = 2019-02-27
action.escu.modification_date = 2019-02-27
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search allows you to retrieve any modifications to logon rights for a specific user account.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) user=$user$ | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Notable History - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Notable History
description = This search queries the notable index and returns all the Notable Events for the particular destination host, giving the analyst an overview of the incidents that may have occurred with the host under investigation.
action.escu.creation_date = 2017-09-20
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cross Account Activity", "AWS Cryptomining", "AWS Network ACL Activity", "AWS User Monitoring", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "Cloud Cryptomining", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Kubernetes Scanning Activity", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router and Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Cloud Authentication Activities", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual AWS EC2 Modifications", "Unusual Processes", "Use of Cleartext Protocols", "Web Fraud Detection", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the notable index and returns all the Notable Events for the particular destination host, giving the analyst an overview of the incidents that may have occurred with the host under investigation.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search `notable` | search dest=$dest$ | table _time, rule_name, owner, priority, severity, status_description

[ESCU - Get Notable Info - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Notable Info
description = This search queries the notable index to retrieve detailed information captured within the notable. Every notable has a unique ID associated with it, which is used to point us directly to the notable event under investigation.
action.escu.creation_date = 2017-09-20
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "AWS User Monitoring", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "Cloud Cryptomining", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Kubernetes Scanning Activity", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router and Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Web Fraud Detection", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse", "Kubernetes Sensitive Role Activity", "Kubernetes Sensitive Object Access Activity", "F5 TMUI RCE CVE-2020-5902", "Windows DNS SIGRed CVE-2020-1350", "Suspicious GCP Storage Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the notable index to retrieve detailed information captured within the notable. Every notable has a unique ID associated with it, which is used to point us directly to the notable event under investigation.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search `notable_by_id($event_id$)` | table time, rule_name, dest, dest_asset_id, dest_owner, priority, severity, owner, status_description

[ESCU - Get Outbound Emails to Hidden Cobra Threat Actors - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Outbound Emails to Hidden Cobra Threat Actors
description = This search returns the information of the users that sent emails to the accounts controlled by the Hidden Cobra Threat Actors: specifically to `misswang8107@gmail.com`, and from `redhat@gmail.com`.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-06-14
action.escu.analytic_story = []
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns the information of the users that sent emails to the accounts controlled by the Hidden Cobra Threat Actors: specifically to `misswang8107@gmail.com`, and from `redhat@gmail.com`.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search recipient=misswang8107@gmail.com OR src_user=redhat@gmail.com | stats count earliest(_time) as firstTime, latest(_time) as lastTime values(dest) values(src) by src_user recipient | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Parent Process Info - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Parent Process Info
description = This search queries the Endpoint data model to give you details about the parent process of a process running on a host which is under investigation. Enter the values of the process name in question and the dest
action.escu.creation_date = 2019-02-28
action.escu.modification_date = 2019-02-28
action.escu.analytic_story = ["Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Phishing Payloads", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the Endpoint data model to give you details about the parent process of a process running on a host which is under investigation. Enter the values of the process name in question and the dest
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = $process_name$ Processes.dest = $dest$ by Processes.user Processes.parent_process_name  Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Get Process File Activity - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process File Activity
description = This search returns the file activity for a specific process on a specific endpoint
action.escu.creation_date = 2019-11-06
action.escu.modification_date = 2019-11-06
action.escu.analytic_story = ["DHS Report TA18-074A", "Suspicious Zoom Child Processes"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns the file activity for a specific process on a specific endpoint
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Filesystem.file_name) as file_name values(Filesystem.dest) as dest, values(Filesystem.process_id) as process_id from datamodel=Endpoint.Filesystem where Filesystem.dest=$dest$ Filesystem.process_id=$process_id$ by Filesystem.file_path, Filesystem.action, _time | `drop_dm_object_name(Filesystem)`  | sort _time | table _time, process_id, dest, action, file_name, file_path

[ESCU - Get Process Info - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Info
description = This search queries the Endpoint data model to give you details about the process running on a host which is under investigation. To gather the process info, enter the values for the process name in question and the destination IP address.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search queries the Endpoint data model to give you details about the process running on a host which is under investigation. To gather the process info, enter the values for the process name in question and the destination IP address.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Proceses.dest=$dest$ Proceses.process_name=$process_name$ by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` 

[ESCU - Get Process Information For Port Activity - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Information For Port Activity
description = This search will return information about the process associated with observed network traffic to a specific destination port from a specific host.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "DHS Report TA18-074A", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Lateral Movement", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious AWS Traffic", "Use of Cleartext Protocols"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search will return information about the process associated with observed network traffic to a specific destination port from a specific host.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest = $dest$ by Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` count from datamodel=Endpoint.Ports where Ports.dest_port=$dest_port$ by Ports.process_id Ports.src  | `drop_dm_object_name(Ports)` | rename src as dest]

[ESCU - Get Process Registry Activity - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Registry Activity
description = This search returns the registry activity for a specific process on a specific endpoint
action.escu.creation_date = 2019-11-06
action.escu.modification_date = 2019-11-06
action.escu.analytic_story = ["DHS Report TA18-074A", "Suspicious Zoom Child Processes"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns the registry activity for a specific process on a specific endpoint
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Registry.registry_key_name) as registry_key_name, values(Registry.dest) as dest, values(Registry.process_id) as process_id from datamodel=Endpoint.Registry where Registry.process_id=$process_id$ AND Registry.dest=$dest$ by Registry.registry_path, Registry.action, _time | `drop_dm_object_name(Registry)` | sort _time | table _time, process_id, dest, action, registry_key_name, registry_path

[ESCU - Get Process Responsible For The DNS Traffic - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Responsible For The DNS Traffic
description = While investigating, an analyst will want to know what process and parent_process is responsible for generating suspicious DNS traffic. Use the following search and enter the value of `dest` in the search to get specific details on the process responsible for creating the DNS traffic.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Brand Monitoring", "Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = While investigating, an analyst will want to know what process and parent_process is responsible for generating suspicious DNS traffic. Use the following search and enter the value of `dest` in the search to get specific details on the process responsible for creating the DNS traffic.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest = $dest$ by Processes.parent_process Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` count from datamodel=Endpoint.Ports where Ports.dest_port=53 by Ports.process_id Ports.src | `drop_dm_object_name(Ports)` | rename src as dest]

[ESCU - Get Registry Activities - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Registry Activities
description = This search queries the Endpoint Datamodel to give you details of the latest registry values for a specific destination computer.
action.escu.creation_date = 2019-03-01
action.escu.modification_date = 2019-03-01
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware  DHS Report TA18-201A ", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Persistence Techniques", "Windows Privilege Escalation"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the Endpoint Datamodel to give you details of the latest registry values for a specific destination computer.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Registry.registry_path) as registry_path values(Registry.registry_key_name) as registry_key_name count FROM datamodel=Endpoint.Registry where Registry.dest = "$dest$" by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | join [| tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name = reg.exe by Processes.process_id | `drop_dm_object_name("Processes")`]

[ESCU - Get Risk Modifiers For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Risk Modifiers For Endpoint
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk\_scores, names of the correlation searches that contributed to create a risk score for a specific endpoint(machine\_name) 
action.escu.creation_date = 2017-10-19
action.escu.modification_date = 2017-10-19
action.escu.analytic_story = ["AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Kubernetes Scanning Activity", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router and Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk\_scores, names of the correlation searches that contributed to create a risk score for a specific endpoint(machine\_name) 
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Risk.All_Risk | search risk_object_type=system risk_object=$dest$ | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Risk Modifiers For User - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Risk Modifiers For User
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk_scores, names of the correlation searches that contributed to create a risk score for a specific user 
action.escu.creation_date = 2017-10-19
action.escu.modification_date = 2017-10-19
action.escu.analytic_story = ["AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Host Redirection", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router and Infrastructure Security", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk_scores, names of the correlation searches that contributed to create a risk score for a specific user 
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Risk.All_Risk | search risk_object_type=user risk_object=$user$ | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` 

[ESCU - Get Sysmon WMI Activity for Host - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Sysmon WMI Activity for Host
description = This search queries Sysmon WMI events for the host of interest.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries Sysmon WMI events for the host of interest.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" EventCode>18 EventCode<22 host=$dest$ | rename host as dest | table _time, dest, user, Name, Operation, EventType, Type, Query, Consumer, Filter

[ESCU - Get Update Logs For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Update Logs For Endpoint
description = This search will tell you give you the update logs for a specific endpoint for the last week.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-08-24
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Monitor for Unauthorized Software", "Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search will tell you give you the update logs for a specific endpoint for the last week.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Updates.Updates  | search (vendor_product="Microsoft Windows" OR vendor_product="OSX:Update" OR vendor_product="Linux:Update") dest=$dest$

[ESCU - Get User Information from Identity Table - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get User Information from Identity Table
description = Gather more information about the user identified in the Notable Event.
action.escu.creation_date = 2017-09-20
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "Cloud Cryptomining", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Host Redirection", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router and Infrastructure Security", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = Gather more information about the user identified in the Notable Event.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | `identities` | search identity=$user$ | table _time, identity, first, last, email, category, watchlist

[ESCU - Get Vulnerability Logs For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Vulnerability Logs For Endpoint
description = This search will show you any vulnerabilities noted for a specific endpoint for the last week.
action.escu.creation_date = 2017-09-10
action.escu.modification_date = 2017-09-10
action.escu.analytic_story = ["ColdRoot MacOS RAT", "DHS Report TA18-074A", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "JBoss Vulnerability", "Monitor for Unauthorized Software", "Ransomware", "SamSam Ransomware", "Windows Log Manipulation"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search will show you any vulnerabilities noted for a specific endpoint for the last week.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Vulnerabilities.Vulnerabilities | search dest=$dest$

[ESCU - Get Web Session Information via session id - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Web Session Information via session id
description = This search helps an analyst investigate a notable event to find out more about a specific web session. The search looks for a specific web session ID in the HTTP web traffic and outputs the URL and user agents, grouped by source IP address and HTTP status code.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search helps an analyst investigate a notable event to find out more about a specific web session. The search looks for a specific web session ID in the HTTP web traffic and outputs the URL and user agents, grouped by source IP address and HTTP status code.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http $session_id$ | stats values(url) values(http_user_agent) by src_ip status

[ESCU - Investigate AWS ECR container listing activity - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS ECR container listing activity
description = This search lists all the users performing a list image operation on AWS Elastic Container Registry. Listing source user, image id, source IP, user type, http user agent. This search also gives counts of unique user agents per listing source.
action.escu.creation_date = 2020-02-20
action.escu.modification_date = 2020-02-20
action.escu.analytic_story = ["Container Implantation Monitoring and Investigation"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the users performing a list image operation on AWS Elastic Container Registry. Listing source user, image id, source IP, user type, http user agent. This search also gives counts of unique user agents per listing source.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = |tstats count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Cloud_Infrastructure.Compute where Compute.user_type!="AssumeRole" AND Compute.event_name="ListImages" by Compute.image_id Compute.src_user Compute.src Compute.http_user_agent Compute.user_type | rename "Compute.*" as * |stats values(http_user_agent) as http_user_agent distinct_count(http_user_agent) as unique_ua_count by src_user, image_id, src, user_type | where unique_ua_count > 1

[ESCU - Investigate AWS User Activities by user field - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS User Activities by user field
description = This search lists all the logged CloudTrail activities by a specific user and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and the user's identity information.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS User Monitoring", "Suspicious Cloud Authentication Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the logged CloudTrail activities by a specific user and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and the user's identity information.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail user=$user$ | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType 

[ESCU - Investigate AWS activities via region name - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS activities via region name
description = This search lists all the user activities logged by CloudTrail for a specific region in question and will create a table of the values of parameters requested, the type of the event and the response from the AWS API by each user
action.escu.creation_date = 2018-02-09
action.escu.modification_date = 2018-02-09
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the user activities logged by CloudTrail for a specific region in question and will create a table of the values of parameters requested, the type of the event and the response from the AWS API by each user
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail awsRegion=$awsRegion$| rename requestParameters.instancesSet.items{}.instanceId as instanceId| stats values(eventName) by userName instanceId

[ESCU - Investigate Cloud Compute Instance Activities - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Cloud Compute Instance Activities
description = This search returns a logs of events that operated on the compute instance.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns a logs of events that operated on the compute instance.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Cloud_Infrastructure.Compute | search dest=$dest$ | fields - _*

[ESCU - Investigate Failed Logins for Multiple Destinations - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Failed Logins for Multiple Destinations
description = This search returns failed logins to multiple destinations by user.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search returns failed logins to multiple destinations by user.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count `security_content_summariesonly` earliest(_time) as first_login latest(_time) as last_login dc(Authentication.dest) AS distinct_count_dest values(Authentication.dest) AS Authentication.dest values(Authentication.app) AS Authentication.app  from datamodel=Authentication where Authentication.action=failure by Authentication.user | where distinct_count_dest > 1 | `security_content_ctime(first_login)` | `security_content_ctime(last_login)` | `drop_dm_object_name("Authentication")`

[ESCU - Investigate Network Traffic From src ip - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Network Traffic From src ip
description = This search allows you to find all the network traffic from a specific IP address.
action.escu.creation_date = 2018-06-15
action.escu.modification_date = 2018-06-15
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Splunk Enterprise Vulnerability CVE-2018-11409"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search allows you to find all the network traffic from a specific IP address.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Network_Traffic.All_Traffic | search src_ip=$src_ip$

[ESCU - Investigate Okta Activity by IP Address - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Okta Activity by IP Address
description = This search returns all okta events from a specific IP address.
action.escu.creation_date = 2020-04-02
action.escu.modification_date = 2020-04-02
action.escu.analytic_story = ["Suspicious Okta Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all okta events from a specific IP address.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = eventtype=okta_log src_ip={src_ip} | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, displayMessage, app, src_ip, state, city, result, outcome.reason

[ESCU - Investigate Okta Activity by app - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Okta Activity by app
description = This search returns all okta events associated with a specific app
action.escu.creation_date = 2020-04-02
action.escu.modification_date = 2020-04-02
action.escu.analytic_story = ["Suspicious Okta Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all okta events associated with a specific app
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = eventtype=okta_log app=$app$ | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, displayMessage, app, src_ip, state, city, result, outcome.reason

[ESCU - Investigate Pass the Hash Attempts - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Pass the Hash Attempts
description = This search hunts for dumped NTLM hashes used for pass the hash.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search hunts for dumped NTLM hashes used for pass the hash.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = `wineventlog_security` EventCode=4624 Logon_Type=9 AuthenticationPackageName=Negotiate | stats count earliest(_time) as first_login latest(_time) as last_login by src_user dest | `security_content_ctime(first_login)` | `security_content_ctime(last_login)`

[ESCU - Investigate Pass the Ticket Attempts - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Pass the Ticket Attempts
description = This search hunts for dumped kerberos ticket from LSASS memory.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search hunts for dumped kerberos ticket from LSASS memory.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = `wineventlog_security` EventCode=4768 OR EventCode=4769 | rex field=user "(?<new_user>[^\@]+)" | stats count BY new_user, dest, EventCode | stats max(count) AS max_count sum(count) AS sum_count BY new_user, dest | where sum_count/max_count!=2 | rename new_user AS user

[ESCU - Investigate Previous Unseen User - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Previous Unseen User
description = This search returns previous unseen user, which didn't log in for 30 days.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search returns previous unseen user, which didn't log in for 30 days.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count `security_content_summariesonly` earliest(_time) as first_login latest(_time) as last_login values(Authentication.dest) AS Authentication.dest values(Authentication.app) AS Authentication.app values(Authentication.action) AS Authentication.action from datamodel=Authentication where Authentication.action=success by _time, Authentication.user | bucket _time span=30d | stats count min(first_login) as first_login max(last_login) as last_login values(Authentication.dest) AS Authentication.dest by Authentication.user | where count=1 | where first_login >= relative_time(now(), "-30d") | `security_content_ctime(first_login)` | `security_content_ctime(last_login)` | `drop_dm_object_name("Authentication")`

[ESCU - Investigate Successful Remote Desktop Authentications - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Successful Remote Desktop Authentications
description = This search returns the source, destination, and user for all successful remote-desktop authentications. A successful authentication after a brute-force attack on a destination machine is suspicious behavior. 
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search returns the source, destination, and user for all successful remote-desktop authentications. A successful authentication after a brute-force attack on a destination machine is suspicious behavior. 
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Authentication where Authentication.signature_id=4624 Authentication.app=win:remote by Authentication.src Authentication.dest Authentication.app Authentication.user Authentication.signature Authentication.src_nt_domain | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("Authentication")`| table firstTime lastTime src src_nt_domain dest user app count | sort count

[ESCU - Investigate Suspicious Strings in HTTP Header - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Suspicious Strings in HTTP Header
description = This search helps an analyst investigate a notable event related to a potential Apache Struts exploitation. To investigate, we will want to isolate and analyze the "payload" or the commands that were passed to the vulnerable hosts by creating a few regular expressions to carve out the commands focusing on common keywords from the payload, such as cmd.exe, /bin/bash and whois. The search returns these suspicious strings found in the HTTP logs of the system of interest.
action.escu.creation_date = 2017-10-20
action.escu.modification_date = 2017-10-20
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search helps an analyst investigate a notable event related to a potential Apache Struts exploitation. To investigate, we will want to isolate and analyze the "payload" or the commands that were passed to the vulnerable hosts by creating a few regular expressions to carve out the commands focusing on common keywords from the payload, such as cmd.exe, /bin/bash and whois. The search returns these suspicious strings found in the HTTP logs of the system of interest.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http src_ip="$src_ip$" dest_ip="$dest_ip$" | eval cs_content_type_length = len(cs_content_type) | search cs_content_type_length > 100 | rex field="cs_content_type" (?<suspicious_strings>cmd.exe) | eval suspicious_strings_found=if(match(cs_content_type, "application"), "True", "False")  | rename suspicious_strings_found AS "Suspicious Content-Type Found" | fields "Suspicious Content-Type Found", dest_ip, src_ip, suspicious_strings, cs_content_type, cs_content_type_length, url

[ESCU - Investigate User Activities In All Cloud Regions - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate User Activities In All Cloud Regions
description = This search lists all the logged cloud infrastructure activities by a specific cloud user
action.escu.creation_date = 2019-04-30
action.escu.modification_date = 2019-04-30
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the logged cloud infrastructure activities by a specific cloud user
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Cloud_Infrastructure.Compute | search user=$src_user$ | fields - _*

[ESCU - Investigate User Activities In Okta - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate User Activities In Okta
description = This search returns all okta events by a specific user
action.escu.creation_date = 2020-04-02
action.escu.modification_date = 2020-04-02
action.escu.analytic_story = ["Suspicious Okta Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all okta events by a specific user
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = eventtype=okta_log user=$user$ | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, displayMessage, app, src_ip, state, city, result, outcome.reason

[ESCU - Investigate User Activities In Single Cloud Region - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate User Activities In Single Cloud Region
description = This search lists all the logged cloud infrastructure activities by a specific cloud user in a specific cloud region
action.escu.creation_date = 2019-04-30
action.escu.modification_date = 2019-04-30
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the logged cloud infrastructure activities by a specific cloud user in a specific cloud region
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Cloud_Infrastructure.Compute | search region=$region$ user=$src_user$ | fields - _*

[ESCU - Investigate Web Activity From Host - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web Activity From Host
description = This search allows you to find all the web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "JBoss Vulnerability", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search allows you to find all the web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Web.Web | search src=$dest$

[ESCU - Investigate Web Activity From src ip - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web Activity From src ip
description = This search searches for all web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.creation_date = 2018-06-15
action.escu.modification_date = 2018-06-15
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Dynamic DNS", "Splunk Enterprise Vulnerability CVE-2018-11409"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search searches for all web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Web.Web | search src=$src_ip$

[ESCU - Investigate Web POSTs From src - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web POSTs From src
description = This investigative search retrieves POST requests from a specified source IP or hostname. Identifying the POST requests, as well as their associated destination URLs and user agent(s), may help you scope and characterize the suspicious traffic. 
action.escu.creation_date = 2018-12-06
action.escu.modification_date = 2018-12-06
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Web"]
action.escu.eli5 = This investigative search retrieves POST requests from a specified source IP or hostname. Identifying the POST requests, as well as their associated destination URLs and user agent(s), may help you scope and characterize the suspicious traffic. 
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Web.url) as url from datamodel=Web by Web.src,Web.http_user_agent,Web.http_method | `drop_dm_object_name("Web")`| where like(src, "$src$") and like(http_method, "POST")

[ESCU - Process Chain Analysis - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Process Chain Analysis
description = Analyze the Process Chain and identify the malicious file. By analyzing the parent process guid and searching for the process guid, the spawning process chain can be identified.
action.escu.creation_date = 2020-04-29
action.escu.modification_date = 2020-04-29
action.escu.analytic_story = []
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = Analyze the Process Chain and identify the malicious file. By analyzing the parent process guid and searching for the process guid, the spawning process chain can be identified.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = `sysmon` EventCode=1 NOT process=*Splunk* | rename process_guid AS out_process_guid process_name AS out_process_name parent_process_guid AS out_parent_process_guid parent_process_name AS out_parent_process_name | stats count by out_process_guid out_process_name out_parent_process_guid out_parent_process_name | eval join_process_guid = out_process_guid | join join_process_guid [ search `sysmon` process_guid={process_guid} EventCode=1 | rename process_name AS sub_process_name process_guid AS sub_process_guid parent_process_name AS sub_parent_process_name parent_process_guid AS sub_parent_process_guid | stats count by sub_process_name sub_process_guid sub_parent_process_name sub_parent_process_guid | eval join_process_guid = sub_parent_process_guid] | rename sub_process_guid AS process_guid sub_process_name AS process_name out_process_guid AS parent_process_guid out_process_name AS parent_process_name out_parent_process_guid AS grandparent_process_guid out_parent_process_name AS grandparent_process_name | stats count by process_guid process_name parent_process_guid parent_process_name grandparent_process_guid grandparent_process_name | head 1 | fields - count



### END ESCU RESPONSE TASKS ###

### USAGE DASHBOARD CONFIGURATIONS ###

[escu-metrics-usage]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
`comment("Find all the search names in the audittrail.")`\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name=="","Adhoc","Scheduled")) \
`comment("If the savedsearch_name field in the audittrail is empty, the search was run adhoc. Otherwise it was run as a scheduled search")`\
| rex field=search "\"(?<savedsearch_name>.*)\""\
`comment("Extract the name of the search from the search string")`\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*

[escu-metrics-search]
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
enableSched = 1
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_audit action=search | transaction search_id maxspan=3m | search ESCU | stats sum(total_run_time) avg(total_run_time) max(total_run_time) sum(result_count)

[escu-metrics-search-events]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
enableSched = 1
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = [search index=_audit sourcetype="audittrail" \"ESCU NOT "index=_audit" | where search !="" | dedup search_id | rex field=search "\"(?<search_name>.*)\"" | rex field=_raw "user=(?<user>[a-zA-Z0-9_\-]+)" | eval usage=if(savedsearch_name!="", "scheduled", "adhoc") | eval savedsearch_name=if(savedsearch_name != "", savedsearch_name, search_name) | table savedsearch_name search_id user _time usage | outputlookup escu_search_id.csv | table search_id] index=_audit total_run_time event_count result_count NOT "index=_audit" | lookup escu_search_id.csv search_id | stats count(savedsearch_name) AS search_count avg(total_run_time) AS search_avg_run_time sum(total_run_time) AS search_total_run_time sum(result_count) AS search_total_results earliest(_time) AS firsts latest(_time) AS lasts by savedsearch_name user usage| eval first_run=strftime(firsts, "%B %d %Y") | eval last_run=strftime(lasts, "%B %d %Y")

[escu-metrics-search-longest-runtime]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
enableSched = 1
cron_schedule = 0 0 * * *
disabled = 1
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_* ESCU [search index=_* action=search latest=-2h earliest=-1d| transaction search_id maxspan=3m | search ESCU | stats values(total_run_time) AS run by search_id | sort -run | head 1| table search_id] | table search search_id

[escu-metrics-usage-search]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
enableSched = 1
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
`comment("Find all the search names in the audittrail. Ignore the last few minutes so we can exclude this search's text from the result.")`\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name=="","Adhoc","Scheduled")) \
`comment("If the savedsearch_name field in the audittrail is empty, the search was run adhoc. Otherwise it was run as a scheduled search")`\
| rex field=search "\"(?<savedsearch_name>.*)\""\
`comment("Extract the name of the search from the search string")`\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*

### END OF USAGE DASHBOARD CONFIGURATIONS ###