#############
# Automatically generated by generator.py in splunk/security-content
# On Date: 2019-12-19T20:12:45 UTC
# Author: Splunk Security Research
# Contact: research@splunk.com
#############

### ESCU DETECTIONS ###


[ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen cities.  Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each city. It returns only those events from cities that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new city is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your city, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen City
action.notable = 1
action.notable.param.nes_fields = src_ip, city
action.notable.param.rule_description = Your AWS infrastructure was provisioned from a city, $city$, which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $city$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by City | eval newCity=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCity=1 | table City] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, City, eventName, errorCode

[ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each country. It returns only those events from countries that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching over plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new country is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen Country
action.notable = 1
action.notable.param.nes_fields = src_ip, country
action.notable.param.rule_description = Your AWS infrastructure was provisioned from a country, $country$,  which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $country$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Country | eval newCountry=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCountry=1 | table Country] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Country, eventName, errorCode

[ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each city. It returns only those events from IP addresses that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen IP Address
action.notable = 1
action.notable.param.nes_fields = src_ip
action.notable.param.rule_description = Your AWS infrastructure was provisioned from an IP, $src_ip$, which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $src_ip$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | table sourceIPAddress] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, eventName, errorCode

[ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen regions. Region in this context is similar to a state in the United States. Provisioning activities are defined broadly as any event that begins with "Run" or "Create."
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each city. It returns only those events from regions that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new region is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your region, there should be few false positives. If you are located in regions where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen Region
action.notable = 1
action.notable.param.nes_fields = src_ip, Region
action.notable.param.rule_description = Your AWS infrastructure was provisioned from a region, $Region$, which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $region$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Region | eval newRegion=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newRegion=1 | table Region] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Region, eventName, errorCode

[ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.eli5 = This search\
1. Retrieves the **AssumeRole** event\
1. Verifies that the log entry contains a value for the account ID of the requesting account\
1. Ensures that the requesting account ID does not match the account ID of the requested account\
1. Pulls in the previously seen requesting and requested account IDs\
1. Splits up and executes multiple search paths at the same.\
1. The first path determines the **firstTime** and **lastTime** entries for the cache file\
1. Outputs the data to the cache file.\
1. Creates a conditional statement that is always false (both because we don't want these values to exit the search pipeline and because we think we're clever).The second pipeline adds the **firstTime** and **lastTime** entries to search results. Next, it filters out any account pairs that haven't been seen for the first time within the last hour. The `isnotnull(_time)` will remove the entries from the cache file.\
The search finishes by gathering the data that it will display to the user.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the `Previously Seen AWS Cross Account Activity` support search only once to create the baseline of previously seen cross account activity. Thanks to Pablo Vega at Recurly for suggesting improvements to the search.
action.escu.known_false_positives = Using multiple AWS accounts and roles is perfectly valid behavior. It's suspicious when an account requests privileges of an account it hasn't before. You should validate with the account owner that this is a legitimate request.
action.escu.creation_date = 2018-02-01
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest_user"]
action.escu.entities = ["dest_user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cross Account Activity From Previously Unseen Account
action.notable = 1
action.notable.param.nes_fields = requestingAccountId, requestedAccountId, src_user, dest_user
action.notable.param.rule_description = Access to $dest_user$ was requested for the first time by $src_user$
action.notable.param.rule_title = AWS Account $dest_user$ access by $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = requestingAccountId, requestedAccountId
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId != requestedAccountId | inputlookup append=t previously_seen_aws_cross_account_activity | multireport [| stats min(eval(coalesce(firstTime, strptime(_time,"%Y-%m-%d %H:%M:%S")))) as firstTime max(eval(coalesce(strptime(_time,"%Y-%m-%d %H:%M:%S"), lastTime))) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | where fact=fiction] [| eventstats min(eval(coalesce(firstTime, strptime(_time,"%Y-%m-%d %H:%M:%S")))) as firstTime, max(eval(coalesce(strptime(_time,"%Y-%m-%d %H:%M:%S"), lastTime))) as lastTime by requestingAccountId, requestedAccountId | where firstTime >= relative_time(now(), "-70m@m") AND isnotnull(_time) | spath output=accessKeyId path=responseElements.credentials.accessKeyId | spath output=requestingARN path=resources{}.ARN | stats values(awsRegion) as awsRegion values(firstTime) as firstTime values(lastTime) as lastTime values(sharedEventID) as sharedEventID, values(requestingARN) as src_user, values(responseElements.assumedRoleUser.arn) as dest_user by _time, requestingAccountId, requestedAccountId, accessKeyId] | table _time, firstTime, lastTime, src_user, requestingAccountId, dest_user, requestedAccountId, awsRegion, accessKeyId, sharedEventID

[ESCU - AWS Network Access Control List Created with All Open Ports - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = A network access control list (ACL) is a layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. Network ACLs with all open ports have a larger attack surface. This search looks for events within your CloudTrail logs to check if there were any Network ACLs created with ports ranging from 1024 to 65525. This search will create a table comprised of AWS account id, src, user and all parameters of the request made by the user and the server response.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2017-01-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Network Access Control List Created with All Open Ports - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["src_user"]
action.escu.entities = ["src_user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Network Access Control List Created with All Open Ports
action.notable = 1
action.notable.param.nes_fields = aws_account_id, src, arn
action.notable.param.rule_description = $src_user$ created a network access control list with all ports open.
action.notable.param.rule_title = Network ACL created with all ports open by $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = arn
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = arn
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=CreateNetworkAclEntry | mvexpand requestParameters | mvexpand responseElements | search requestParameters.portRange.from=1024 requestParameters.portRange.to=65535 requestParameters.ruleAction=allow | rename userIdentity.arn as arn | rename requestParameters.networkAclId as networkAclId | table _time aws_account_id src userName arn networkAclId requestParameters.* responseElements.*

[ESCU - AWS Network Access Control List Deleted - Rule]
action.escu = 0
action.escu.enabled = 1
description = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = The search looks for CloudTrail events to detect whether any network ACLs have been deleted and gives you values of error messages and error codes (if any), user details, user source IP, the user who initiated this request, and the name of the event.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that a user has legitimately deleted a network ACL.
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2017-01-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Network Access Control List Deleted - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["arn"]
action.escu.entities = ["arn"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Network Access Control List Deleted
action.notable = 1
action.notable.param.nes_fields = arn, eventName
action.notable.param.rule_description = AWS network ACL has been deleted by $arn$.
action.notable.param.rule_title = AWS Network ACL deleted by $arn$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = arn
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = arn
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=DeleteNetworkAcl|rename userIdentity.arn as arn  | stats count min(_time) as firstTime max(_time) as lastTime values(errorMessage) values(errorCode) values(userAgent) values(userIdentity.*) by src userName arn eventName | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`

[ESCU - Abnormally High AWS Instances Launched by User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully launched by a particular user. Since we want to detect a high number of instances launched within a short period, we create event buckets for 10-minute windows. We then calculate the total number of instances launched by a particular user, as well as the average and standard deviation values. Assign a `threshold_value` in the search. Start with 3 (but it will likely need to be tweaked for your environment). The `eval` function will set the outlier 1 if the number of instances is greater than the average number of instances terminated, added to the multiplied value of threshold and standard deviation. For your reference, we then keep only the outliers and calculate the number of standard deviations away the value is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Launched by User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["userName"]
action.escu.entities = ["userName"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = */10 * * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Abnormally High AWS Instances Launched by User
action.notable = 1
action.notable.param.nes_fields = userName
action.notable.param.rule_description = An abnormally high number of instances were launched by a user within in a 10-minute window
action.notable.param.rule_title = High Number of instances launched by $userName$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = userName
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | bucket span=10m _time | stats count AS instances_launched by _time userName | eventstats avg(instances_launched) as total_launched_avg, stdev(instances_launched) as total_launched_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_launched > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m") | eval num_standard_deviations_away = round(abs(instances_launched - total_launched_avg) / total_launched_stdev, 2) | table _time, userName, instances_launched, num_standard_deviations_away, total_launched_avg, total_launched_stdev

[ESCU - Abnormally High AWS Instances Launched by User - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully launched by a particular user. Since we want to detect a high number of instances launched within a short period, we create event buckets for 10-minute windows. We then compare the total number of instances launched by a particular user against the saved baseline data in the model ec2_excessive_runinstances_v1.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Launched by User - MLTK - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["src_user"]
action.escu.entities = ["src_user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Cloud Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = */10 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Abnormally High AWS Instances Launched by User - MLTK
action.notable = 1
action.notable.param.nes_fields = src_user
action.notable.param.rule_description = An abnormally high number of instances were launched by a user within in a 10-minute window
action.notable.param.rule_title = High Number of instances launched by $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success `ec2_excessive_runinstances_mltk_input_filter` | bucket span=10m _time  | stats count as instances_launched by _time src_user  | apply ec2_excessive_runinstances_v1  | rename "IsOutlier(instances_launched)" as isOutlier  | where isOutlier=1

[ESCU - Abnormally High AWS Instances Terminated by User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where an abnormally high number of instances were successfully terminated by a user in a 10-minute window
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully terminated by a particular user. Since we want to detect a high number of instances terminated within a short period, we create event buckets for 10-minute windows. We then calculate the total number of instances terminated by a particular user, as well as the average- and standard-deviation values. Assign a `threshold_value` in the search. Try starting with 3 (but it will likely need to be tweaked for your environment). The `eval` function will set the outlier to 1 if the number of instances is greater than the average number of instances terminated, added to the multiplied value of threshold and standard deviation. We then filter out outliers with a value of 1 and show only those instance-termination events that happened within the previous 10 minutes.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = Many service accounts configured with your AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify whether this search alerted on a human user.
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Terminated by User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["userName"]
action.escu.entities = ["userName"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
cron_schedule = */10 * * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Abnormally High AWS Instances Terminated by User
action.notable = 1
action.notable.param.nes_fields = userName
action.notable.param.rule_description = An abnormally high number of instances were terminated by a user in a 10-minute window
action.notable.param.rule_title = High number of instances terminated by $userName$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = userName
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=TerminateInstances errorCode=success | bucket span=10m _time | stats count AS instances_terminated by _time userName | eventstats avg(instances_terminated) as total_terminations_avg, stdev(instances_terminated) as total_terminations_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_terminated > total_terminations_avg+(total_terminations_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m")| eval num_standard_deviations_away = round(abs(instances_terminated - total_terminations_avg) / total_terminations_stdev, 2) |table _time, userName, instances_terminated, num_standard_deviations_away, total_terminations_avg, total_terminations_stdev

[ESCU - Abnormally High AWS Instances Terminated by User - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user successfully terminates an abnormally high number of instances.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully terminated by a particular user. Since we want to detect a high number of instances terminated within a short period, we create event buckets for 10-minute windows. We then compare the total number of instances terminated by a particular user against the saved baseline data in the model ec2_excessive_terminateinstances_v1.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Terminated by User - MLTK - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["src_user"]
action.escu.entities = ["src_user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
cron_schedule = */10 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Abnormally High AWS Instances Terminated by User - MLTK
action.notable = 1
action.notable.param.nes_fields = src_user
action.notable.param.rule_description = An abnormally high number of instances were terminated by a user within in a 10-minute window
action.notable.param.rule_title = High Number of instances terminated by $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=TerminateInstances errorCode=success `ec2_excessive_terminateinstances_mltk_input_filter` | bucket span=10m _time  | stats count as instances_terminated by _time src_user  | apply ec2_excessive_terminateinstances_v1  | rename "IsOutlier(instances_terminated)" as isOutlier  | where isOutlier=1

[ESCU - Access LSASS Memory for Dump Creation - Rule]
action.escu = 0
action.escu.enabled = 1
description = Detect memory dumping of the LSASS process.
action.escu.mappings = {"cis20": ["CIS 6", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.eli5 = dbgcore.dll is a specifc DLL for Windows core debugging. It is used to obtain a memory dump of a process. This search detects the usage of this DLL for creating a memory dump of LSASS process. Memory dumps of the LSASS process can be created with tools such as Windows Task Manager or procdump.
action.escu.how_to_implement = This search requires Sysmon Logs and a Sysmon configuration, which includes EventCode 10 for lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Administrators can create memory dumps for debugging purposes, but memory dumps of the LSASS process would be unusual.
action.escu.creation_date = 2019-12-06
action.escu.modification_date = 2019-12-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Access LSASS Memory for Dump Creation - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Access LSASS Memory for Dump Creation
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Possible attempt at credential dumping was detected on $dest$.
action.notable.param.rule_title = LSASS memory dump detected on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = `sysmon` EventCode=10 TargetImage=*lsass.exe CallTrace=*dbgcore.dll* | stats count min(_time) as firstTime max(_time) as lastTime by Computer, TargetImage, TargetProcessId, SourceImage, SourceProcessId | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `access_lsass_memory_for_dump_creation_filter` 

[ESCU - Attempt To Add Certificate To Untrusted Store - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attempt to add a certificate to the untrusted certificate store
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Disabling Security Tools"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers will often attempt to disable security tools in order to evade detection. It is also possible for end users to attempt to disable anti-virus or other security tools to circumvent restrictions they encounter while trying to execute other programs. One way malware may accomplish this is by adding the legitimate certificate used to sign the security software to the untrusted certificate store. This will cause the system to no longer trust the software signed with this certificate and disallow it from executing. This search simply looks for the execution of **certutil.exe** with the parameters `-addcert` and `disallowed`, which add a certification to the "untrusted" certificate store.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = There may be legitimate reasons for administrators to add a certificate to the untrusted certificate store. In such cases, this will typically be done on a large number of systems.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Add Certificate To Untrusted Store - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempt To Add Certificate To Untrusted Store
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = Attempt to add a certificate to the untrusted certificate store
action.notable.param.rule_title = Attempt To Add Certificate to Untrusted Store
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process, dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=certutil.exe (Processes.process=*-addstore* AND Processes.process=*disallowed* ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`

[ESCU - Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass - Rule]
action.escu = 0
action.escu.enabled = 1
description = Monitor for changes of the ExecutionPolicy in the registry to the values "unrestricted" or "bypass," which allows the execution of malicious scripts.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Execution", "PowerShell", "Scripting"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for changes of the ExecutionPolicy in the registry. The ExecutionPolicy is a safety feature that controls the conditions under which PowerShell loads configuration files and runs scripts. Usually, the ExecutionPolicy is "Restricted" for Windows clients and "RemoteSigned" for Windows Servers, allowing only certain scripts to run. This search detects when an attacker sets the ExecutionPolicy to "Unrestricted" or "Bypass."
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Registry node. You must also be ingesting logs with the fields registry_path, registry_key_name, and registry_value_name from your endpoints.
action.escu.known_false_positives = Administrators may attempt to change the default execution policy on a system for a variety of reasons. However, setting the policy to "unrestricted" or "bypass" as this search is designed to identify, would be unusual. Hits should be reviewed and investigated as appropriate.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2019-12-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Credential Dumping", "Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass
action.notable = 1
action.notable.param.nes_fields = dest, registry_path, registry_key_name, registry_value_name
action.notable.param.rule_description = An attempt to modify the default PowerShell execution policy in the registry to "Unrestricted" or "Bypass" was detected on $dest$.
action.notable.param.rule_title = Attempt To Set PowerShell Execution Policy To "Unrestricted" or "Bypass" On $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process_name, dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Registry where Registry.registry_path=*Software\\Microsoft\\Powershell\\1\\ShellIds\\Microsoft.PowerShell* Registry.registry_key_name=ExecutionPolicy (Registry.registry_value_name=Unrestricted OR Registry.registry_value_name=Bypass) by Registry.registry_path Registry.registry_key_name Registry.registry_value_name Registry.dest | `drop_dm_object_name(Registry)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `attempt_to_set_default_powershell_execution_policy_to_unrestricted_or_bypass_filter`

[ESCU - Attempt To Stop Security Service - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for attempts to stop security-related services on the endpoint.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Disabling Security Tools"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the processes **net.exe** and **sc.exe** with a parameter of `"stop"`. It then searches a list of security-related services included in a lookup file for matches on the command line. Results are subsequently returned in table format. The included lookup file can be modified to update the services to monitor.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data. The search is shipped with a lookup file, `security_services.csv`, that can be edited to update the list of services to monitor. This lookup file can be edited directly where it lives in `$SPLUNK_HOME/etc/apps/DA-ESS-ContentUpdate/lookups`, or via the Splunk console. You should add the names of services an attacker might use on the command line and surround with asterisks (*****), so that they work properly when searching the command line. The file should be updated with the names of any services you would like to monitor for attempts to stop the service.,
action.escu.known_false_positives = None identified. Attempts to disable security-related services should be identified and understood.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2017-09-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Stop Security Service - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempt To Stop Security Service
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = Attempt to stop a security-related service on $dest$
action.notable.param.rule_title = Attempt to Stop Security Service On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name = net.exe OR  Processes.process_name = sc.exe) Processes.process="* stop *" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |lookup security_services_lookup service as process OUTPUTNEW category, description | search category=security

[ESCU - Attempted Credential Dump From Registry via Reg.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = Monitor for execution of reg.exe with parameters specifying an export of keys that contain hashed credentials that attackers may try to crack offline.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the process reg.exe with the "save" parameter, which specifies a binary export from the registry. In addition, it looks for the keys that contain the hashed credentials, which attackers may retrieve and use for brute-force attacks in order to harvest legitimate credentials.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2019-12-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempted Credential Dump From Registry via Reg.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempted Credential Dump From Registry via Reg.exe
action.notable = 1
action.notable.param.nes_fields = user, process_name, process
action.notable.param.rule_description = An attempt to save registry keys holding credentials was identified by $user$.
action.notable.param.rule_title = Attempted Credential Dump From Registry from $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process_name, dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=reg.exe OR Processes.process_name=cmd.exe) Processes.process=*save* (Processes.process=*HKEY_LOCAL_MACHINE\\Security* OR Processes.process=*HKEY_LOCAL_MACHINE\\SAM* OR Processes.process=*HKEY_LOCAL_MACHINE\\System* OR Processes.process=*HKLM\\Security* OR Processes.process=*HKLM\\System* OR Processes.process=*HKLM\\SAM*) by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `attempted_credential_dump_from_registry_via_reg_filter`

[ESCU - Batch File Write to System32 - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a batch file (.bat) written to the Windows system directory tree.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Delivery"], "mitre_attack": [], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts, as well as for evidence of batch files being written to paths that include "system32." This activity is consistent with some SamSam attacks and is, in general, suspicious.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = It is possible for this search to generate a notable event for a batch file write to a path that includes the string "system32", but is not the actual Windows system directory. As such, you should confirm the path of the batch file identified by the search. In addition, a false positive may be generated by an administrator copying a legitimate batch file in this directory tree. You should confirm that the activity is legitimate and modify the search to add exclusions, as necessary.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - Batch File Write to System32 - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Batch File Write to System32
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A batch file was written to the system directory on $dest$.
action.notable.param.rule_title = Batch file write to system32 detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name values(Filesystem.user) as user from datamodel=Endpoint.Filesystem by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_path=*system32* AND file_extension=.bat

[ESCU - Child Processes of Spoolsv.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for child processes of spoolsv.exe. This activity is associated with a POC privilege-escalation exploit associated with CVE-2018-8440. Spoolsv.exe is the process associated with the Print Spooler service in Windows and typically runs as SYSTEM.
action.escu.mappings = {"cis20": ["CIS 5", "CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["Privilege Escalation", "Exploitation for Privilege Escalation"], "nist": ["PR.AC", "PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for child processes of spoolsv.exe, which is associated with the Print Spooler service on Windows. Children of this process typically run under the SYSTEM context. This search should address the POC developed for the Windows local-privilege-escalation exploit announced in September of 2018. The associated vulnerability was assigned CVE-2018-8440. More information is available at https://doublepulsar.com/task-scheduler-alpc-exploit-high-level-analysis-ff08cda6ad4f.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Some legitimate printer-related processes may show up as children of spoolsv.exe. You should confirm that any activity as legitimate and may be added as exclusions in the search.
action.escu.creation_date = 2018-11-26
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Child Processes of Spoolsv.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Child Processes of Spoolsv.exe
action.notable = 1
action.notable.param.nes_fields = dest, process_name, parent_process_name
action.notable.param.rule_description = A child process of spoolsv.exe was detected on $dest$.
action.notable.param.rule_title = Spoolsv.exe spawned a child process on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process_name) as process_name values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name=spoolsv.exe AND Processes.process_name!=regsvr32.exe by Processes.dest Processes.parent_process Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Clients Connecting to Multiple DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify the endpoints that have connected to more than five DNS servers and made DNS Queries over the time frame of the search.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12", "CIS 13"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Exfiltration", "Exfiltration Over Alternative Protocol", "Commonly Used Port", "Standard Application Layer Protocol"], "nist": ["PR.PT", "DE.AE", "PR.DS"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = DNS Queries with multiple DNS servers from a single client is unusual and may be indicative of malicious activity. This search works by performing a count by the source of the distinct destinations for the DNS traffic. The search uses the `Network_Resolution` data model.
action.escu.how_to_implement = This search requires that DNS data is being ingested and populating the `Network_Resolution` data model. This data can come from DNS logs or from solutions that parse network traffic for this data, such as Splunk Stream or Bro.\
This search produces fields (`dest_count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** Distinct DNS Connections, **Field:** dest_count\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It's possible that an enterprise has more than five DNS servers that are configured in a round-robin rotation. Please customize the search, as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Clients Connecting to Multiple DNS Servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "src"]
action.escu.entities = ["dest", "src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "DNS Hijacking", "Host Redirection", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Clients Connecting to Multiple DNS Servers
action.notable = 1
action.notable.param.nes_fields = src, dest
action.notable.param.rule_description = This search allows you to identify the endpoints that have connected to more than five DNS servers over the time frame specified in the search.
action.notable.param.rule_title = Client $src$ Connecting to Multiple DNS Servers
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count, values(DNS.dest) AS dest dc(DNS.dest) as dest_count from datamodel=Network_Resolution where DNS.message_type=QUERY by DNS.src | `drop_dm_object_name("Network_Resolution")` |where dest_count > 5

[ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud compute instances created by users who have not created them before.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = For each user, the search returns the first time seen, last time seen, and the systems. It then appends the historical data and merges it into the data. The search then splits and outputs the updated times for each user back to the lookup file and then clears out any output. The other part of the search limits the results to when the user was seen for the first time within the previous 70 minutes. It then displays the new user, the instances created by that user, and the associated times.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the "Previously Seen Cloud Compute Creations By User" support search to create of baseline of previously seen users.
action.escu.known_false_positives = It's possible that a user will start to create compute instances for the first time, for any number of reasons. Verify with the user launching instances that this is the intended behavior.
action.escu.creation_date = 2019-10-03
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Cloud Compute Instance
action.escu.fields_required = ["dest", "src_user"]
action.escu.entities = ["dest", "src_user"]
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Cloud Compute Instance Created By Previously Unseen User
action.notable = 1
action.notable.param.nes_fields = src_user, dest
action.notable.param.rule_description = The compute instance $dest$ was created by $src_user$. This is the first time $src_user$ has created a compute instance.
action.notable.param.rule_title = Cloud Compute Instance Created By Previously Unseen User $src_user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.drilldown_name = Show all instances created by $src_user$
action.notable.param.drilldown_search = | from datamodel:Cloud_Infrastructure.Compute | action=run src_user=$src_user$
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user, dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.action=run by Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_creations_by_user  | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by src_user | multireport [| table src_user, firstTime, lastTime | outputlookup previously_seen_cloud_compute_creations_by_user | where fact=fiction][| eval new_user=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_creations_by_user_search_window_begin_offset`), 1, 0) | where new_user=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table src_user, dest, firstTime, lastTime

[ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud compute instances being created with previously unseen image IDs.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = For each image ID and user, the search returns the first time seen, last time seen, and the systems. It then appends the historical data and merges it into the data. The search then splits and outputs the updated times for each image back to the lookup file and clears out any output. The other part of the search limits the results to when the image was seen for the first time within the previous 70 minutes. It then displays the new image, the instances created using it, the user who created it, and the associated times.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the "Previously Seen Cloud Compute Images" support search to create a baseline of previously seen images.
action.escu.known_false_positives = After a new image is created, the first systems created with that image will cause this alert to fire.  Verify that the image being used was created by a legitimate user.
action.escu.creation_date = 2019-10-03
action.escu.modification_date = 2018-10-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Cloud Compute Instance
action.escu.fields_required = ["dest", "src_user"]
action.escu.entities = ["dest", "src_user"]
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Cloud Compute Instance Created With Previously Unseen Image
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The cloud compute instance $dest$ was created with previously unused image $image_id$.
action.notable.param.rule_title = Cloud Compute Instances Created With New Image
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.drilldown_name = Show all instances created with image $image_id$
action.notable.param.drilldown_search = | from datamodel:Cloud_Infrastructure.Compute | image_id=$image_id$
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `previously_seen_cloud_compute_image_input_filter` by Compute.image_id, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_images | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by image_id, src_user | multireport [| table image_id, firstTime, lastTime | outputlookup previously_seen_cloud_compute_images | where fact=fiction][| eval new_image=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_image_search_window_begin_offset`), 1, 0) | where new_image=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table image_id, dest, src_user, firstTime, lastTime

[ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule]
action.escu = 0
action.escu.enabled = 1
description = Find EC2 instances being created with previously unseen instance types.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = For each instance type and user, the search returns the first time seen, last time seen, and the system. It then appends the historical data and merges it into the data. The search then splits and outputs the updated times for each instance type back to the lookup file and clears out any output. The other part of the search limits the results to when the instance type was seen for the first time within the previous 70 minutes. It then displays the new instance type, the instances created using it, the user who created them, and the times associated.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the " Previously Seen Cloud Compute Instance Types" support search to create a baseline of previously seen regions.
action.escu.known_false_positives = It is possible that an admin will create a new system using a new instance type that has never been used before. Verify with the creator that they intended to create the system with the new instance type.
action.escu.creation_date = 2019-10-03
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Cloud Compute Instance
action.escu.fields_required = ["dest", "src_user"]
action.escu.entities = ["dest", "src_user"]
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Cloud Compute Instance Created With Previously Unseen Instance Type
action.notable = 1
action.notable.param.nes_fields = instance_type
action.notable.param.rule_description = The instance type $instance_type$ was used for the first time to create $dest$.
action.notable.param.rule_title = New Cloud Compute Instance Type $instance_type$ detected
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.drilldown_name = Find all compute instances of type $instance_type$
action.notable.param.drilldown_search = | from datamodel:Cloud_Infrastructure.Compute | instance_type=$instance_type$
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.event_name=RunInstances `previously_seen_cloud_compute_instance_types_input_filter` by Compute.instance_type, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_instance_types | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by instance_type, src_user | multireport [| table instance_type, firstTime, lastTime | outputlookup previously_seen_cloud_compute_instance_types | where fact=fiction][| eval new_type=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_instance_types_search_window_begin_offset`), 1, 0) | where new_type=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table instance_type, dest, src_user, firstTime, lastTime

[ESCU - Cloud Compute Instance Started In Previously Unused Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.
action.escu.mappings = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.eli5 = In this search, we query cloud infrastructure compute logs to look for events that indicate that an instance was started in a particular region. Using the \"previously_seen_cloud_regions\" lookup file created using the support search, we compare the region where this instance was started to all previously observed regions. The \"eval\" and \"if\" functions determine that the earliest times seen for this region and instance were within the last day. If a new region is detected, it will alert you with \"Instance Started in a New Region.\" However, this region will be added to the list in \"previously_seen_cloud_regions.\"
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the \"Previously Seen Cloud Compute Instance Types\" support search to create a baseline of previously seen regions.
action.escu.known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
action.escu.creation_date = 2019-10-02
action.escu.modification_date = 2019-10-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Cloud Compute Instance Started In Previously Unused Region - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Cloud Compute Instance
action.escu.fields_required = ["dest", "region", "src_user"]
action.escu.entities = ["dest", "region", "src_user"]
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.analytic_story = ["Cloud Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Cloud Compute Instance Started In Previously Unused Region
action.notable = 1
action.notable.param.nes_fields = dest,region
action.notable.param.rule_description = A cloud compute instance, $dest$, is started in a new, previously unseen, region $region$
action.notable.param.rule_title = Cloud instance $dest$ started in a new region $region$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.drilldown_name = See all activity in $region$
action.notable.param.drilldown_search = | from datamodel:Cloud_Infrastructure.Compute | search region="$region$"
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,region
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.event_name=RunInstances `previously_seen_cloud_regions_input_filter` by Compute.region, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_regions | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by region, src_user | multireport [| table region, firstTime, lastTime | outputlookup previously_seen_cloud_regions | where fact=fiction][| eval new_region=if(firstTime >= relative_time(now(), `previously_seen_cloud_regions_search_window_begin_offset`), 1, 0) | where new_region=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table region, dest, src_user, firstTime, lastTime

[ESCU - Common Ransomware Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for file modifications with extensions commonly used by Ransomware
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": [], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts and identifies files with extensions that are commonly associated with the encrypted files generated by ransomware.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.\
This search produces fields (`query`,`query_length`,`count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** Name, **Field:** Name\
1. \
1. **Label:** File Extension, **Field:** file_extension\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It is possible for a legitimate file with these extensions to be created. If this is a true ransomware attack, there will be a large number of files created with these extensions.
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Common Ransomware Extensions - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Common Ransomware Extensions
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file modification was detected on $dest$ with an extension commonly used by ransomware.
action.notable.param.rule_title = Ransomware Extension detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | `ransomware_extensions`

[ESCU - Common Ransomware Notes - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for files created with names matching those typically used in ransomware notes that tell the victim how to get their data back.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": [], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications in the Change Analysis data model. It checks modified file names against an included lookup file, which contains the names of note files left behind by ransomware (to inform the victim how they can pay the ransom and retrieve their files). The search returns a list of files with matching names.
action.escu.how_to_implement = You must be ingesting data that records file-system activity from your hosts to populate the Endpoint Filesystem data-model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = It's possible that a legitimate file could be created with the same name used by ransomware note files.
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Common Ransomware Notes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Common Ransomware Notes
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file modification associated with a ransomware victim notification file detected on $dest$
action.notable.param.rule_title = Ransomware Note File detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`|`ransomware_notes`

[ESCU - Create Remote Thread into LSASS - Rule]
action.escu = 0
action.escu.enabled = 1
description = Detect remote thread creation into LSASS consistent with credential dumping.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.eli5 = This search detects the creation of a remote thread into LSASS (Local Security Authority Subsystem Service). This technique can be used by attackers to inject code into LSASS and dump the memory in order to obtain credentials.
action.escu.how_to_implement = This search needs Sysmon Logs with a Sysmon configuration, which includes EventCode 8 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Other tools can access LSASS for legitimate reasons and generate an event. In these cases, tweaking the search may help eliminate noise.
action.escu.creation_date = 2019-12-06
action.escu.modification_date = 2019-12-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Create Remote Thread into LSASS - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Create Remote Thread into LSASS
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Possible attempt at credential dumping was detected on $dest$.
action.notable.param.rule_title = remote thread creation into LSASS on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, TargetProcessId
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = `sysmon` EventID=8 TargetImage=*lsass.exe | stats count min(_time) as firstTime max(_time) as lastTime by Computer, EventCode, TargetImage, TargetProcessId | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`create_remote_thread_into_lsass_filter`

[ESCU - Create local admin accounts using net.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of local administrator accounts using net.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Net.exe is a built-in Windows command-line tool that can be used to add, display, or modify user accounts. While Microsoft administrators use this tool to manage user groups, threat actors often leverage it to create local admin accounts to maintain persistence. In this search, we are looking for the execution of process net.exe with command-line parameters such as `localgroup`, `add`, or `user` that may correspond to the creation of local admin accounts or setting user/group properties.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators often leverage net.exe to create admin accounts.
action.escu.creation_date = 2018-03-28
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Create local admin accounts using net.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 8 * * *
dispatch.earliest_time = -1440m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Create local admin accounts using net.exe
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Net.exe was used to create local administrator accounts on $dest$.
action.notable.param.rule_title = Local administrator account created on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processs.process_name=net.exe OR Processes.process_name=net1.exe) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`  | search (process=*localgroup* OR process=*/add* OR process=*user*)

[ESCU - Create or delete hidden shares using net.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation or deletion of hidden shares using net.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Net.exe is a built-in command-line tool on Windows that can be used to create, delete, and manage shared resources on the computer, both locally and remotely. Though this tool is used by Microsoft administrators to manage the network shares, attackers also leverage it to create and delete hidden file shares by appending "$" after the name of the share. To look for hidden shares, use a regular expression to look for a `(name_file_share)$`. In this search, we are looking for the command-line execution of net.exe with command-line parameters such as `net`, `share`, or `delete` that may correspond to the creation of hidden shares
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators often leverage net.exe to create or delete network shares. You should verify that the activity was intentional and is legitimate.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Create or delete hidden shares using net.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Hidden Cobra Malware"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Create or delete hidden shares using net.exe
action.notable = 1
action.notable.param.nes_fields = dest,process_name
action.notable.param.rule_description = Net.exe was used to create or delete hidden network shares by $user$ on $dest$
action.notable.param.rule_title = Hidden File shares created/deleted on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processs.process_name=net.exe OR Processes.process_name=net1.exe) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search (process=*share* OR process=*delete*)| regex process="\S+[$]"

[ESCU - Creation of Shadow Copy - Rule]
action.escu = 0
action.escu.enabled = 1
description = Monitor for signs that Ntdsutil, Vssadmin, or Wmic has been used to create a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The ntds.dit file contains the Active Directory (AD) database. This file can't be copied directly. That's why attackers will first create a shadow copy before exfiltrating the file. This search detects the creation of a shadow copy using Ntdsutil, Vssadmin, or Wmic.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legtimate administrator usage of Ntdsutil, Vssadmin, or Wmic will create false positives.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Creation of Shadow Copy - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Creation of Shadow Copy
action.notable = 1
action.notable.param.nes_fields = user, dest, process_name, process
action.notable.param.rule_description = An attempt to create a shadow copy with Ntdsutil, Vssadmin, or Wmic was detected on $dest$.
action.notable.param.rule_title = Attempted Credential Dump of ntds.dit from $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process_name, dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=ntdsutil.exe Processes.process=*ntds* Processes.process=*create*) OR (Processes.process_name=vssadmin.exe Processes.process=*create* Processes.process=*shadow*) OR (Processes.process_name=wmic.exe Processes.process=*shadowcopy* Processes.process=*create*) by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `creation_of_shadow_copy_filter`

[ESCU - Creation of Shadow Copy with wmic and powershell - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the use of wmic and Powershell to create a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.eli5 = The ntds.dit file contains the Active Directory (AD) database. This file can't be copied directly. That's why attackers create a shadow copy before exfiltrating the file. This search detects the creation of a shadow copy using wmic, which is executed by Powershell.
action.escu.how_to_implement = You must enable Powershell scriptblock logging in order to detect this attack.This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Legtimate administrator usage of wmic to create a shadow copy.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Creation of Shadow Copy with wmic and powershell - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Creation of Shadow Copy with wmic and powershell
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = An attempt to create a shadow copy with wmic and Powershell was detected on $dest$.
action.notable.param.rule_title = Attempted Credential Dump of ntds.dit on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = `sysmon` Message=*win32_shadowcopy* Message=*Create* | stats count min(_time) as firstTime max(_time) as lastTime by dvc User EventCode Message | rename User as user, dvc as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `creation_of_shadow_copy_with_wmic_and_powershell_filter` 

[ESCU - Credential Dumping via Copy Command from Shadow Copy - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects credential dumping using copy command from a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The file system, security, sam and ntds.dit containing sensitive credentials. Normally, the files can't be easily copied. But it is possible by creating first a shadow copy and then copy it from the shadow copy. This search will detect this attack of credential dumping.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = unknown
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Credential Dumping via Copy Command from Shadow Copy - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Credential Dumping via Copy Command from Shadow Copy
action.notable = 1
action.notable.param.nes_fields = user, dest, process_name, process
action.notable.param.rule_description = credential dumping using copy command was detected on $dest$.
action.notable.param.rule_title = Attempted Credential Dump using copy command from $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest, process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe (Processes.process=*\\system32\\config\\sam* OR Processes.process=*\\system32\\config\\security* OR Processes.process=*\\system32\\config\\system* OR Processes.process=*\\windows\\ntds\\ntds.dit*) by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `cred_dump_via_copy_from_shadowcopy_filter`

[ESCU - Credential Dumping via Symlink to Shadow Copy - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the creation of a symlink to a shadow copy.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The file system, security, sam, and ntds.dit containing sensitive credentials. Normally, the files can't be easily copied, but it can be done by creating shadow copy and then create a symlink to the shadow copy. This search will detect this attack of credential dumping.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = unknown
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.confidence = high
action.escu.full_search_name = ESCU - Credential Dumping via Symlink to Shadow Copy - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Credential Dumping via Symlink to Shadow Copy
action.notable = 1
action.notable.param.nes_fields = user, dest, process_name, process
action.notable.param.rule_description = credential dumping using symlink on $dest$.
action.notable.param.rule_title = Attempted Credential Dump using symlink from $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest, process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe Processes.process=*mklink* Processes.process=*HarddiskVolumeShadowCopy* by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `cred_dump_via_symlink_shadowcopy_filter` 

[ESCU - DNS Query Length Outliers - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify DNS requests that are unusually large for the record type being requested in your environment.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Attackers often use random, long domain names for components of their attack infrastructure. This search leverages the probability distribution function algorithm provided by the Machine Learning Toolkit (MLTK) to identify outliers in the length of the DNS query for each record type observed. The companion search "Baseline of DNS Query Length - MLTK" creates a machine-learning (ML) model built over the historical data used by this search. The determination of what is considered an outlier may be adjusted via the threshold parameter in the search. More information on the algorithm used can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, the Machine Learning Toolkit (MLTK) version 4.2 or greater must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of DNS Query Length - MLTK" must be executed before this detection search, because it builds a machine-learning (ML) model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.\
This search produces fields (`query`,`query_length`,`count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** DNS Query, **Field:** query\
1. \
1. **Label:** DNS Query Length, **Field:** query_length\
1. \
1. **Label:** Number of events, **Field:** count\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = If you are seeing more results than desired, you may consider reducing the value for threshold in the search. You should also periodically re-run the support search to re-build the ML model on the latest data.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - DNS Query Length Outliers - MLTK - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Hidden Cobra Malware", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = DNS Query Length Outliers - MLTK
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = Identify DNS traffic with unusual query lengths by record type
action.notable.param.rule_title = DNS query length outliers
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = query
alert.suppress.period = 43200s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as start_time max(_time) as end_time values(DNS.src) as src values(DNS.dest) as dest from datamodel=Network_Resolution by DNS.query DNS.record_type | search DNS.record_type=* |  `drop_dm_object_name(DNS)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | eval query_length = len(query) | apply dns_query_pdfmodel threshold=0.01 | rename "IsOutlier(query_length)" as isOutlier | search isOutlier > 0 | sort -query_length | table start_time end_time query record_type count src dest query_length

[ESCU - DNS Query Length With High Standard Deviation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify DNS requests and compute the standard deviation on the length of the names being resolved, then filter on two times the standard deviation to show you those queries that are unusually large for your environment.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Attackers often use random, long domain names for their attack infrastructure. This search looks at all the queries observed over the search time frame, and identifies any domains being resolved with names that are greater that 2 times the standard deviation.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = It's possible there can be long domain names that are legitimate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - DNS Query Length With High Standard Deviation - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Hidden Cobra Malware", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = DNS Query Length With High Standard Deviation
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = Filter DNS requests and compute the standard deviation then filter on 2 times the standard deviation
action.notable.param.rule_title = DNS query length with high standard deviation
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = query
alert.suppress.period = 43200s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type |  `drop_dm_object_name("DNS")` | eval query_length = len(query) | table query query_length record_type count | eventstats stdev(query_length) AS stdev avg(query_length) AS avg p50(query_length) AS p50| where query_length>(avg+stdev*2) | eval z_score=(query_length-avg)/stdev

[ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect DNS requests resolved by unauthorized DNS servers. Legitimate DNS servers should be identified in the Enterprise Security Assets and Identity Framework.
action.escu.mappings = {"cis20": ["CIS 1", "CIS 3", "CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Exfiltration", "Command and Control", "Defense Evasion", "Commonly Used Port"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Clients should be resolving their DNS requests via a trusted DNS server. This search will identify DNS queries being sent to unauthorized DNS servers by comparing the destination and source of the traffic with assets marked as DNS servers.
action.escu.how_to_implement = To successfully implement this search you will need to ensure that DNS data is populating the Network_Resolution data model. It also requires that your DNS servers are identified correctly in the Assets and Identity table of Enterprise Security.
action.escu.known_false_positives = Legitimate DNS activity can be detected in this search. Investigate, verify and update the list of authorized DNS servers as appropriate.
action.escu.creation_date = 2017-07-08
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "src"]
action.escu.entities = ["dest", "src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "DNS Hijacking", "Host Redirection", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = DNS Query Requests Resolved by Unauthorized DNS Servers
action.notable = 1
action.notable.param.nes_fields = dest, src
action.notable.param.rule_description = The table represents a list of unauthorized DNS servers interacting with hosts in your network
action.notable.param.rule_title = DNS requests resolved by unauthorized DNS servers
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution where DNS.dest_category != dns_server AND DNS.src_category != dns_server by DNS.src DNS.dest | `drop_dm_object_name("DNS")`

[ESCU - DNS record changed - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search takes the DNS records and their answers results of the discovered_dns_records lookup and finds if any records have changed by searching DNS response from the Network_Resolution datamodel across the last day.
action.escu.mappings = {"cis20": ["CIS 1", "CIS 3", "CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Exfiltration", "Command and Control", "Defense Evasion", "Commonly Used Port"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Using a lookup `discover_dns_records` generated by support search "Discover DNS records" we check previous network traffic and make sure the responses have not changed.
action.escu.how_to_implement = To successfully implement this search you will need to ensure that DNS data is populating the `Network_Resolution` data model. It also requires that the `discover_dns_record` lookup table be populated by the included support search "Discover DNS record". \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called "DNS Hijack Enrichment" can be configured to run when any results are found by this detection search. The playbook takes in the DNS record changed and uses Geoip, whois, Censys and PassiveTotal to detect if DNS issuers changed. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook Link:`https://my.phantom.us/4.2/playbook/dns-hijack-enrichment/`).\

action.escu.known_false_positives = Legitimate DNS changes can be detected in this search. Investigate, verify and update the list of provided current answers for the domains in question as appropriate.
action.escu.creation_date = 2019-02-14
action.escu.modification_date = 2019-02-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - DNS record changed - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src", "dest"]
action.escu.entities = ["src", "dest"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["DNS Hijacking"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = DNS record changed
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = The table represents a list of DNS records and their responses for corporate domains that have recently changed
action.notable.param.rule_title = DNS record changed
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | inputlookup discovered_dns_records.csv | rename answer as discovered_answer | join domain[|tstats `security_content_summariesonly` count values(DNS.record_type) as type, values(DNS.answer) as current_answer values(DNS.src) as src from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,src,domain,type,query,current_answer,discovered_answer | makemv current_answer  | mvexpand current_answer | makemv discovered_answer | eval n=mvfind(discovered_answer, current_answer) | where isnull(n)

[ESCU - Deleting Shadow Copies - Rule]
action.escu = 0
action.escu.enabled = 1
description = The vssadmin.exe utility is used to interact with the Volume Shadow Copy Service.  Wmic is an interface to the Windows Management Instrumentation.  This search looks for either of these tools being used to delete shadow copies.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 10"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for execution of vssadmin or wmic with both the "delete" and "shadows" parameters passed on the command-line. The two arguments are searched for separately because we can't predict the number of spaces between the words on the command-line. The search will return the number of times this activity was observed, and the times of the first and last event.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = vssadmin.exe and wmic.exe are standard applications shipped with modern versions of windows. They may be used by administrators to legitimately delete old backup copies, although this is typically rare.
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Deleting Shadow Copies - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Deleting Shadow Copies
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = Using $process_name$ to delete shadow copies is common behavior by ransomware. This activity was observed on $dest$
action.notable.param.rule_title = Deleting Shadow Copies on $dest$ with $process_name$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=vssadmin.exe OR Processes.process_name=wmic.exe)  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process=*delete* AND process=*shadow*

[ESCU - Detect API activity from users without MFA - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user logged into the AWS account, is making API calls and has not enabled Multi Factor authentication. Multi factor authentication adds a layer of security by forcing the users to type a unique authentication code from an approved authentication device when they access AWS websites or services. AWS Best Practices recommend that you enable MFA for privileged IAM users.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["Execution"], "nist": ["DE.DP", "PR.AC"]}
action.escu.eli5 =  In this search, we query CloudTrail logs and specifically look for events where the multi factor authentication context of the user's session is false which basically means, that the user does not have MFA enabled on AWS. We then filter out all the known AWS service accounts since service accounts typically do not have MFA enabled. The search then creates a table of the first and last time a user without MFA was detected, the values and count of the API calls made, the type of user identity, ARN and the name of the user.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Leverage the support search `Create a list of approved AWS service accounts`: run it once every 30 days to create a list of service accounts and validate them.\
This search produces fields (`eventName`,`userIdentity.type`,`userIdentity.arn`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** AWS User ARN, **Field:** userIdentity.arn\
1. \
1. **Label:** AWS User Type, **Field:** userIdentity.type\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure do not have multi factor authentication enabled. Please ignore the service accounts, if triggered and instead add them to the aws_service_accounts.csv file to fine tune the detection. It is also possible that the search detects users in your environment using Single Sign-On systems, since the MFA is not handled by AWS.
action.escu.creation_date = 2018-05-17
action.escu.modification_date = 2018-05-17
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect API activity from users without MFA - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 8 * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect API activity from users without MFA
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = API Activity detected from $user$ without MFA enabled.
action.notable.param.rule_title = API Activity detected from $user$ without MFA enabled
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 84600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail userIdentity.sessionContext.attributes.mfaAuthenticated=false | search NOT [| inputlookup aws_service_accounts | fields identity | rename identity as user]| stats  count min(_time) as firstTime max(_time) as lastTime values(eventName) as eventName by userIdentity.arn userIdentity.type user | `security_content_ctime(firstTime)`  | `security_content_ctime(lastTime)`

[ESCU - Detect AWS API Activities From Unapproved Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for successful CloudTrail activity by user accounts that are not listed in the identity table or `aws_service_accounts.csv`. It returns event names and count, as well as the first and last time a specific user or service is detected, grouped by users.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Execution"], "nist": ["DE.DP", "DE.CM", "PR.AC", "ID.AM"]}
action.escu.eli5 = In this search, we are looking for successful API calls via CloudTrail. We filter out events triggered by known users listed in the `identity_lookup_expanded` lookup file and the service accounts. Once filtered out, we output a table with the event names and count, as well as the first and last time a specific user or service is detected.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You must also populate the `identity_lookup_expanded` lookup shipped with the Asset and Identity framework to be able to look up users in your identity table in Enterprise Security (ES). Leverage the support search called "Create a list of approved AWS service accounts": run it once every 30 days to create and validate a list of service accounts.\
This search produces fields (`eventName`,`firstTime`,`lastTime`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** First Time, **Field:** firstTime\
1. \
1. **Label:** Last Time, **Field:** lastTime\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It's likely that you'll find activity detected by users/service accounts that are not listed in the `identity_lookup_expanded` or ` aws_service_accounts.csv` file. If the user is a legitimate service account, update the `aws_service_accounts.csv` table with that entry.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-13
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect AWS API Activities From Unapproved Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect AWS API Activities From Unapproved Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A successful API activity was invoked by $user$, an unapproved/unknown account.
action.notable.param.rule_title = Successful API activity by a non-approved account: $user$
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail errorCode=success | rename userName as identity | search NOT [| inputlookup identity_lookup_expanded | fields identity] | search NOT [| inputlookup aws_service_accounts | fields identity] | rename identity as user | stats count min(_time) as firstTime max(_time) as lastTime values(eventName) as eventName by user | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Detect AWS Console Login by User from New City - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that a user has attempted to log in to the AWS console from a new city and group the events using ARN value. Using the `previously_seen_users_console_logins.csv` lookup file created using the support search, we compare the ARN to all the previously seen ARN and city combinations logging into the AWS console. The `eval` and `if` functions determine whether the earliest time we see this user ARN was seen within the last hour. The alert will be fired only when a user is seen for first time in the last hour.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-04-24
action.escu.modification_date = 2018-04-30
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New City - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect AWS Console Login by User from New City
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A user has logged into the AWS console from a new city.
action.notable.param.rule_title = AWS Console Login by User from New City
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user City | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New City","Previously Seen City") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New City" AND UserData="Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `security_content_ctime(earliestseen)` | table user City userStatus firstTime lastTime earliestseen

[ESCU - Detect AWS Console Login by User from New Country - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that a user has attempted to log in to the AWS console from a new country and group the events using ARN value. Using the `previously_seen_users_console_logins.csv` lookup file created using the support search, we compare the ARN to all the previously seen ARN and country combinations logging into the AWS console. The `eval` and `if` functions determine whether the earliest time we see this user ARN was seen within the last hour. The alert will be fired only when a user is seen for first time in the last hour.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-04-24
action.escu.modification_date = 2018-04-30
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New Country - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect AWS Console Login by User from New Country
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A user has logged into the AWS console from a new country.
action.notable.param.rule_title = AWS Console Login by User from New Country
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user Country | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New Country","Previously Seen Country") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New Country" AND UserData="Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`security_content_ctime(earliestseen)` | table user Country userStatus firstTime lastTime earliestseen

[ESCU - Detect AWS Console Login by User from New Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that a user has attempted to log in to the AWS console from a new region and group the events using ARN value. Using the `previously_seen_users_console_logins.csv` lookup file created using the support search, we compare the ARN to all the previously seen ARN and region combinations logging into the AWS console. The `eval` and `if` functions determine whether the earliest time we see this user ARN was seen within the last hour. The alert will be fired only when a user is seen for first time in the last hour.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-04-24
action.escu.modification_date = 2018-04-30
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New Region - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect AWS Console Login by User from New Region
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A user has logged into the AWS console from a new region.
action.notable.param.rule_title = AWS Console Login by User from New Region
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user Region | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New Region","Previously Seen Region") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New Region" AND UserData="Old User" | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `security_content_ctime(earliestseen)` | table user Region userStatus firstTime lastTime earliestseen

[ESCU - Detect Activity Related to Pass the Hash Attacks - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific authentication events from the Windows Security Event logs to detect potential attempts at using the Pass-the-Hash technique.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Lateral Movement", "Pass the Hash"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = To detect pass the hash activity, we look at all events with event code 4624 or 4625 that specify a logon type 3 (network logons). We are looking for the NtLmSsP account, with a key length set to 0. These indicate lower level protocols that are typically used through Pass the Hash (WMI, SMB, etc.). The search also filters out events with an account name of 'Anonymous' to help reduce false positives.
action.escu.how_to_implement = To successfully implement this search, you must ingest your Windows Security Event logs and leverage the latest TA for Windows.
action.escu.known_false_positives = Legitimate logon activity by authorized NTLM systems may be detected by this search. Please investigate as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2019-02-27
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect Activity Related to Pass the Hash Attacks - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Activity Related to Pass the Hash Attacks
action.notable = 1
action.notable.param.nes_fields = src_ip, dest, user
action.notable.param.rule_description = This search looks for Authentication log events from the Windows Security Audit logs to detect potential attempts for Passing the Hash
action.notable.param.rule_title = Detect Activity Related to Pass the Hash
action.notable.param.security_domain = access
action.notable.param.severity = low
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_security (signature_id = 4624 OR signature_id = 4625) Logon_Process = NtLmSsp Logon_Type=3 Account_Name ! = "ANONYMOUS LOGON" Key_Length = 0 | table _time src_ip user dest dest_nt_domain signature_id signature

[ESCU - Detect Credential Dumping through LSASS access - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for reading lsass memory consistent with credential dumping.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["PR.IP", "PR.AC", "DE.CM"]}
action.escu.eli5 = This search looks for LSASS access using Credential Dumping tools by detecting Process access with Sysmon logs (EventCode 10), TargetImage lsass.exe and GrantedAccess 0x1410 or 0x1010. This will for example detect the use of sekurlsa::logonpasswords in Mimikatz.
action.escu.how_to_implement = This search needs Sysmon Logs and a sysmon configuration, which includes EventCode 10 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = The activity may be legitimate. Other tools can access lsass for legitimate reasons, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2019-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Credential Dumping through LSASS access - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Credential Dumping through LSASS access
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = Possible attempt at credential dumping was detected on $dest$.
action.notable.param.rule_title = Detect reading lsass memory on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest, ProcessName
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = `sysmon` EventCode=10 TargetImage=*lsass.exe (GrantedAccess=0x1010 OR GrantedAccess=0x1410) | stats count min(_time) as firstTime max(_time) as lastTime by Computer, SourceImage, SourceProcessId, TargetImage, TargetProcessId, EventCode, GrantedAccess | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_credential_dumping_through_LSASS_access_filter`

[ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DNS requests for phishing domains that are leveraging EvilGinx tools to mimic websites.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 7"], "kill_chain_phases": ["Delivery", "Command and Control"], "mitre_attack": ["Spearphishing Link", "Command and Control"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution", "Web"]
action.escu.eli5 = This search gathers all the answers to each system's DNS query, then filters for queries that have subdomains extracted from the EvilGinx toolkit. It will then run a regex to extract `legit_domains` from the query and remove that from the detection if it is listed in the `legit_domains.csv`
action.escu.how_to_implement = You need to ingest data from your DNS logs in the Network_Resolution datamodel. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You will have to add legitimate domain names to the `legit_domains.csv` file shipped with the app. \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called `Lets Encrypt Domain Investigate` can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook link:`https://my.phantom.us/4.2/playbook/lets-encrypt-domain-investigate/`).\

action.escu.known_false_positives = If a known good domain is not listed in the legit_domains.csv file, then the search could give you false postives. Please update that lookup file to filter out DNS requests to legitimate domains.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Common Phishing Frameworks"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect DNS requests to Phishing Sites leveraging EvilGinx2
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = The host $src$ issued a DNS request for a domain that could be a phishing site leverating EvilGinx toolkit.
action.notable.param.rule_title = DNS request for EvilGinx subdomain detected on $src$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, query
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(DNS.answer) as answer from datamodel=Network_Resolution.DNS by DNS.dest DNS.src DNS.query host | `drop_dm_object_name(DNS)`| rex field=query ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | stats count values(query) as query by domain dest src answer| search `evilginx_phishlets_amazon` OR `evilginx_phishlets_facebook` OR `evilginx_phishlets_github` OR `evilginx_phishlets_0365` OR `evilginx_phishlets_outlook` OR `evilginx_phishlets_aws` OR `evilginx_phishlets_google` | search NOT [ inputlookup legit_domains.csv | fields domain]| join domain type=outer [| tstats count `security_content_summariesonly` values(Web.url) as url from datamodel=Web.Web by Web.dest Web.site | rename "Web.*" as * | rex field=site ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | table dest domain url] | table count src dest query answer domain url

[ESCU - Detect Excessive Account Lockouts From Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search identifies endpoints that have caused a relatively high number of account lockouts in a short period.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["Initial Access", "Valid Accounts"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search queries the `Change.All_Changes` datamodel under the nodename is `Account_Management` , where the result is "lockout", which indicates that an account has been locked out. It then counts the number of times an endpoint has caused an account lockout within a four hour window and displays those hosts with a count greater than or equal to five.
action.escu.how_to_implement = You must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment. \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called "Excessive Account Lockouts Enrichment and Response" can be configured to run when any results are found by this detection search. The Playbook executes the Contextual and Investigative searches in this Story, conducts additional information gathering on Windows endpoints, and takes a response action to shut down the affected endpoint. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook Link:`https://my.phantom.us/4.1/playbook/excessive-account-lockouts-enrichment-and-response/`).\

action.escu.known_false_positives = It's possible that a widely used system, such as a kiosk, could cause a large number of account lockouts.
action.escu.creation_date = 2017-08-17
action.escu.modification_date = 2019-04-18
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect Excessive Account Lockouts From Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -5m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Excessive Account Lockouts From Endpoint
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ has generated a high number of account lockouts.
action.notable.param.rule_title = $dest$ has generated a high number of account lockouts
action.notable.param.security_domain = access
action.notable.param.severity = low
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.dest All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search count > 5

[ESCU - Detect Excessive User Account Lockouts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects user accounts that have been locked out a relatively high number of times in a short period.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["Initial Access", "Valid Accounts"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search queries the `Change.All_Changes` datamodel under the nodename is `Account_Management` , where the result is "lockout", which indicates that an account has been locked out. It then counts the number of times a user  has caused an account lockout within a four hour window and displays those users with a count greater than or equal to five.
action.escu.how_to_implement = ou must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment.
action.escu.known_false_positives = It is possible that a legitimate user is experiencing an issue causing multiple account login failures leading to lockouts.
action.escu.creation_date = 2017-08-17
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Excessive User Account Lockouts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Excessive User Account Lockouts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = The account $user$ has been locked out an excessive number of times
action.notable.param.rule_title = $user$ locked account an excessive number of times
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.user All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search count > 5

[ESCU - Detect Large Outbound ICMP Packets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for outbound ICMP packets with a packet size larger than 1,000 bytes. Various threat actors have been known to use ICMP as a command and control channel for their attack infrastructure. Large ICMP packets from an endpoint to a remote host may be indicative of this activity.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Standard Non-Application Layer Protocol"], "nist": ["DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search works by looking at fields in the Network_Traffic data model, which is populated by various firewalls and passive networking monitoring technologies. Specifically, the search looks for ICMP packets larger than 1,000 bytes with a destination that is external to your organization.
action.escu.how_to_implement = In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have a good understanding of how your network segments are designed and that you are able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in the `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model
action.escu.known_false_positives = ICMP packets are used in a variety of ways to help troubleshoot networking issues and ensure the proper flow of traffic. As such, it is possible that a large ICMP packet could be perfectly legitimate. If large ICMP packets are associated with command and control traffic, there will typically be a large number of these packets observed over time. If the search is providing a large number of false positives, you can modify the search to adjust the byte threshold or whitelist specific IP addresses, as necessary.
action.escu.creation_date = 2018-06-01
action.escu.modification_date = 2018-06-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Large Outbound ICMP Packets - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["Bro", "Splunk Stream", "Palo Alto Firewall"]
action.escu.analytic_story = ["Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Large Outbound ICMP Packets
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = Large outbound ICMP packet detected.
action.notable.param.rule_title = Large ICMP packet from $src_ip$ to $dest_ip$ detected
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as firstTime latest(_time) as lastTime values(All_Traffic.action) values(All_Traffic.bytes) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.protocol=icmp OR All_Traffic.transport=icmp) All_Traffic.bytes > 1000 by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`

[ESCU - Detect Long DNS TXT Record Response - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect attempts to use DNS tunneling, by calculating the length of responses to DNS TXT queries. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting unusually large volumes of DNS traffic.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12", "CIS 13"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search uses the Network_Resolution data model and gathers all the answers to DNS queries for TXT records. The query then looks at the answer section and calculates the length of the answer. The search will then return information for those responses that exceed 100 characters in length.
action.escu.how_to_implement = To successfully implement this search you need to ingest data from your DNS logs, or monitor DNS traffic using Stream, Bro or something similar. Specifically, this query requires that the DNS data model is populated with information regarding the DNS record type that is being returned as well as the data in the answer section of the protocol.
action.escu.known_false_positives = It's possible that legitimate TXT record responses can be long enough to trigger this search. You can modify the packet threshold for this search to help mitigate false positives.
action.escu.creation_date = 2017-06-18
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Long DNS TXT Record Response - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Long DNS TXT Record Response
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = A DNS TXT record response of over 100 characters was detected.
action.notable.param.rule_title = Long DNS TXT Record Response
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Resolution where DNS.message_type=response AND DNS.record_type=TXT by DNS.src DNS.dest DNS.answer DNS.record_type |  `drop_dm_object_name("DNS")` | eval anslen=len(answer) | search anslen>100 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename src as "Source IP", dest as "Destination IP", answer as "DNS Answer" anslen as "Answer Length" record_type as "DNS Record Type" firstTime as "First Time" lastTime as "Last Time" count as Count | table "Source IP" "Destination IP" "DNS Answer" "DNS Record Type"  "Answer Length" Count "First Time" "Last Time"

[ESCU - Detect Mimikatz Using Loaded Images - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for reading loaded Images unique to credential dumping with Mimikatz.
action.escu.mappings = {"cis20": ["CIS 6", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.AE", "DE.CM"]}
action.escu.eli5 = This search looks for loaded images (dll) unique for Mimikatz using Sysmon EventCode 7 logs.
action.escu.how_to_implement = This search needs Sysmon Logs and a sysmon configuration, which includes EventCode 7 with powershell.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Other tools can import the same DLLs. These tools should be part of a whtelist.
action.escu.creation_date = 2019-12-03
action.escu.modification_date = 2019-12-03
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Mimikatz Using Loaded Images - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Mimikatz Using Loaded Images
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Possible attempt at credential dumping was detected on $dest$.
action.notable.param.rule_title = Detect Mimikatz using loaded images on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, Image
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = `sysmon` EventCode=7 | stats values(ImageLoaded) as ImageLoaded values(ProcessId) as ProcessId by Computer, Image | search ImageLoaded=*WinSCard.dll ImageLoaded=*cryptdll.dll ImageLoaded=*hid.dll ImageLoaded=*samlib.dll ImageLoaded=*vaultcli.dll | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_mimikatz_using_loaded_images_filter`

[ESCU - Detect Mimikatz Via PowerShell And EventCode 4703 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell requesting privileges consistent with credential dumping.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["PR.IP", "PR.AC", "DE.CM"]}
action.escu.eli5 = This search looks for Windows Event Code(signature_id) 4703 (token right adjusted), where the process requesting the token change is PowerShell.exe and the requested privilege is "SeDebugPrivilege". This is consistent with the use of PowerShell to execute Mimikatz using sekurlsa::logonpasswords. It will return the host where the activity occurred, the process and associated id, the enabled privilege, and the message in the event.
action.escu.how_to_implement = You must be ingesting Windows Security logs. You must also enable the account change auditing here: http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata. Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.
action.escu.known_false_positives = The activity may be legitimate. PowerShell is often used by administrators to perform various tasks, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Mimikatz Via PowerShell And EventCode 4703 - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = []
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Mimikatz Via PowerShell And EventCode 4703
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = Possible attempt at credential dumping via PowerShell was detected on $dest$ by $user$.
action.notable.param.rule_title = Event Code 4703 Specifying PowerShell Acquiring A Token with SeDebugPrivilege Identified on $dest$.
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest, process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_security signature_id=4703 Process_Name=*powershell.exe | rex field=Message "Enabled Privileges:\s+(?<privs>\w+)\s+Disabled Privileges:" | where privs="SeDebugPrivilege" | stats count min(_time) as firstTime max(_time) as lastTime by dest, Process_Name, privs, Process_ID, Message | rename privs as "Enabled Privilege" | rename Process_Name as process |  `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Detect New Local Admin account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for newly created accounts that have been elevated to local administrators.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "mitre_attack": ["Valid Accounts", "Defense Evasion", "Persistence"], "nist": ["PR.AC", "DE.CM"]}
action.escu.eli5 = This search looks for Windows Event Code 4720 (account creation) and 4732 (account added to a security-enabled local group), where the group name is "Administrators", and determines whether they are generated for the same user's Security ID within three hours of each other.  It will return the user account that was added, the Security ID, the group name to which the user was added, the account name of the user who initiated the action, and the subsequent message returned.
action.escu.how_to_implement = You must be ingesting Windows Security logs. You must also enable the account change auditing here:http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata. Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.\
This search produces fields (`Security_ID`,`Group_Name`,`Message`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** Security ID, **Field:** Security_ID\
1. \
1. **Label:** Group Name, **Field:** Group_Name\
1. \
1. **Label:** Message, **Field:** Message\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = The activity may be legitimate. For this reason, it's best to verify the account with an administrator and ask whether there was a valid service request for the account creation. If your local administrator group name is not "Administrators", this search may generate an excessive number of false positives
action.escu.creation_date = 2018-03-26
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect New Local Admin account - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 9 * * *
dispatch.earliest_time = -1440m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect New Local Admin account
action.notable = 1
action.notable.param.nes_fields = user,src_user, dest
action.notable.param.rule_description = The new user account $user$ was created on $dest$ by $src_user$.
action.notable.param.rule_title = New local admin account $user$ created by $src_user$.
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype = wineventlog_security signature_id=4720 OR (signature_id=4732 Group_Name= Administrators) | transaction Security_ID connected=false maxspan=180m | search signature_id=4720 signature_id=4732 | table _time user dest signature_id Security_ID Group_Name src_user Message

[ESCU - Detect New Login Attempts to Routers - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = Attackers will often attempt to compromise network devices such as routers for a variety of nefarious purposes, including modifying VPN settings or re-routing network traffic. Typically, only a relatively small number of user accounts log into these devices on a regular basis. This search identifies 'new' connections to your routers by checking to see if a similar login was made in the last 30 days. Routers are identified by checking the IP address against those categorized as a "router" in the ES assets and identity framework.
action.escu.how_to_implement = To successfully implement this search, you must ensure the network router devices are categorized as "router" in the Assets and identity table. You must also populate the Authentication data model with logs related to users authenticating to routing infrastructure.
action.escu.known_false_positives = Legitimate router connections may appear as new connections
action.escu.creation_date = 2017-07-18
action.escu.modification_date = 2017-09-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect New Login Attempts to Routers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Active Directory", "Palo Alto Firewall"]
action.escu.analytic_story = ["Router & Infrastructure Security"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect New Login Attempts to Routers
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = This search detects new connections made to the router devices at $dest$
action.notable.param.rule_title = Detected a New Router Login
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as earliest latest(_time) as latest from datamodel=Authentication where Authentication.dest_category=router by Authentication.dest Authentication.user| eval isOutlier=if(earliest >= relative_time(now(), "-30d@d"), 1, 0) | where isOutlier=1| `security_content_ctime(earliest)`| `security_content_ctime(latest)` | `drop_dm_object_name("Authentication")`

[ESCU - Detect New Open S3 buckets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Initial Access", "Exfiltration"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.eli5 = This search queries CloudTrail logs for events with S3 bucket access controls given to the "All Users" group, which allows anyone in the world access to the resource. This search generates a table displaying the time when the bucket was made public, the permission of the S3 bucket, the bucket name, and the ARN of the user who created the bucket.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), and then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.
action.escu.creation_date = 2018-07-25
action.escu.modification_date = 2018-07-25
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect New Open S3 buckets - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = S3 Bucket
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect New Open S3 buckets
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = An open/public S3 bucket, $bucketName$, was created by $user$.
action.notable.param.rule_title = Public S3 bucket $bucketName$ created by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user,bucketName
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail AllUsers eventName=PutBucketAcl | spath output=userIdentityArn path=userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | spath output=aclControlList path=requestParameters.AccessControlPolicy.AccessControlList | spath input=aclControlList output=grantee path=Grant{} | mvexpand grantee | spath input=grantee | search Grantee.URI=*AllUsers | rename userIdentityArn as user| table _time, src,awsRegion Permission, Grantee.URI, bucketName, user

[ESCU - Detect Oulook.exe writing a .zip file - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for execution of process `outlook.exe` where the process is writing a `.zip` file to the disk.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Initial Access", "Spearphishing Attachment"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are essentially trying to detect if outlook.exe is writing a `.zip` file to the disk. The way this search would run is, it will execute the the subsearch first which looks for all .zip files being written to the disk and outputs a crucial field "process_id", that we use the main search to check if that process\_id belongs to a process_name of outlook.exe. The search uses a join command to essentially give you an end result of the first and last time that zip file was written by outlook.exe, the dest and user logged on the system, the hash value and the complete path to the zip file on disk
action.escu.how_to_implement = You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.
action.escu.known_false_positives = It is not uncommon for outlook to write legitimate zip files to the disk.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Oulook.exe writing a .zip file - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Phishing Payloads"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Oulook.exe writing a .zip file
action.notable = 1
action.notable.param.nes_fields = dest, process_name, file_name
action.notable.param.rule_description = Outlook.exe is writing a zip file $file_name$ on $dest$
action.notable.param.rule_title = Outlook.exe is writing a zip file $file_name$ on $dest$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly`  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name=outlook.exe OR Processes.process_name=explorer.exe by _time span=5m Processes.parent_process_id Processes.process_id Processes.dest Processes.process_name Processes.parent_process_name Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename process_id as malicious_id| rename parent_process_id as outlook_id| join malicious_id type=inner[| tstats `security_content_summariesonly` count values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name  FROM datamodel=Endpoint.Filesystem where (Filesystem.file_path=*zip*   OR Filesystem.file_name=*.lnk ) AND (Filesystem.file_path=C:\\Users* OR Filesystem.file_path=*Local\\Temp*) by  _time span=5m Filesystem.process_id Filesystem.file_hash Filesystem.dest  | `drop_dm_object_name(Filesystem)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename process_id as malicious_id| fields malicious_id outlook_id dest file_path file_name file_hash count file_id] | table firstTime lastTime user malicious_id outlook_id process_name parent_process_name file_name  file_path | where file_name != ""

[ESCU - Detect Outbound SMB Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for outbound SMB connections made by hosts within your network to the Internet. SMB traffic is used for Windows file-sharing activity. One of the techniques often used by attackers involves retrieving the credential hash using an SMB request made to a compromised server controlled by the threat actor.
action.escu.mappings = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "mitre_attack": ["Commonly Used Port", "Credential Access", "Lateral Movement"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = In this search, we are looking for the network connections that were not blocked by the firewall and that are destined for destination port 139 or 445. We then filter out events that have Classless Inter-Domain Routing (CIDR) blocks categorized as internal in the `assets_by_cidr.csv` lookup file which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. Since we are only looking for outbound traffic from the hosts made to the Internet, we filter out traffic whose destination IP address is private.
action.escu.how_to_implement = In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have good understanding of how your network segments are designed, and be able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model
action.escu.known_false_positives = It is likely that the outbound Server Message Block (SMB) traffic is legitimate, if the company's internal networks are not well-defined in the Assets and Identity Framework. Categorize the internal CIDR blocks as `internal` in the lookup file to avoid creating notable events for traffic destined to those CIDR blocks. Any other network connection that is going out to the Internet should be investigated and blocked. Best practices suggest preventing external communications of all SMB versions and related protocols at the network boundary.
action.escu.creation_date = 2018-03-20
action.escu.modification_date = 2018-03-20
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Outbound SMB Traffic - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Hidden Cobra Malware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Outbound SMB Traffic
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = Outbound SMB network traffic detected.
action.notable.param.rule_title = Outbound SMB traffic from $src_ip$ to $dest_ip$ detected
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as earliest latest(_time) as latest values(All_Traffic.action) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb) by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | `security_content_ctime(earliest)`| `security_content_ctime(latest)`

[ESCU - Detect Path Interception By Creation Of program.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is looking for the creation of program.exe in the C: drive.  The creation of this file in that location may be driven by a motive to perform path interception.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Privilege Escalation", "Persistence"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search queries the Endpoint file-system data model node to list out all the values of destination machines, as well as the values of file hashes and file paths that have the file "program.exe" in the C: drive. Path interception occurs when an executable is placed in a specific path so that it is executed by an application instead of by the intended target. In this case, applications vulnerable to path interception (because of unquoted service paths with spaces in Windows registry) allow attackers to execute maliciously crafted program.exes.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes.
action.escu.known_false_positives = It is unlikely that a normal user may create and place this file in the C: drive.  Confirm with the user.
action.escu.creation_date = 2017-11-16
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Path Interception By Creation Of program.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Path Interception By Creation Of program.exe
action.notable = 1
action.notable.param.nes_fields = dest, file_path, file_name
action.notable.param.rule_description = A potentially malicious file program.exe was detected on the C: drive. The creation of this file is often associated with a motive to perform a path interception attack. 
action.notable.param.rule_title = Path Interception attempt discovered $dest$ via creation of program.exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, file_path, file_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_hash) as file_hash values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem where Filesystem.file_path="C:\\program.exe" by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`

[ESCU - Detect Prohibited Applications Spawning cmd.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and that does not typically launch cmd.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["Execution", "Command-Line Interface"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Obtaining access to the Command-Line Interface (CLI) is typically a primary attacker goal. Once an attacker has obtained the ability to execute code on a target system, they will often further manipulate the system via commands passed to the CLI. It is also unusual for many applications to spawn a command shell during normal operation, while it is often observed if an application has been compromised in some way. As such, it is often beneficial to look for cmd.exe being executed by processes that are often targeted for exploitation, or that would not spawn cmd.exe in any other circumstances. A lookup file is provided to easily modify the processes that are being watched for execution of cmd.exe.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts and populates the Endpoint data model with the resultant dataset. This search includes a lookup file, `prohibited_apps_launching_cmd.csv`, that contains a list of processes that should not be spawning cmd.exe. You can modify this lookup to better suit your environment.
action.escu.known_false_positives = There are circumstances where an application may legitimately execute and interact with the Windows command-line interface. Investigate and modify the lookup file, as appropriate.
action.escu.creation_date = 2017-10-07
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Prohibited Applications Spawning cmd.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Command-Line Executions", "Suspicious MSHTA Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Prohibited Applications Spawning cmd.exe
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process
action.notable.param.rule_description = A prohibited application from prohibited_apps_launching_cmd.csv was leveraged to launch cmd.exe
action.notable.param.rule_title = Prohibited application($parent_process$) used to launch cmd.exe on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe by Processes.parent_process_name Processes.process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |search [`prohibited_apps_launching_cmd`]

[ESCU - Detect PsExec With accepteula Flag - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for events where `PsExec.exe` is run with the `accepteula` flag in the command line. PsExec is a built-in Windows utility that enables you to execute processes on other systems. It is fully interactive for console applications. This tool is widely used for launching interactive command prompts on remote systems. Threat actors leverage this extensively for executing code on compromised systems. If an attacker is running PsExec for the first time, they will be prompted to accept the end-user license agreement (EULA), which can be passed as the argument `accepteula` within the command line.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Command-Line Interface"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are looking for the PsExec process with `accepteula` on the command line.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators can leverage PsExec for accessing remote systems and might pass `accepteula` as an argument if they are running this tool for the first time. However, it is not likely that you'd see multiple occurrences of this event on a machine
action.escu.creation_date = 2018-03-28
action.escu.modification_date = 2019-02-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect PsExec With accepteula Flag - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect PsExec With accepteula Flag
action.notable = 1
action.notable.param.nes_fields = dest,process_name
action.notable.param.rule_description = The process pssxec.exe was run with the -accepteula flag on $dest$ by $user$.
action.notable.param.rule_title = PsExec executed with accepteula flag on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = PsExec.exe Processes.process = "*accepteula*" by Processes.process_name Processes.dest  Processes.parent_process_name | `drop_dm_object_name(Processes)`| `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Detect Rare Executables - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will return a table of rare processes, the names of the systems running them, and the users who initiated each process.
action.escu.mappings = {"cis20": ["CIS 2", "CIS 8"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["ID.AM", "PR.PT", "PR.DS", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search first executes the subsearch and counts all of your processes to determine the 10 most rare (the limit set is 10). It then filters out whitelisted processes and outputs the first and last time a rare process was encountered, the destination where the process is running, the count of occurrences, and the users who initiated the processes.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts and populating the endpoint data model with the resultant dataset. The macro `filter_rare_process_whitelist` searches two lookup files to whitelist your processes.  These consist of `rare_process_whitelist_default.csv` and `rare_process_whitelist_local.csv`. To add your own processes to the whitelist, add them to `rare_process_whitelist_local.csv`. If you wish to remove an entry from the default lookup file, you will have to modify the macro itself to set the whitelist value for that process to false. You can modify the limit parameter and search scheduling to better suit your environment.
action.escu.known_false_positives = Some legitimate processes may be only rarely executed in your environment. As these are identified, update `rare_process_whitelist_local.csv` to filter them out of your search results.
action.escu.creation_date = 2016-08-09
action.escu.modification_date = 2018-10-30
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Rare Executables - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)", "Unusual Processes"]
cron_schedule = 10 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Rare Executables
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = The process $process$ was detected running on $dest. This process is rare in your environment.
action.notable.param.rule_title = Rare Process $process$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.dest) as dest values(Processes.user) as user min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.process_name  | rename Processes.process_name as process | rex field=user "(?<user_domain>.*)\\\\(?<user_name>.*)" | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search [| tstats count from datamodel=Endpoint.Processes by Processes.process_name | rare Processes.process_name limit=30 | rename Processes.process_name as process| `filter_rare_process_whitelist`| table process ]

[ESCU - Detect S3 access from a new IP - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks at S3 bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed an S3 bucket.
action.escu.mappings = {"cis20": ["CIS 13", "CIS 14"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Exfiltration"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.eli5 = Here the subsearch executes first and returns all successful S3 bucket-access attempts (HTTP code "200") within the last hour. It groups the results by the earliest and latest times it has seen a remote IP accessing a particular bucket. It appends this information to the historical data from the lookup file and then recalculates the `firstTime` and `lastTime` field for each remote IP accessing an S3 bucket. Next, it returns only those remote IP addresses that have first been seen accessing a specific bucket within the past hour. This is combined with the main search to return the time, bucket name, source IP, city, and country operations performed, as well as the requested URI of the resource 
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access logs' inputs. This search works best when you run the "Previously Seen S3 Bucket Access by Remote IP" support search once to create a history of previously seen remote IPs and bucket names.
action.escu.known_false_positives = S3 buckets can be accessed from any IP, as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past hour
action.escu.creation_date = 2018-06-25
action.escu.modification_date = 2018-06-28
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect S3 access from a new IP - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = S3 Bucket
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect S3 access from a new IP
action.notable = 1
action.notable.param.nes_fields = bucket_name, src_ip
action.notable.param.rule_description = A remote IP, $src_ip$, has made a successful connection with an S3 $bucket_name$.
action.notable.param.rule_title = S3 bucket $bucketName$ was accessed by a new $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = low
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = bucket_name, src_ip
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:s3:accesslogs http_status=200  [search sourcetype=aws:s3:accesslogs http_status=200 | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip | inputlookup append=t previously_seen_S3_access_from_remote_ip.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip.csv | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | table bucket_name remote_ip]| iplocation remote_ip |rename remote_ip as src_ip | table _time bucket_name src_ip City Country operation request_uri

[ESCU - Detect Spike in AWS API Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes of API activity in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Execution"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through a series of steps, as per the following: \
1. Retrieves all the AWS CloudTrail log entries that have recorded AWS API calls.\
1. Kicks off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.\
1. Counts the number of API calls per ARN.\
1. Loads the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
1. Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. \
1. Renames `apiCalls` as `latestCount`.\
1. Calculates the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation--weighting the past more heavily than the current.\
1. Updates the cache file with the latest results.\
1. Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.\
1. Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
1. Filters out anything that it determines is not a spike and returns the list of ARNs to the main search. The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.\
This search produces fields (`eventName`,`numberOfApiCalls`,`uniqueApisCalled`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** Number of API Calls, **Field:** numberOfApiCalls\
1. \
1. **Label:** Unique API Calls, **Field:** uniqueApisCalled\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = 
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-04-09
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in AWS API Activity - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in AWS API Activity
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of AWS API calls by $user$ was detected.
action.notable.param.rule_title = Spike in AWS API activity detected by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall [search sourcetype=aws:cloudtrail eventType=AwsApiCall | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup api_call_by_user_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in Network ACL Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes in API activity related to network access-control lists (ACLs)in your AWS environment.
action.escu.mappings = {"cis20": ["CIS 12", "CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Exfiltration"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through the following series of steps: \
1. Retrieve all the AWS CloudTrail log entries that have recorded AWS API calls specifically for creating/modifying/replacing network Access Control Lists (ACLs).\
1. Kick off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.\
1. Count the number of API calls per Amazon Resource Name (ARN).\
1. Load the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
1. Drop the count from the latest hour, since it is not necessary, and merge the rest of the data with the results of the stats command. \
1. Rename `apiCalls` as `latestCount`.\
1. Calculate the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. They do the same for the standard deviation--weighting the past more heavily than the current.\
1. Update the cache file with the latest results.\
1. Set the minimum threshold for the number of data points and set the number of standard deviations away from the mean it must be to be considered a spike.\
1. Make a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
1. Filter out anything that it determines is not a spike and return the list of ARNs to the main search. The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Network ACL Activity by ARN" support search once to create a lookup file of previously seen Network ACL Activity. To add or remove API event names related to network ACLs, edit the macro `network_acl_events`.
action.escu.known_false_positives = The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Please modify this according the your environment.
action.escu.creation_date = 2018-05-17
action.escu.modification_date = 2018-05-21
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in Network ACL Activity - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 10 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in Network ACL Activity
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of AWS API calls related to network ACLs by $user$ was detected.
action.notable.param.rule_title = Spike in AWS Network ACL activity detected by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `network_acl_events` [search sourcetype=aws:cloudtrail `network_acl_events` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup network_acl_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in S3 Bucket deletion - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects users creating spikes in API activity related to deletion of S3 buckets in your AWS environment. It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Execution"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through the following series of steps: \
1. Retrieve all the AWS CloudTrail log entries that have recorded AWS API calls specifically for deletion of S3 buckets.\
1. Kick off a subsearch that retrieves the same data and pulls out and converts the ARN into a more friendly format.\
1. Count the number of API calls per ARN.\
1. Load the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
1. Drop the count from the latest hour, since it is unnecessary, and merge the rest of the data with the results of the `stats` command. \
1. Rename `apiCalls` as `latestCount`.\
1. Calculate the new average value for each ARN with the latest count, weighting the past more heavily than the current hour. It does the same for the standard deviation&#151;weighting the past more heavily than the current.\
1. Update the cache file with the latest results.\
1. Set the minimum threshold for the number of data points and the number of standard deviations away from the mean it must be to be considered a spike.\
1. Make a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and if the count is a sufficient number of standard deviations away from the average.\
1. Filter out anything that it determines is not a spike and returns the list of ARNs to the main search. The main search subsequently gets the names of the deleted S3 buckets, the number of unique API calls, and the total number of API calls for each of these user ARNs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of S3 Bucket deletion activity by ARN" support search once to create a baseline of previously seen S3 bucket-deletion activity.
action.escu.known_false_positives = Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.
action.escu.creation_date = 2018-07-17
action.escu.modification_date = 2018-11-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in S3 Bucket deletion - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = S3 Bucket
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in S3 Bucket deletion
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of S3 buckets deleted by $user$ was detected.
action.notable.param.rule_title = Spike detected in S3 bucket deletion activity by $user$.
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=DeleteBucket [search sourcetype=aws:cloudtrail eventName=DeleteBucket | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup s3_deletion_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | stats values(bucketName) as bucketName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in Security Group Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes in API activity related to security groups in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Execution"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through the following series of steps: \
1. Retrieves all the AWS CloudTrail log entries that have recorded AWS API calls specifically for security groups.\
1. Kicks off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.\
1. Counts the number of API calls per ARN.\
1. Loads the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
1. Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. \
1. Renames `apiCalls` as `latestCount`.\
1. Calculates the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation--weighting the past more heavily than the current.\
1. Updates the cache file with the latest results.\
1. Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.\
1. Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
1. Filters out anything that it determines is not a spike and returns the list of ARNs to the main search. The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.This search works best when you run the "Baseline of Security Group Activity by ARN" support search once to create a history of previously seen Security Group Activity. To add or remove API event names for security groups, edit the macro `security_group_api_calls`.
action.escu.known_false_positives = Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in Security Group Activity - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in Security Group Activity
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of AWS API calls related to security groups by $user$ was detected.
action.notable.param.rule_title = Spike in AWS Security Group activity detected by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `security_group_api_calls` [search sourcetype=aws:cloudtrail `security_group_api_calls` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup security_group_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "mitre_attack": ["Exfiltration", "Command and Control"], "nist": ["DE.AE", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search retrieves all the VPC Flow log entries that have recorded a blocked outbound network connection originating from your AWS environment. Then it kicks off a subsearch, which looks at the same data and performs the following series of steps: \
1. Counts the number of blocked outbound connections by each source IP\
1. Loads the cache file that contains the number of data points, the count from the latest hour, the average blocked connections, and the standard deviation for each source IP.\
1. Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. \
1. Renames `numberOfBlockedConnections` as `latestCount`.\
1. Calculates the new average value for each source IP with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation, weighting the past more heavily than the current.\
1. Updates the cache file with the latest results.\
1. Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.\
1. Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
1. Filters out anything that it determines is not a spike and returns the list of source IPs to the main search. The main search subsequently gets the list of all destination IPs for which the traffic was blocked, the network interface ID, the number of unique destination IP, and the total number of blocked connections for each of these source IP addresses. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your VPC Flow logs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the number of data points required to meet the definition of "spike." The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Blocked Outbound Connection" support search once to create a history of previously seen blocked outbound connections.
action.escu.known_false_positives = The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Additionally, false positives may result when AWS administrators roll out policies enforcing network blocks, causing sudden increases in the number of blocked outbound connections.
action.escu.creation_date = 2018-04-26
action.escu.modification_date = 2018-05-07
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in blocked Outbound Traffic from your AWS
action.notable = 1
action.notable.param.nes_fields = src_ip
action.notable.param.rule_description = A spike in the blocked outbound connection is detected from source $src_ip$.
action.notable.param.rule_title = Spike in blocked outbound network connections from $src_ip$ detected.
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  [search  sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  | stats count as numberOfBlockedConnections by src_ip | inputlookup baseline_blocked_outbound_connections append=t | fields - latestCount | stats values(*) as * by src_ip | rename numberOfBlockedConnections as latestCount | eval newAvgBlockedConnections=avgBlockedConnections + (latestCount-avgBlockedConnections)/720 | eval newStdevBlockedConnections=sqrt(((pow(stdevBlockedConnections, 2)*719 + (latestCount-newAvgBlockedConnections)*(latestCount-avgBlockedConnections))/720)) | eval avgBlockedConnections=coalesce(newAvgBlockedConnections, avgBlockedConnections), stdevBlockedConnections=coalesce(newStdevBlockedConnections, stdevBlockedConnections), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | eval dataPointThreshold = 5, deviationThreshold = 3 | eval isSpike=if((latestCount > avgBlockedConnections+deviationThreshold*stdevBlockedConnections) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | table src_ip] | stats values(dest_ip) as "Blocked Destination IPs", values(interface_id) as "resourceId" count as numberOfBlockedConnections, dc(dest_ip) as uniqueDestConnections by src_ip

[ESCU - Detect USB device insertion - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to detect hosts that generate Windows Event ID 4663 for successful attempts to write to or read from a removable storage and Event ID 4656 for failures, which occurs when a USB drive is plugged in. In this scenario we are querying the Change_Analysis data model to look for Windows Event ID 4656 or 4663 where the priority of the affected host is marked as high in the ES Assets and Identity Framework.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Exfiltration"], "nist": ["PR.PT", "PR.DS"]}
action.escu.data_models = ["Change_Analysis"]
action.escu.eli5 = USB is a common attack vector for delivering or propagating malicious code, or the exfiltration of data. Your corporation may have a policy of not allowing removable media at all, or may only allow approved media to be used on specific hosts by specific users. By logging USB activity from Windows and other endpoints gathered using the Universal Forwarder, you can gain an understanding of what systems might be vulnerable to attack via removable media, or what users might need additional security training. This search is looking for event_id 4656 for failure and 4663 for successful USB read/write attempts from Windows Security Event logs, which is the event code generated when a files are read from and written to a removable storage device
action.escu.how_to_implement = To successfully implement this search, you must ingest Windows Security Event logs and track event code 4663 and 4656. Ensure that the field from the event logs is being mapped to the result_id field in the Change_Analysis data model. To minimize the alert volume, this search leverages the Assets and Identity framework to filter out events from those assets not marked high priority in the Enterprise Security Assets and Identity Framework.
action.escu.known_false_positives = Legitimate USB activity will also be detected. Please verify and investigate as appropriate.
action.escu.creation_date = 2017-08-03
action.escu.modification_date = 2017-11-27
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect USB device insertion - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Data Protection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect USB device insertion
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Read/Write attempt to a USB was detected on this host
action.notable.param.rule_title = Read/Write attempt to a USB detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = low
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) AS earliest latest(_time) AS latest from datamodel=Change_Analysis where (nodename = All_Changes) All_Changes.result="Removable Storage device" (All_Changes.result_id=4663 OR All_Changes.result_id=4656) (All_Changes.src_priority=high) by All_Changes.dest | `drop_dm_object_name("All_Changes")`| `security_content_ctime(earliest)`| `security_content_ctime(latest)` 

[ESCU - Detect Unauthorized Assets by MAC address - Rule]
action.escu = 0
action.escu.enabled = 1
description = By populating the organization's assets within the assets_by_str.csv, we will be able to detect unauthorized devices that are trying to connect with the organization's network by inspecting DHCP request packets, which are issued by devices when they attempt to obtain an IP address from the DHCP server. The MAC address associated with the source of the DHCP request is checked against the list of known devices, and reports on those that are not found.
action.escu.mappings = {"cis20": ["CIS 1"], "kill_chain_phases": ["Reconnaissance", "Delivery", "Actions on Objectives"], "mitre_attack": ["Defense Evasion"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Network_Sessions"]
action.escu.eli5 = This search requires you to leverage the Enterprise Security Assets and Identity framework to populate assets_by_str.csv. Once the assets_by_str.csv is populated, we then query your DHCP logs to detect unknown systems connecting to your network. More documentation is available at: http://docs.splunk.com/Documentation/ES/4.7.1/Admin/Verifyassetandidentitydata.
action.escu.how_to_implement = This search uses the Network_Sessions data model shipped with Enterprise Security. It leverages the Assets and Identity framework to populate the assets_by_str.csv file located in SA-IdentityManagement, which will contain a list of known authorized organizational assets including their MAC addresses. Ensure that all inventoried systems have their MAC address populated.
action.escu.known_false_positives = This search might be prone to high false positives. Please consider this when conducting analysis or investigations. Authorized devices may be detected as unauthorized. If this is the case, verify the MAC address of the system responsible for the false positive and add it to the Assets and Identity framework with the proper information.
action.escu.creation_date = 2017-06-11
action.escu.modification_date = 2017-09-13
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Unauthorized Assets by MAC address - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Infrastructure
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Asset Tracking"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Unauthorized Assets by MAC address
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = The host $src$ issued a DHCP request to connect with your network that does not belong to the list of authorized devices
action.notable.param.rule_title = Unauthorized Asset found with mac address: $src_mac$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_mac,src_ip
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST by All_Sessions.src_ip All_Sessions.src_mac | dedup All_Sessions.src_mac| `drop_dm_object_name("Network_Sessions")`|`drop_dm_object_name("All_Sessions")` | search NOT [| inputlookup asset_lookup_by_str |rename mac as src_mac | fields + src_mac]

[ESCU - Detect Use of cmd.exe to Launch Script Interpreters - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the execution of the cscript.exe or wscript.exe processes, with a parent of cmd.exe. The search will return the count, the first and last time this execution was seen on a machine, the user, and the destination of the machine
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["Execution", "Command-Line Interface"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers often leverage various scripting languages to execute their attacks. In a Windows environment, the Windows Script Host is the tool that interprets the scripts and is included in all modern versions of Windows. The Windows Script Host is available as a command-line tool called "cscript.exe" or "wscript.exe." To detect this behavior, the search looks for process-creation events for cscript.exe or wscript.exe with a parent process of cmd.exe. The search will return the count, the first and last times this behavior was seen on a destination machine, and user and process information.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Some legitimate applications may exhibit this behavior.
action.escu.creation_date = 2017-10-09
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Use of cmd.exe to Launch Script Interpreters - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)", "Suspicious Command-Line Executions"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Use of cmd.exe to Launch Script Interpreters
action.notable = 1
action.notable.param.nes_fields = dest, process_name, parent_process
action.notable.param.rule_description = Potentially malicious script execution detected.
action.notable.param.rule_title = Command prompt is executing scripts on $dest$ using $process_name$ 
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process="*cmd.exe" (Processes.process_name=cscript.exe OR Processes.process_name =wscript.exe) by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`

[ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific GET or HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers. JexBoss is described as the exploit tool of choice for this malicious activity.
action.escu.mappings = {"kill_chain_phases": ["Reconnaissance"], "mitre_attack": ["Discovery", "System Information Discovery"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search returns the number of times a URL associated with this type of JexBoss probe is observed.
action.escu.how_to_implement = You must be ingesting data from the web server or network traffic that contains web specific information, and populating the Web data model.
action.escu.known_false_positives = It's possible for legitimate HTTP requests to be made to URLs containing the suspicious paths.
action.escu.creation_date = 2016-10-04
action.escu.modification_date = 2017-09-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Apache", "Bro"]
action.escu.analytic_story = ["JBoss Vulnerability", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect attackers scanning for vulnerable JBoss servers
action.notable = 1
action.notable.param.nes_fields = 
action.notable.param.rule_description = This search looks for specific GET/HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers.
action.notable.param.rule_title = Detect attackers scanning for vulnerable JBoss servers
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,url
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") AND (Web.url="*/web-console/ServerInfo.jsp*" OR Web.url="*web-console*" OR Web.url="*jmx-console*" OR Web.url = "*invoker*") by Web.http_method, Web.url, Web.src, Web.dest | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Detect hosts connecting to dynamic domain providers - Rule]
action.escu = 0
action.escu.enabled = 1
description = Malicious actors often abuse legitimate Dynamic DNS services to host malicious payloads or interactive command and control nodes. Attackers will automate domain resolution changes by routing dynamic domains to countless IP addresses to circumvent firewall blocks, blacklists as well as frustrate a network defenders analytic and investigative processes. This search will look for DNS queries made from within your infrastructure to suspicious dynamic domains.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 12", "CIS 13"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Exfiltration", "Exfiltration Over Command and Control Channel", "Defense Evasion", "Commonly Used Port"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = The search leverages an accelerated `Network_Resolution` data model to count and list the values of resolved domains for each DNS query. It checks the results against the list of Dynamic DNS providers in the lookup `dynamic_dns_providers` by each host (DNS.src).
action.escu.how_to_implement = First, you'll need to ingest data from your DNS operations. This can be done by ingesting logs from your server or data, collected passively by Splunk Stream or a similar solution. Specifically, data that contains the domain that is being queried and the IP of the host originating the request must be populating the `Network_Resolution` data model. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of Dynamic DNS providers. Please consider updating the local lookup periodically by adding new domains to the list of `dynamic_dns_providers_local.csv`.\
This search produces fields (query, answer, isDynDNS) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable event. To see the additional metadata, add the following fields, if not already present, to Incident Review. Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** DNS Query, **Field:** query\
1. \
1. **Label:** DNS Answer, **Field:** answer\
1. \
1. **Label:** IsDynamicDNS, **Field:** isDynDNS\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = Some users and applications may leverage Dynamic DNS to reach out to some domains on the Internet since dynamic DNS by itself is not malicious, however this activity must be verified.
action.escu.creation_date = 2017-11-17
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect hosts connecting to dynamic domain providers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "query"]
action.escu.entities = ["dest", "query"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "DNS Hijacking", "Data Protection", "Dynamic DNS", "Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect hosts connecting to dynamic domain providers
action.notable = 1
action.notable.param.nes_fields = answer, src, query
action.notable.param.rule_description = The search has detected a host making outbound queries to Dynamic DNS providers
action.notable.param.rule_title = Host $src$ detected to make a query to a Dynamic DNS provider
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, query
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(DNS.answer) as answer min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `security_content_ctime(firstTime)` | `dynamic_dns_providers`

[ESCU - Detect malicious requests to exploit JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect malicious HTTP requests crafted to exploit jmx-console in JBoss servers. The malicious requests have a long URL length, as the payload is embedded in the URL.
action.escu.mappings = {"cis20": ["CIS 12", "CIS 4", "CIS 18"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "nist": ["ID.RA", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for HTTP requests for a URL that has been used to exploit JBoss servers.
action.escu.how_to_implement = You must ingest data from the web server or capture network data that contains web specific information with solutions such as Bro or Splunk Stream, and populating the Web data model
action.escu.known_false_positives = No known false positives for this detection.
action.escu.creation_date = 2016-10-04
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect malicious requests to exploit JBoss servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Apache", "Bro"]
action.escu.analytic_story = ["JBoss Vulnerability", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect malicious requests to exploit JBoss servers
action.notable = 1
action.notable.param.nes_fields = src, dest_ip
action.notable.param.rule_description = A search for detecting malicious requests made to exploit jmx-console in JBoss servers. The bad requests have a long url length since it serves the payload via the url
action.notable.param.rule_title = Detected malicious requests to exploit JBoss servers
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,url,src
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") by Web.http_method, Web.url,Web.url_length Web.src, Web.dest | search Web.url="*jmx-console/HtmlAdaptor?action=invokeOpByName&name=jboss.admin*import*" AND Web.url_length > 200 | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table src, dest_ip, http_method, url, firstTime, lastTime

[ESCU - Detect mshta.exe running scripts in command-line arguments - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the execution of "mshta.exe" with command-line arguments that launch a script. The search will return the first time and last time these command-line arguments were used for these executions, as well as the target system, the user, process "mshta.exe" and its parent process.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Mshta.exe is a built-in Windows utility that can launch HTML files with .hta extensions (HTML applications), javascript, or VBScript. The search detects this behavior by looking for events where the process mshta.exe is executed with command-line arguments that indicate that a script is invoked
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with the process name, parent process, and command-line executions from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Although unlikely, some legitimate applications may exhibit this behavior, triggering a false positive.
action.escu.creation_date = 2018-08-07
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect mshta.exe running scripts in command-line arguments - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious MSHTA Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect mshta.exe running scripts in command-line arguments
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process_name
action.notable.param.rule_description = Mshta.exe is seen to be executing scripts via the command-line arguments
action.notable.param.rule_title = Mshta.exe is executing scripts on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process, parent_process_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=mshta.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search (process=*vbscript* OR process=*javascript*)

[ESCU - Detect new API calls from user roles - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects new API calls that have either never been seen before or that have not been seen in the previous hour, where the identity type is `AssumedRole`.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch will execute first and return the user roles and names of the API calls completed within the last hour, where the type of user identity is `AssumedRole`. It then appends the historical data to those results in the lookup file. Next, it recalculates the `earliest` and `latest` fields for each user role, as well as the name of the API call, and returns only those roles and API calls that have first been seen in the past hour. This is combined with the main search to return the values of API calls, name of the user role, and the earliest and latest time of this activity. It is worth noting that the name of the role of a particular user is parsed as "userName" in the CloudTrail logs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously seen API call per user roles in CloudTrail" support search once to create a history of previously seen user roles.
action.escu.known_false_positives = It is possible that there are legitimate user roles making new or infrequently used API calls in your infrastructure, causing the search to trigger.
action.escu.creation_date = 2018-04-01
action.escu.modification_date = 2018-04-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect new API calls from user roles - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect new API calls from user roles
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A new API call made by $user$ has been detected. This API activity has either never been seen before or has not been seen within the last hour.
action.notable.param.rule_title = New API call by $user$ detected
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole [search sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success  userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName |  inputlookup append=t previously_seen_api_calls_from_user_roles | stats min(earliest) as earliest, max(latest) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles| eval newApiCallfromUserRole=if(earliest>=relative_time(now(), "-70m@m"), 1, 0) | where newApiCallfromUserRole=1 | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | table eventName userName]  |rename userName as user| stats values(eventName) earliest(_time) as earliest latest(_time) as latest by user | `security_content_ctime(earliest)` | `security_content_ctime(latest)`

[ESCU - Detect new user AWS Console Login - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that a user has attempted to log in to the AWS console and group the events using ARN value. Using the `previously_seen_users_console_logins.csv` lookup file created using the support search, we compare the ARN to all the previously seen users logging into the AWS console. The `eval` and `if` functions determine whether the earliest time we see this user ARN was seen within the last hour. The alert will be fired only when a user is seen for first time in the last hour.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-04-30
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect new user AWS Console Login - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect new user AWS Console Login
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A new user has logged into the AWS console
action.notable.param.rule_title = AWS Console Login by New User
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=ConsoleLogin | rename userIdentity.arn as user | stats earliest(_time) as firstTime latest(_time) as lastTime by user | inputlookup append=t previously_seen_users_console_logins.csv  | stats min(firstTime) as firstTime max(lastTime) as lastTime by user | eval userStatus=if(firstTime >= relative_time(now(), "-70m@m"), "First Time Logging into AWS Console","Previously Seen User") | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| where userStatus ="First Time Logging into AWS Console" 

[ESCU - Detect processes used for System Network Configuration Discovery - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for fast execution of processes used for system network configuration discovery on the endpoint.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers have a range of built-in Windows tools they leverage to ascertain the topography of a network from the point of view of a compromised machine. It is uncommon to see these commands execute quickly within short periods of time. This search returns the number of times, as well as the first time and last times, that every process has run for each endpoint. It then executes the macro `system_network_configuration_discovery_tools`, which looks for processes that are typically used for network configuration discovery. Once you have a list of suspicious process launches for each destination, you can leverage the transaction command to see what processes are fired within a five-minute span on an endpoint and detect only those events where the count of these processes is greater than five.
action.escu.how_to_implement = You must be ingesting data that records registry activity from your hosts to populate the Endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report reads and writes to the registry or that are populated via Windows event logs, after enabling process tracking in your Windows audit settings.
action.escu.known_false_positives = It is uncommon for normal users to execute a series of commands used for network discovery. System administrators often use scripts to execute these commands. These can generate false positives.
action.escu.creation_date = 2018-11-04
action.escu.modification_date = 2018-11-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect processes used for System Network Configuration Discovery - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect processes used for System Network Configuration Discovery
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = Fast execution of processes $related to network system configuration discovery seen on $dest$.
action.notable.param.rule_title = Fast execution of processes $process_name$ related to network discovery seen on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.process_name Processes.user _time | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | search `system_network_configuration_discovery_tools` | transaction dest connected=false maxpause=5m |where eventcount>=5 | table firstTime lastTime dest user process_name process parent_process eventcount

[ESCU - Detect web traffic to dynamic domain providers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for web connections to dynamic DNS providers.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Command and Control", "Web Service", "Exfiltration Over Command and Control Channel", "Defense Evasion"], "nist": ["PR.IP", "DE.DP"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for hosts in your environment that may be communicating with a dynamic DNS provider. It checks each URL an endpoint is connecting to against a list of dynamic DNS providers. It returns the source and destination IP address of the web request, the URL requested, and the first time the event occurred.
action.escu.how_to_implement = This search requires you to be ingesting web-traffic logs. You can obtain these logs from indexing data from a web proxy or by using a network-traffic-analysis tool, such as Bro or Splunk Stream. The web data model must contain the URL being requested, the IP address of the host initiating the request, and the destination IP. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of dynamic DNS providers. Consider periodically updating this local lookup file with new domains.\
This search produces fields (`isDynDNS`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** IsDynamicDNS, **Field:** isDynDNS\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = It is possible that list of dynamic DNS providers is outdated and/or that the URL being requested is legitimate.
action.escu.creation_date = 2018-09-06
action.escu.modification_date = 2018-09-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect web traffic to dynamic domain providers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.analytic_story = ["Dynamic DNS"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect web traffic to dynamic domain providers
action.notable = 1
action.notable.param.nes_fields = src, url, dest
action.notable.param.rule_description = The host $src$ has been detected making a web request to $url$, which is a listed as a dynamic DNS provider.
action.notable.param.rule_title = Dynamic DNS web traffic detected on $src$.
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, url , dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Web.url) as url min(_time) as firstTime from datamodel=Web where Web.status=200 by Web.src Web.dest Web.status | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `dynamic_dns_web_traffic`

[ESCU - Detection of DNS Tunnels - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect DNS tunneling, by calculating the sum of the length of DNS queries and DNS answers. The search also filters out potential false positives by filtering out queries made to internal systems and the queries originating from internal DNS, Web, and Email servers. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting an unusually large volume of DNS traffic.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "nist": ["PR.PT", "PR.DS"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = The search will calculate the distinct count and sum of the length of DNS queries made and DNS answers received by a particular host to alert the analyst if the combined length is greater than 10000, which is not typical behavior.
action.escu.how_to_implement = To successfully implement this search, we must ensure that DNS data is being ingested and mapped to the appropriate fields in the Network_Resolution data model. Fields like src_category are automatically provided by the Assets and Identity Framework shipped with Splunk Enterprise Security. You will need to ensure you are using the Assets and Identity Framework and populating the src_category field. You will also need to enable the `cim_corporate_web_domain_search()` macro which will essentially filter out the DNS queries made to the corporate web domains to reduce alert fatigue.
action.escu.known_false_positives = It's possible that normal DNS traffic will exhibit this behavior. If an alert is generated, please investigate and validate as appropriate. The threshold can also be modified to better suit your environment.
action.escu.creation_date = 2017-07-19
action.escu.modification_date = 2017-09-18
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detection of DNS Tunnels - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Data Protection", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detection of DNS Tunnels
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = Potential DNS tunnel detected from $src$ which may be exfiltrating large data
action.notable.param.rule_title = DNS tunnel detected on $src$
action.notable.param.security_domain = network
action.notable.param.severity = low
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, query
alert.suppress.period = 43200s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` dc("DNS.query") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.query" | rename "DNS.src" as src  "DNS.query" as message | eval length=len(message) | stats sum(length) as length by src | append [ tstats `security_content_summariesonly` dc("DNS.answer") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.answer" | rename "DNS.src" as src  "DNS.answer" as message | eval message=if(message=="unknown","", message) | eval length=len(message) | stats sum(length) as length by src ] | stats sum(length) as length by src | where length > 10000

[ESCU - Detection of tools built by NirSoft - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific command-line arguments that may indicate the execution of tools made by Nirsoft, which are legitimate, but may be abused by attackers.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Discovery", "Execution", "Lateral Movement", "Third-party Software", "Account Discovery"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for process-creation events accompanied by specific command-line arguments ("scomma" and "stext"). These parameters may be leveraged by a set of free, legitimate tools built by NirSoft. Attackers have been seen abusing the tools' capabilities to steal passwords, set up key loggers, recover account information from mail clients, and conduct other nefarious activities. The search will identify the count, the first and last times a process is executed, the command-line arguments, and the parent process.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = While legitimate, these NirSoft tools are prone to abuse. You should verfiy that the tool was used for a legitimate purpose.
action.escu.creation_date = 2018-09-11
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detection of tools built by NirSoft - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detection of tools built by NirSoft
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for specific arguments passed via the command line and detects execution of tools built by NirSoft, which are often abused by attackers.
action.notable.param.rule_title = Potential abuse of NirSoft tools on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process="* /stext *" OR Processes.process="* /scomma *" ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)`

[ESCU - Disabling Remote User Account Control - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to registry keys that control the enforcement of Windows User Account Control (UAC).
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Modify Registry"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search checks to see if the registry key SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\System\LocalAccountTokenFilterPolicy was modified.  This registry key can be used to disable remote User Account Control.  The search returns the count, the first time activity was seen, last time activity was seen, the registry path that was modified, the host where the modification took place and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.
action.escu.known_false_positives = This registry key may be modified via administrators to implement a change in system policy. This type of change should be a very rare occurrence.
action.escu.creation_date = 2017-10-12
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Disabling Remote User Account Control - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Disabling Remote User Account Control
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = The registry key SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\System\LocalAccountTokenFilterPolicy was modified.  This registry key is associated with disabling remote UAC on Windows.
action.notable.param.rule_title = Registry Key Associated With Disabling Remote UAC Modified on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, registry_path
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.registry_path="*Windows\\CurrentVersion\\Policies\\System\\LocalAccountTokenFilterPolicy" by Registry.dest, Registry.registry_key_name Registry.status Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)`

[ESCU - EC2 Instance Modified With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being modified by users who have not previously modified them.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the ARNs of all successful EC2 instance modifications within the last hour and then appends the historical data in the lookup file to those results. EC2 modification APIs are defined by the macro `ec2_modification_api_calls`. The search then recalculates the `firstTime` and `lastTime` field for each ARN and returns only those ARNs that have first been seen in the past hour. This is combined with the main search to return the time, user, and instance ID of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
action.escu.known_false_positives = It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Modified With Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Modified With Previously Unseen User
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = The EC2 instance $dest$ was modified by $user$. This user has never modified an EC2 instance before.
action.notable.param.rule_title = EC2 Instance Modified By Previously Unseen User $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `ec2_modification_api_calls` [search sourcetype=aws:cloudtrail `ec2_modification_api_calls` errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_modifications_by_user | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=dest responseElements.instancesSet.items{}.instanceId | spath output=user userIdentity.arn | table _time, user, dest

[ESCU - EC2 Instance Started In Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where an instance is started in a particular region in the last one hour and then compares it to a lookup file of previously seen regions where an instance was started
action.escu.mappings = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that an instance was started in a particular region. Using the `previously_seen_aws_regions.csv` lookup file created using the support search, we compare the region where this instance was started to all previously observed regions. The `eval` and `if` functions determine that the earliest times seen for this region and instance were within the last day. If a new region is detected, it will alert you with "Instance Started in a New Region". However, this region will be added to the list of `previously_seen_aws_regions.csv`. Please maintain `previously_seen_aws_regions.csv`
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen AWS Regions" support search only once to create of baseline of previously seen regions.
action.escu.known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
action.escu.creation_date = 2018-02-01
action.escu.modification_date = 2018-02-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started In Previously Unseen Region - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["awsRegion"]
action.escu.entities = ["awsRegion"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started In Previously Unseen Region
action.notable = 1
action.notable.param.nes_fields = awsRegion
action.notable.param.rule_description = An AWS instance is started in a new, previously unseen, region
action.notable.param.rule_title = AWS instance is started in a new region
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = awsRegion
action.risk.param._risk_object_type = other
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = awsRegion
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail earliest=-1h StartInstances  | stats earliest(_time) as earliest latest(_time) as latest by awsRegion| inputlookup append=t previously_seen_aws_regions.csv | stats min(earliest) as earliest max(latest) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | eval regionStatus=if(earliest >= relative_time(now(), "-1d@d"), "Instance Started in a New Region","Previously Seen Region") | convert security_content_ctime(earliest) security_content_ctime(latest) | where regionStatus="Instance Started in a New Region"

[ESCU - EC2 Instance Started With Previously Unseen AMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created with previously unseen AMIs.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the AMI image ID of all successful EC2 instance launches within the last hour and then appends the historical data from the lookup file to those results.  It then recalculates the earliest and latest seen time field for each AMI image ID and returns only those AMI image IDs that have first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 AMIs" support search once to create a history of previously seen AMIs.
action.escu.known_false_positives = After a new AMI is created, the first systems created with that AMI will cause this alert to fire.  Verify that the AMI being used was created by a legitimate user.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen AMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started With Previously Unseen AMI
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The EC2 instance $dest$ was created with previously unused AMI $amiID$
action.notable.param.rule_title = EC2 Instance Type $dest$ Created With New AMI
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by requestParameters.instancesSet.items{}.imageId | rename requestParameters.instancesSet.items{}.imageId as amiID | inputlookup append=t previously_seen_ec2_amis.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by amiID | outputlookup previously_seen_ec2_amis.csv | eval newAMI=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | where newAMI=1 | rename amiID as requestParameters.instancesSet.items{}.imageId | table requestParameters.instancesSet.items{}.imageId] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as arn, requestParameters.instancesSet.items{}.imageId as amiID | table firstTime, lastTime, arn, amiID, dest, instanceType

[ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created with previously unseen instance types.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the instance types of all successful EC2 instance launches within the last hour and then appends the historical data in the lookup file to those results.  It then recalculates the earliest seen time field for each instance type and returns only those instance types that has first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Instance Types" support search once to create a history of previously seen instance types.
action.escu.known_false_positives = It is possible that an admin will create a new system using a new instance type never used before. Verify with the creator that they intended to create the system with the new instance type.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started With Previously Unseen Instance Type
action.notable = 1
action.notable.param.nes_fields = instanceType
action.notable.param.rule_description = The EC2 instance type $instanceType$ was used for the first time to create $dest$.
action.notable.param.rule_title = New EC2 Instance Type $instanceType$ detected
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | fillnull value="m1.small" requestParameters.instanceType | stats earliest(_time) as earliest latest(_time) as latest by requestParameters.instanceType | rename requestParameters.instanceType as instanceType | inputlookup append=t previously_seen_ec2_instance_types.csv | stats min(earliest) as earliest max(latest) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | eval newType=if(earliest >= relative_time(now(), "-70m@m"), 1, 0) | convert security_content_ctime(earliest) security_content_ctime(latest) | where newType=1 | rename instanceType as requestParameters.instanceType | table requestParameters.instanceType] | spath output=user userIdentity.arn | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest | table _time, user, dest, instanceType

[ESCU - EC2 Instance Started With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created by users who have not created them before.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the ARNs of all successful EC2 instance launches within the last hour and then appends the historical data in the lookup file to those results.  It then recalculates the `firstTime` and `lastTime` field for each ARN and returns only those ARNs that have first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs.
action.escu.known_false_positives = It's possible that a user will start to create EC2 instances when they haven't before for any number of reasons. Verify with the user that is launching instances that this is the intended behavior.
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started With Previously Unseen User
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = The EC2 instance $dest$ was created by $user$.  This user has never created an EC2 instance before.
action.notable.param.rule_title = EC2 Instance Created By Previously Unseen User $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_launches_by_user.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as user | table _time, user, dest, instanceType

[ESCU - Email Attachments With Lots Of Spaces - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attackers often use spaces as a means to obfuscate an attachment's file extension. This search looks for messages with email attachments that have many spaces within the file names.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "mitre_attack": [], "nist": ["PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks at any emails with file attachment names that contain many spaces, relative to the length of the file name. Specifically, it checks to see whether spaces make up more than 10% of the number of characters in the file name. This percentage can be tuned for each environment. The search will output the message ID of the email, the count, the sender and recipient addresses, the first and last time this event was seen, and the space ratio of the file attachment name.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. The threshold ratio is set to 10%, but this value can be configured to suit each environment. \
 **Splunk Phantom Playbook Integration**\
If Splunk Phantom is also configured in your environment, a playbook called "Suspicious Email Attachment Investigate and Delete" can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/` and add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search. The notable event will be sent to Phantom and the playbook will gather further information about the file attachment and its network behaviors. If Phantom finds malicious behavior and an analyst approves of the results, the email will be deleted from the user's inbox.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-09-19
action.escu.confidence = high
action.escu.full_search_name = ESCU - Email Attachments With Lots Of Spaces - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src", "message_id"]
action.escu.entities = ["src", "message_id"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Email Attachments With Lots Of Spaces
action.notable = 1
action.notable.param.nes_fields = src_user, file_name
action.notable.param.rule_description = The sender $src_user$ has sent an email with a suspicious amount of spaces in the file name: $file_name$
action.notable.param.rule_title = Suspicious Email Attachment from $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(All_Email.recipient) as recipient_address min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Email")` | eval space_ratio = (mvcount(split(file_name," "))-1)/len(file_name) | search space_ratio >= 0.1 |  rex field=recipient_address "(?<recipient_user>.*)@"

[ESCU - Email files written outside of the Outlook directory - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks at the change-analysis data model and detects email files created outside the normal Outlook directory.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Collection", "Email Collection"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are looking for activities consistent with an adversary collecting email data from local machines. The search will detect email files (files with .pst or .ost extensions) created in directories other than the standard Outlook directory (c:\users\username\My Documents\Outlook Files\.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = Administrators and users sometimes prefer backing up their email data by moving the email files into a different folder. These attempts will be detected by the search.
action.escu.creation_date = 2017-12-13
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Email files written outside of the Outlook directory - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Email files written outside of the Outlook directory
action.notable = 1
action.notable.param.nes_fields = dest, file_path, action, file_name
action.notable.param.rule_description = The system $dest$ has email files outside of the normal Outlook directory 
action.notable.param.rule_title = Email files created or modified on $dest$ that are not in the normal Outlook directory
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, file_path
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Filesystem where (Filesystem.file_name=*.dll OR Filesystem.file_name=*.ost) Filesystem.file_path != "C:\\Users\\*\\My Documents\\Outlook Files\\*" by Filesystem.action Filesystem.process_id Filesystem.file_name Filesystem.dest | `drop_dm_object_name("Filesystem")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Email servers sending high volume traffic to hosts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Collection", "Email Collection", "Commonly Used Port"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search may look complex, but it's a neat representation of how statistics can help you understand your dataset to bubble up events that are not normal compared to its behavior. The search consists of three parts. The first part of the SPL fetches the data you want to work on. In this search, we calculate the sum of bytes sent and bytes_out from systems categorized as email_server to each host. We then calculate the average and standard deviation for the bytes sent to all the hosts combined and on a per-host basis. Then we set threshold values to deviation_threshold and minimum_data_samples using eval statements. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.  We then check for byte transfers that are statistically significantly higher than normal. The search then gives IP address of the host, the time of the increased byte transfer, how much data was transferred, and the average amount of data transfer the email server normally sends to all hosts and to this specific host. Finally, it includes the number of standard deviations away the byte count was from these averages.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.creation_date = 2017-12-20
action.escu.modification_date = 2017-12-20
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Email servers sending high volume traffic to hosts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest_ip"]
action.escu.entities = ["dest_ip"]
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Email servers sending high volume traffic to hosts
action.notable = 1
action.notable.param.nes_fields = dest_ip
action.notable.param.rule_description = High volume of traffic that originated from an email server is being sent to $dest_ip$
action.notable.param.rule_title = High volume of traffic from an email server sent to $dest_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` sum(All_Traffic.bytes_out) as bytes_out from datamodel=Network_Traffic where All_Traffic.src_category=email_server by All_Traffic.dest_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_out) as avg_bytes_out stdev(bytes_out) as stdev_bytes_out | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_avg_bytes_out stdev(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_stdev_bytes_out by dest_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_out > (avg_bytes_out + (deviation_threshold * stdev_bytes_out)) AND bytes_out > (per_source_avg_bytes_out + (deviation_threshold * per_source_stdev_bytes_out)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_out - avg_bytes_out) / stdev_bytes_out, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_out - per_source_avg_bytes_out) / per_source_stdev_bytes_out, 2) | table dest_ip, _time, bytes_out, avg_bytes_out, per_source_avg_bytes_out, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average

[ESCU - Excessive DNS Failures - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success, and trigger on more than 50 occurrences.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Exfiltration", "Exfiltration Over Alternative Protocol", "Command and Control", "Commonly Used Port"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search looks at DNS traffic with a reply code that is NOT indicative of a successful response. Numerous unsuccessful replies may be indicative of DNS protocol tampering or other malicious activity. If more than 50 of these unsuccessful responses are observed over the time frame of the search, a notable event will be generated.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = It is possible legitimate traffic can trigger this rule. Please investigate as appropriate. The threshold for generating an event can also be customized to better suit your environment.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Excessive DNS Failures - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Excessive DNS Failures
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success and triggers on more than 50 occurrences.
action.notable.param.rule_title = Excessive DNS Failures
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src,query
alert.suppress.period = 43200s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values("DNS.query") as queries from datamodel=Network_Resolution where nodename=DNS "DNS.reply_code"!="No Error" "DNS.reply_code"!="NoError" DNS.reply_code!="unknown" NOT "DNS.query"="*.arpa" "DNS.query"="*.*" by "DNS.src","DNS.query"| `drop_dm_object_name("DNS")`| lookup cim_corporate_web_domain_lookup domain as query OUTPUT domain| where isnull(domain)| lookup update=true alexa_lookup_by_str domain as query OUTPUT rank| where isnull(rank)| stats sum(count) as count mode(queries) as queries by src| `get_asset(src)`| where count>50

[ESCU - Execution of File With Spaces Before Extension - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched from files with at least five spaces in the name before the extension. This is typically done to obfuscate the file extension by pushing it outside of the default view.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Persistence", "Change Default File Association"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search uses the endpoint data model to look for process names with at least five spaces between the file name and its extension.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-01-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Execution of File With Spaces Before Extension - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Execution of File With Spaces Before Extension
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ executed a file with spaces before its extension.
action.notable.param.rule_title = Process $process$ with spaces before extension Launched on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process_path) as process_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = "*     .*" by Processes.dest Processes.user Processes.process Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)`

[ESCU - Execution of File with Multiple Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched from files that have double extensions in the file name. This is typically done to obscure the "real" file extension and make it appear as though the file being accessed is a data file, as opposed to executable content.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Persistence", "Change Default File Association"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search uses the "Application State" data model to look for process names with specific combinations of double extensions. Relatively straightforward, the search looks for strings in the "process" field that match what you're looking for.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Execution of File with Multiple Extensions - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Execution of File with Multiple Extensions
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = The system $dest$ executed a file with a double extension.
action.notable.param.rule_title = Process With Multiple Extensions Launched on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = *.doc.exe OR Processes.process = *.htm.exe OR Processes.process = *.html.exe OR Processes.process = *.txt.exe OR Processes.process = *.pdf.exe OR Processes.process = *.doc.exe by Processes.dest Processes.user Processes.process Processes.parent_process | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)`

[ESCU - Extended Period Without Successful Netbackup Backups - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search returns a list of hosts that have not successfully completed a backup in over a week.
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.eli5 = This search finds all the successful backup messages in your logs, and then looks for the most recent backup time for each system. It then identifies those systems where the most recent successful backup time is over a week ago, and reports on them.
action.escu.how_to_implement = To successfully implement this search you need to first obtain data from your backup solution, either from the backup logs on your hosts, or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your backup solution. Depending on how often you backup your systems, you may want to modify how far in the past to look for a successful backup, other than the default of seven days.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-15
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Extended Period Without Successful Netbackup Backups - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution"]
cron_schedule = 0 0 1 * *
dispatch.earliest_time = -7d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Extended Period Without Successful Netbackup Backups
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ has not had a successful backup for an extended period.
action.notable.param.rule_title = Extended period of no successful backups by $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" MESSAGE="Disk/Partition backup completed successfully." | stats latest(_time) as latestTime by COMPUTERNAME | `security_content_ctime(latestTime)` | rename COMPUTERNAME as dest | eval isOutlier=if(latestTime <= relative_time(now(), "-7d@d"), 1, 0) | search isOutlier=1 | table latestTime, dest

[ESCU - File with Samsam Extension - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for file writes with extensions consistent with a SamSam ransomware attack.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Installation"], "mitre_attack": [], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts and creates notable events when it identifies files with extensions associated with the SamSam ransomware, including `.stubbin`, `.berkshire`, `.satoshi`, `.sophos`, or `.keyxml`. Files with these extensions have been observed in SamSam attacks consisting of payload data or keying material.
action.escu.how_to_implement = You must be ingesting data that records file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Because these extensions are not typically used in normal operations, you should investigate all results.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - File with Samsam Extension - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = File with Samsam Extension
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file with an extension associated with SamSam ransomware was written on $dest$.
action.notable.param.rule_title = File with known SamSam extension detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_extension=.stubbin OR file_extension=.berkshire OR file_extension=.satoshi OR file_extension=.sophos OR file_extension=.keyxml

[ESCU - First Time Seen Running Windows Service - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the first time a Windows service is seen running in your environment.
action.escu.mappings = {"cis20": ["CIS 2", "CIS 9"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Execution", "New Service"], "nist": ["ID.AM", "PR.DS", "PR.AC", "DE.AE"]}
action.escu.eli5 = This search looks for a change in the status of a Windows service and extracts the name of the service and the action taken by the service. Then the cache file of previously seen Windows services is added to the search. At this point, the search takes two different paths: the first updates the cache file with the latest information and the second searches for services that have never before been seen. It returns the time, the Windows host name, and the service name.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs in order for this search to execute successfully. The support search, `Previously Seen Running Windows Services`, should be run before this search to create the baseline of known Windows services.
action.escu.known_false_positives = A previously unseen service is not necessarily malicious. Verify that the service is legitimate and that was installed by a legitimate process.
action.escu.creation_date = 2018-07-22
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - First Time Seen Running Windows Service - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Orangeworm Attack Group", "Windows Service Abuse"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = First Time Seen Running Windows Service
action.notable = 1
action.notable.param.nes_fields = serviceName
action.notable.param.rule_description = The service $serviceName$ is running on $dest$. This is the first time this service has been run on any system.
action.notable.param.rule_title = First Time Seen Windows Service $serviceName$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = serviceName, dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_system signature_id=7036 | rex field=Message "The (?<serviceName>[\w\s-]*) service entered the (?<action>\w*) state" | where action="running" | inputlookup append=t previously_seen_running_windows_services | multireport [| stats earliest(eval(coalesce(_time, firstTime))) as firstTime, latest(eval(coalesce(_time, lastTime))) as lastTime by serviceName | outputlookup previously_seen_running_windows_services | where fact=fiction] [| eventstats earliest(eval(coalesce(_time, firstTime))) as firstTime, latest(eval(coalesce(_time, lastTime))) as lastTime by serviceName | where firstTime >= relative_time(now(), "-60m@m") AND isnotnull(_time) | stats values(dest) as dest by _time, serviceName] | table _time, serviceName, dest

[ESCU - First time seen command line argument - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for command-line arguments that use a `/c` parameter to execute a command that has not previously been seen.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution", "Scripting", "Persistence", "Command-Line Interface"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The subsearch returns all events where `cmd.exe` was used with a `/c` parameter in the command-line arguments to execute other commands/programs. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for command-line execution and outputs this data to the lookup file to update the local cache. It returns only those events that have first been seen in the past one hour. This is combined with the main search to return the time, user, destination, process, parent process, and value of the command-line argument.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model. Please make sure you run the support search "Previously seen command line arguments,"&#151;which creates a lookup file called `previously_seen_cmd_line_arguments.csv`&#151;a historical baseline of all command-line arguments. You must also validate this list. For the search to do accurate calculation, ensure the search scheduling is the same value as the `relative_time` evaluation function.
action.escu.known_false_positives = Legitimate programs can also use command-line arguments to execute. Please verify the command-line arguments to check what command/program is being executed.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2019-03-04
action.escu.confidence = medium
action.escu.full_search_name = ESCU - First time seen command line argument - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Hidden Cobra Malware", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Suspicious Command-Line Executions"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = First time seen command line argument
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = The system $dest$ executed a command-line argument, $process$, that has not previously been seen.
action.notable.param.rule_title = First-time seen command-line argument was detected on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process Processes.process_name Processes.parent_process_name Processes.dest| `drop_dm_object_name(Processes)`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process | `drop_dm_object_name(Processes)` | inputlookup append=t previously_seen_cmd_line_arguments | stats min(firstTime) as firstTime, max(lastTime) as lastTime by process | outputlookup previously_seen_cmd_line_arguments | eval newCmdLineArgument=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCmdLineArgument=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table process]

[ESCU - Hiding Files And Directories With Attrib.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attackers leverage an existing Windows binary, attrib.exe, to mark specific as hidden by using specific flags so that the victim does not see the file.  The search looks for specific command-line arguments to detect the use of attrib.exe to hide files.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Persistence"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search is looking to detect command-line execution with of attrib.exe binary with the +h flag set.  The +h flag is used to hide a file.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Some applications and users may legitimately use attrib.exe to interact with the files. 
action.escu.creation_date = 2017-10-23
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Hiding Files And Directories With Attrib.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Hiding Files And Directories With Attrib.exe
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = Attrib.exe is often used by attackers to hide malware files and directories in windows environments. This rule detects command-line arguments used to hide a file/directory
action.notable.param.rule_title = Suspicious usage of attrib.exe on $dest$ 
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=attrib.exe (Processes.process=*+h*) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`

[ESCU - Hosts receiving high volume of network traffic from email server - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Collection", "Commonly Used Port"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search may look complex, but it's a neat representation of how statistics can help you understand your dataset to bubble up events that are not normal compared to its behavior. The search consists of three parts. The first part of the SPL fetches the data you want to work on. In this search, we calculate the sum of bytes sent and bytes_out from systems categorized as email_server to each host. We then calculate the average and standard deviation for the bytes sent to all the hosts combined and on a per-host basis. Then we set threshold values to deviation_threshold and minimum_data_samples using eval statements. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.  We then check for byte transfers that are statistically significantly higher than normal. The search then gives IP address of the host, the time of the increased byte transfer, how much data was transferred, and the average amount of data transfer the email server normally sends to all hosts and to this specific host. Finally, it includes the number of standard deviations away the byte count was from these averages.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.creation_date = 2017-12-20
action.escu.modification_date = 2017-12-20
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Hosts receiving high volume of network traffic from email server - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Hosts receiving high volume of network traffic from email server
action.notable = 1
action.notable.param.nes_fields = src_ip
action.notable.param.rule_description = $src_ip$ receiving high volume of traffic that originated from an email server
action.notable.param.rule_title = High volume traffic from email server received by $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` sum(All_Traffic.bytes_in) as bytes_in from datamodel=Network_Traffic where All_Traffic.dest_category=email_server by All_Traffic.src_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_in) as avg_bytes_in stdev(bytes_in) as stdev_bytes_in | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_avg_bytes_in stdev(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_stdev_bytes_in by src_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_in > (avg_bytes_in + (deviation_threshold * stdev_bytes_in)) AND bytes_in > (per_source_avg_bytes_in + (deviation_threshold * per_source_stdev_bytes_in)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_in - avg_bytes_in) / stdev_bytes_in, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_in - per_source_avg_bytes_in) / per_source_stdev_bytes_in, 2) | table src_ip, _time, bytes_in, avg_bytes_in, per_source_avg_bytes_in, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average

[ESCU - Identify New User Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This detection search will help profile user accounts in your environment by identifying newly created accounts that have been added to your network in the past week.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["Persistence", "Create Account"], "nist": ["PR.IP"]}
action.escu.data_models = ["Identity_Management"]
action.escu.eli5 = Adversaries will often seek to create new user accounts as a means of maintaining access to a target environment. Using this search, we identify accounts created in the last week by comparing the start date in the Identity_Management data model against the current time.
action.escu.how_to_implement = To successfully implement this search, you need to be populating the Enterprise Security Identity_Management data model in the assets and identity framework.
action.escu.known_false_positives = If the Identity_Management data model is not updated regularly, this search could give you false positive alerts. Please consider this and investigate appropriately.
action.escu.creation_date = 2017-08-05
action.escu.modification_date = 2017-09-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Identify New User Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Domain Server
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["Active Directory"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Identify New User Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = Using the identities lookup and macro from Enterprise Security to identify (report) new users (6 month period) and temp users (3 months until account expiration)
action.notable.param.rule_title = Identify Temporary Users
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = identity
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | from datamodel Identity_Management.All_Identities  | eval empStatus=case((now()-startDate)<604800, "Accounts created in last week") | search empStatus="Accounts created in last week"| `security_content_ctime(endDate)` | `security_content_ctime(startDate)`| table identity empStatus endDate startDate

[ESCU - Large Volume of DNS ANY Queries - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
action.escu.mappings = {"cis20": ["CIS 11", "CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.PT", "DE.AE", "PR.IP"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search counts the number of DNS ANY queries received in 5 minutes, and generates a Notable Event if the count exceeds a predefined threshold. The search returns the count, the first time, and the last time a DNS packet was observed with the ANY flag set.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = Legitimate ANY requests may trigger this search, however it is unusual to see a large volume of them under typical circumstances. You may modify the threshold in the search to better suit your environment.
action.escu.creation_date = 2016-08-24
action.escu.modification_date = 2017-09-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Large Volume of DNS ANY Queries - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = DNS Servers
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["DNS Amplification Attacks"]
cron_schedule = */5 * * * *
dispatch.earliest_time = -15m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Large Volume of DNS ANY Queries
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
action.notable.param.rule_title = Large Volume of DNS ANY Queries
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 7200s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution where nodename=DNS "DNS.message_type"="QUERY" "DNS.record_type"="ANY" by "DNS.dest" | `drop_dm_object_name("DNS")` | where count>200

[ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with parameters to modify the execution policy of the run, run in a hidden window, and connect to the Internet. This combination of command-line options is suspicious because it's overriding the default PowerShell execution policy, attempts to hide its activity from the user, and connects to the Internet.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution", "PowerShell", "Scripting"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes running with specific command-line arguments that indicate that the process will download a file from the Internet without display anything to the user. The search for "*-Exec*" is to check and see if the default execution policy for PowerShell is being overridden on the command-line. The search for "*-WindowStyle*" and "*hidden*" are to see if the window that would normally be displayed will be hidden from the user instead. Finally, the search for "*New-Object*" and "*System.Net.WebClient*" are there to check to see if a PowerShell object that can be used to download files will be created. This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Connect To Internet With Hidden Window
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell process that connects to the Internet with a hidden window.
action.notable.param.rule_title = Malicious PowerShell Process detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process_name, dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process="*-Exec*" process="*-WindowStyle*" process="*hidden*" process="*New-Object*" process="*System.Net.WebClient*"

[ESCU - Malicious PowerShell Process - Encoded Command - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes that have encoded the script within the command-line. Malware has been seen using this parameter, as it obfuscates the code and makes it relatively easy to pass a script on the command-line.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution", "PowerShell", "Scripting"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that are passing encoded commands on the command-line. The flags "-EncodedCommand" and "-enc" are two different possible flags that can be used to pass base64 encoded commands to PowerShell.  This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = System administrators may use this option, but it's not common.
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Encoded Command - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Encoded Command
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell process that has an encoded command on the command-line
action.notable.param.rule_title = PowerShell process with an encoded command detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, process_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process=*-EncodedCommand* OR  process=*-enc*

[ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with parameters used to bypass the local execution policy for scripts. These parameters are often observed in attacks leveraging PowerShell scripts as they override the default PowerShell execution policy.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution", "PowerShell", "Scripting"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that were launched using a parameter designed to bypass the local PowerShell execution policy. By default, the policy is set to "Restricted," which disables the execution of PowerShell scripts. In environments that make heavy use of PowerShell, the policy can be set to allow only scripts signed by a trusted publisher. Malicious PowerShell use almost always includes the parameter `-ExecutionPolicy bypass`. PowerShell is very liberal when it comes to interpreting command-line parameters passed to it. For example, the parameter we look for, `-ExecutionPolicy`, can be abbreviated to `-Execution`, `-Exec`, or even `-ex`. As such, we look for `* -ex*`, which should catch all variations of this parameter, followed by the keyword `bypass`. This search will return the host, the user the process ran under, the process and its command-line arguments, the number of times it has seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = There may be legitimate reasons to bypass the PowerShell execution policy. The PowerShell script being run with this parameter should be validated to ensure that it is legitimate.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "process_id", "process", "parent_process_id"]
action.escu.entities = ["dest", "process_id", "process", "parent_process_id"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 50 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Execution Policy Bypass
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell process with parameters to bypass the local execution policy.
action.notable.param.rule_title = PowerShell process with -executionpolicy bypass detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.drilldown_name = View powershell process information on $dest$
action.notable.param.drilldown_search = | from datamodel:Endpoint.Processes | search dest="$dest$" process_id=$process_id$
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process_id) as process_id, values(Processes.parent_process_id) as parent_process_id values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe AND (Processes.process="* -ex*" OR Processes.process="* bypass *") by Processes.process_id, Processes.user, Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with a base64 encoded command-line passed to it, with parameters to modify the execution policy for the process, and those that prevent the display of an interactive prompt to the user. This combination of command-line options is suspicious because it overrides the default PowerShell execution policy, attempts to hide itself from the user, and passes an encoded script to be run on the command-line.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution", "PowerShell", "Scripting"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that have a number of suspicious flags on the command-line. It is looking for flags are passing encoded commands on the command-line. The flags `-EncodedCommand` and `-enc` are two different possible flags that can be used to pass base64 encoded commands to PowerShell. The `*-Exec*` flag looks to see it the default execution policy of PowerShell is being overridden, while the `*-NonI*` flag tells the PowerShell process that this will be a noninteractive process, so the user doesn't know about the process. This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 50 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments
action.notable = 1
action.notable.param.nes_fields = dest, user, process, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell that had an encoded command on the command-line, attempted to bypass local execution policy, and prevented the display of an interactive prompt to the user.
action.notable.param.rule_title = PowerShell process with multiple suspicious command-line arguments detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search (process=*-EncodedCommand* OR process=*-enc*) process=*-Exec* AND process=*-NonI*

[ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes launched with arguments that have characters indicative of obfuscation on the command-line.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 8"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution", "PowerShell", "Scripting"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that are passing command-line arguments with unusual characters (backticks and carets) that are PowerShell specific escape characters. Attackers use this obfuscation technique since it does not affect the functionality of PowerShell and it will bypass standard security controls that look for straight up malicious strings and commands. The search counts the occurrence of these obfuscation characters and lists out destination IPs running these PowerShell commands.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = These characters might be legitimately on the command-line, but it is not common.
action.escu.creation_date = 2017-04-25
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process With Obfuscation Techniques
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name, process
action.notable.param.rule_description = The system $dest$ executed a PowerShell process that has evidence of obfuscation on the command-line
action.notable.param.rule_title = PowerShell process with an obfuscation techniques detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process_name,process
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| eval num_obfuscation = (mvcount(split(process, "`"))-1) + (mvcount(split(process, "^"))-1) | search num_obfuscation > 0

[ESCU - Monitor DNS For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DNS requests for faux domains similar to the domains that you want to have monitored for abuse.
action.escu.mappings = {"kill_chain_phases": ["Delivery", "Actions on Objectives"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search gathers all the answers to each system's DNS query, then filters out all queries that do not appear on the list of faux "look-a-like" domains that have been generated from the brand abuse domains you are monitoring.
action.escu.how_to_implement = You need to ingest data from your DNS logs. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor DNS For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Brand Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor DNS For Brand Abuse
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = The host $src$ issued a DNS request for a domain to that which you are monitoring for brand abuse.
action.notable.param.rule_title = DNS Query Brand Abuse from $src$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src,query
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(DNS.answer) as IPs min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `security_content_ctime(firstTime)`| `brand_abuse_dns`

[ESCU - Monitor Email For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for emails claiming to be sent from a domain similar to one that you want to have monitored for abuse.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "nist": ["PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks at the sender address in email headers, and identifies those with a sender address using a domain name that matches the list of permutations generated for the domain you want to monitor.
action.escu.how_to_implement = You need to ingest email header data. Specifically the sender's address (src_user) must be populated.  You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2018-01-05
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor Email For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_user"]
action.escu.entities = ["src_user"]
action.escu.providing_technologies = ["Microsoft Exchange", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor Email For Brand Abuse
action.notable = 1
action.notable.param.nes_fields = src_user, message_id
action.notable.param.rule_description = The sender $src_user$ has sent an email from a similar domain to that which you are monitoring for brand abuse.
action.notable.param.rule_title = Possible Brand Abuse from $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = message_id, src_user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(All_Email.recipient) as recipients, min(_time) as firstTime, max(_time) as lastTime from datamodel=Email by All_Email.src_user, All_Email.message_id | `drop_dm_object_name("All_Email")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | eval temp=split(src_user, "@") | eval email_domain=mvindex(temp, 1) | lookup update=true brandMonitoring_lookup domain as email_domain OUTPUT domain_abuse | search domain_abuse=true | table message_id, src_user, email_domain, recipients, firstTime, lastTime

[ESCU - Monitor Registry Keys for Print Monitors - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for registry activity associated with modifications to the registry key `HKLM\SYSTEM\CurrentControlSet\Control\Print\Monitors`. In this scenario, an attacker can load an arbitrary .dll into the print-monitor registry by giving the full path name to the after.dll. The system will execute the .dll with elevated (SYSTEM) permissions and will persist after reboot.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Privilege Escalation", "Local Port Monitor"], "nist": ["PR.PT", "DE.CM", "PR.AC"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we look for modifications to registry keys used for adding print-monitor entries on Microsoft platforms via the `registry_path` field in the endpoint data model. It then provides the destination, command used to initiate the change, the user who conducted this activity, the resource affected (registry_key_name), and the entire path of the registry.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.
action.escu.known_false_positives = You will encounter noise from legitimate print-monitor registry entries.
action.escu.creation_date = 2017-12-01
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Monitor Registry Keys for Print Monitors - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor Registry Keys for Print Monitors
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = A registry key associated with adding print monitors can potentially be misused by giving it a path of a malicious .dll in the registry.
action.notable.param.rule_title = Registry Key changes for Print Monitors detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, registry_path
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.action=modified AND Registry.registry_path="*CurrentControlSet\\Control\\Print\\Monitors*" by Registry.dest, Registry.registry_key_name Registry.status Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)`

[ESCU - Monitor Web Traffic For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Web requests to faux domains similar to the one that you want to have monitored for abuse.
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "mitre_attack": [], "nist": ["PR.IP"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks at all the URLs an endpoint is connecting to and then checks the URL against a list of faux domains that could be indicative of brand abuse.
action.escu.how_to_implement = You need to ingest data from your web traffic. This can be accomplished by indexing data from a web proxy, or using a network traffic analysis tool, such as Bro or Splunk Stream. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor Web Traffic For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.analytic_story = ["Brand Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor Web Traffic For Brand Abuse
action.notable = 1
action.notable.param.nes_fields = src, url
action.notable.param.rule_description = The host $src$ connected to a web site with a domain similar to that which you are monitoring for brand abuse.
action.notable.param.rule_title = Web URL Brand Abuse from $src$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Web.url) as urls min(_time) as firstTime from datamodel=Web by Web.src | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `brand_abuse_web`

[ESCU - No Windows Updates in a time frame - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Windows endpoints that have not generated an event indicating a successful Windows update in the last 60 days. Windows updates are typically released monthly and applied shortly thereafter. An endpoint that has not successfully applied an update in this time frame indicates the endpoint is not regularly being patched for some reason.
action.escu.mappings = {"cis20": ["CIS 18"], "nist": ["PR.PT", "PR.MA"]}
action.escu.data_models = ["Updates"]
action.escu.eli5 = Keeping your systems up-to-date with the latest patches is an important step in keeping your systems secured. For Windows endpoints, Microsoft typically releases patches on the second Tuesday of every month. These patches contain fixes for vulnerabilities in the system that could potentially be exploited by malicious actors. This search checks for messages regarding Windows updates in the 'Update' data model. If a message indicating a successful update has not been observed in 60 days, a notable event will be generated. These systems should be checked to determine why it has not been updated in that time frame.
action.escu.how_to_implement = To successfully implement this search, it requires that the 'Update' data model is being populated. This can be accomplished by ingesting Windows events or the Windows Update log via a universal forwarder on the Windows endpoints you wish to monitor. The Windows add-on should be also be installed and configured to properly parse Windows events in Splunk. There may be other data sources which can populate this data model, including vulnerability management systems.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-08-15
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - No Windows Updates in a time frame - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Monitor for Updates"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = No Windows Updates in a time frame
action.notable = 1
action.notable.param.nes_fields = src, user
action.notable.param.rule_description = The system $src$ has not generated a successful Windows Update event in 60 days or more.
action.notable.param.rule_title = No Windows updates in last 60 days on $src$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` max(_time) as lastTime from datamodel=Updates where Updates.status=Installed Updates.vendor_product="Microsoft Windows" by Updates.dest Updates.status Updates.vendor_product | rename Updates.dest as Host | rename Updates.status as "Update Status" | rename Updates.vendor_product as Product | eval isOutlier=if(lastTime <= relative_time(now(), "-60d@d"), 1, 0)  | `security_content_ctime(lastTime)`  | search isOutlier=1 | rename lastTime as "Last Update Time", | table Host, "Update Status", Product, "Last Update Time"

[ESCU - Open Redirect in Splunk Web - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to look for evidence of exploitation for CVE-2016-4859, the Splunk Open Redirect Vulnerability.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 4", "CIS 18"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.AC", "PR.IP", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks within Splunk's internal logs for evidence of CVE-2016-4859 open redirect exploitation attempts.
action.escu.how_to_implement = No extra steps needed to implement this search.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-19
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Open Redirect in Splunk Web - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Splunk Server
action.escu.fields_required = ["host"]
action.escu.entities = ["host"]
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.analytic_story = ["Splunk Enterprise Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Open Redirect in Splunk Web
action.notable = 1
action.notable.param.nes_fields = host
action.notable.param.rule_description = Search for exploitation of the Splunk Open Redirect Vulnerability
action.notable.param.rule_title = Open Redirect in Splunk Web
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = host
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = index=_internal sourcetype=splunk_web_access return_to="/%09/*"

[ESCU - Osquery pack - ColdRoot detection - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for ColdRoot events from the osx-attacks osquery pack.
action.escu.mappings = {"cis20": ["CIS 4", "CIS 8"], "kill_chain_phases": ["Installation", "Command and Control"], "mitre_attack": ["Execution", "Persistence", "Command and Control"], "nist": ["DE.DP", "DE.CM", "PR.PT"]}
action.escu.data_models = ["Alerts"]
action.escu.eli5 = The search looks at the Alerts data model to identify those  generated from the osquery osx-attacks.conf pack, which search for the ColdRoot RAT.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model
action.escu.known_false_positives = There are no known false positives.
action.escu.creation_date = 2019-01-29
action.escu.modification_date = 2019-01-29
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Osquery pack - ColdRoot detection - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["host"]
action.escu.entities = ["host"]
action.escu.providing_technologies = ["OSquery"]
action.escu.analytic_story = ["ColdRoot MacOS RAT"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Osquery pack - ColdRoot detection
action.notable = 1
action.notable.param.nes_fields = host, user
action.notable.param.rule_description = Host $host$ generated an alert for the macOS RAT ColdRoot
action.notable.param.rule_title = Osquery ColdRoot alert for $host$
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = host
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | from datamodel Alerts.Alerts | search app=osquery:results (name=pack_osx-attacks_OSX_ColdRoot_RAT_Launchd OR name=pack_osx-attacks_OSX_ColdRoot_RAT_Files) | rename columns.path as path | bucket _time span=30s | stats count(path) by _time, host, user, path

[ESCU - Overwriting Accessibility Binaries - Rule]
action.escu = 0
action.escu.enabled = 1
description = Microsoft Windows contains accessibility features that can be launched with a key combination before a user has logged in. An adversary can modify or replace these programs so they can get a command prompt or backdoor without logging in to the system. This search looks for modifications to these binaries.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Accessibility Features"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns all the different accessibility binaries that have been modified for each Windows host.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Microsoft may provide updates to these binaries. Verify that these changes do not correspond with your normal software update cycle.
action.escu.creation_date = 2017-12-07
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Overwriting Accessibility Binaries - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Overwriting Accessibility Binaries
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file, $file_name$, was created in the default shim database directory on $dest.
action.notable.param.rule_title = Modification to accessibility binary, $file_path$, was detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem where (Filesystem.file_path=*\Windows\System32\sethc.exe* OR Filesystem.file_path=*\Windows\System32\utilman.exe* OR Filesystem.file_path=*\Windows\System32\osk.exe* OR Filesystem.file_path=*\Windows\System32\Magnify.exe* OR Filesystem.file_path=*\Windows\System32\Narrator.exe* OR Filesystem.file_path=*\Windows\System32\DisplaySwitch.exe* OR Filesystem.file_path=*\Windows\System32\AtBroker.exe*) by Filesystem.file_name Filesystem.dest | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`

[ESCU - Process Execution via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched via WMI.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Windows Management Instrumentation"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for processes launched via WMI, either remotely or locally, by looking for processes launched by WmiPrvSE.exe, which is the process WMI uses to execute new processes and commands.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Although unlikely, administrators may use wmi to execute commands for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Process Execution via WMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Process Execution via WMI
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for child processes of WmiPrvSE.exe, which indicates that a process was launched via WMI.
action.notable.param.rule_title = Process launched via WMI on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.parent_process_name = *WmiPrvSE.exe by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Processes Tapping Keyboard Events - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes in an MacOS system that is tapping keyboard events in MacOS, and essentially monitoring all keystrokes made by a user. This is a common technique used by RATs to log keystrokes from a victim, although it can also be used by legitimate processes like Siri to react on human input
action.escu.mappings = {"cis20": ["CIS 4", "CIS 8"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Collection"], "nist": ["DE.DP"]}
action.escu.data_models = ["Alerts"]
action.escu.eli5 = The search leverages Alerts generated from the osquery osx-attacks.conf pack search `Keyboard_Event_Taps` to detect when a process is monitoring the keystrokes of a machine, This is a common technique used by macOS remote access trojans to log keystrokes from a machine
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model.
action.escu.known_false_positives = There might be some false positives as keyboard event taps are used by processes like Siri and Zoom video chat, for some good examples of processes to exclude please see [this](https://github.com/facebook/osquery/pull/5345#issuecomment-454639161) comment.
action.escu.creation_date = 2019-01-25
action.escu.modification_date = 2019-01-25
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Processes Tapping Keyboard Events - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["host"]
action.escu.entities = ["host"]
action.escu.providing_technologies = ["OSquery"]
action.escu.analytic_story = ["ColdRoot MacOS RAT"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Processes Tapping Keyboard Events
action.notable = 1
action.notable.param.nes_fields = host, cmd, process_id
action.notable.param.rule_description = Host $host$ has process $process_id$ tapping keyboard events with command $cmd$
action.notable.param.rule_title = Host $host has process $process_id$ monitoring its keystrokes
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = host
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | from datamodel Alerts.Alerts | search app=osquery:results name=pack_osx-attacks_Keyboard_Event_Taps | rename columns.cmdline as cmd, columns.name as process_name, columns.pid as process_id| dedup host,process_name | table host,process_name, cmd, process_id

[ESCU - Processes created by netsh - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launching netsh.exe to execute various commands via the netsh command-line utility. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper .dll when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe that are executing commands via the command line.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for all processes with the parent process "c:\Windows\System32\
etsh.exe" and returns the process, the command line used to execute it, the host name, and the user context under which it ran.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting logs with the process name, command-line arguments, and parent processes from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = It is unusual for netsh.exe to have any child processes in most environments. It makes sense to investigate the child process and verify whether the process spawned is legitimate.
action.escu.creation_date = 2018-01-04
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Processes created by netsh - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Netsh Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Processes created by netsh
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process
action.notable.param.rule_description = A process, $process$, is spawned by netsh.exe. It is highly unlikely for netsh to have any child processes.
action.notable.param.rule_title = Process spawned by netsh.exe detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process="C:\Windows\System32\
etsh.exe" by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`

[ESCU - Processes launching netsh - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launching netsh.exe. Netsh is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via the command line.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Command-Line Interface", "Persistence", "Defense Evasion", "Disabling Security Tools"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for all the parent processes of netsh.exe and returns that process, the command-line used to execute it, the host name, and the user context under which it ran.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model
action.escu.known_false_positives = Some VPN applications are known to launch netsh.exe. Outside of these instances, it is unusual for an executable to launch netsh.exe and run commands.
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Processes launching netsh - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Netsh Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Processes launching netsh
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process, cmdline
action.notable.param.rule_description = A process detected on $dest$ is launching netsh.exe. 
action.notable.param.rule_title = Process launching netsh.exe detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process=netsh.exe by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`

[ESCU - Prohibited Network Traffic Allowed - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic defined by port and transport layer protocol in the Enterprise Security lookup table "lookup_interesting_ports", that is marked as prohibited, and has an associated 'allow' action in the Network_Traffic data model. This could be indicative of a misconfigured network device.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Delivery", "Command and Control"], "mitre_attack": ["Command and Control", "Commonly Used Port", "Exfiltration", "Exfiltration Over Alternative Protocol"], "nist": ["DE.AE", "PR.AC"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = The search looks for traffic marked 'is_prohibited' in the Enterprise Security lookup table 'interesting_ports_lookup', and then determines if any network devices have an associated 'allow' action on that traffic by checking the Network_Traffic data model.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2017-09-11
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Prohibited Network Traffic Allowed - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Command and Control", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Prohibited Network Traffic Allowed
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = This search looks for network traffic defined by port and transport in the ES lookup table "lookup_interesting_ports", that is marked as prohibited, and yet has an 'allow' action in the Network_Traffic data model. This should help to identify areas where a network device is not properly configured.
action.notable.param.rule_title = Prohibited Network Traffic Allowed from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip,src_ip
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.action = allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | lookup update=true interesting_ports_lookup dest_port as All_Traffic.dest_port OUTPUT app is_prohibited note transport | search is_prohibited=true | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Prohibited Software On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for applications on the endpoint that you have marked as prohibited.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns the number of times, as well as the first and last time, every process has run for each endpoint and user. It then displays only those processes that you have marked as "prohibited" in the Enterprise Security "Interesting Processes" table.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report process tracking in your Windows audit settings. In addition, you must also have only the `process_name` (not the entire process path) marked as "prohibited" in the Enterprise Security `interesting processes` table. To include the process names marked as "prohibited", which is included with ES Content Updates, run the included search <code>Add Prohibited Processes to Enterprise Security</code>.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-26
action.escu.modification_date = 2019-10-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - Prohibited Software On Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)", "Monitor for Unauthorized Software", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Prohibited Software On Endpoint
action.notable = 1
action.notable.param.nes_fields = dest, process_name, user
action.notable.param.rule_description = Prohibited software $process_name$ has been detected on $dest$.
action.notable.param.rule_title = Prohibited Software Detected On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `prohibited_softwares`

[ESCU - Protocol or Port Mismatch - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic on common ports where a higher layer protocol does not match the port that is being used. For example, this search should identify cases where protocols other than HTTP are running on TCP port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications over ports and protocols that are typically allowed and not well inspected.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Commonly Used Port"], "nist": ["DE.AE", "PR.AC"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for instances in which the protocol observed is not consistent with the port and transport protocol typically used for that protocol. For example, looking for network traffic other than HTTP running over TCP port 80. Such behavior could indicate a misconfiguration or a custom command and control protocol that has been designed to look like ordinary web traffic. The search will also identify if HTTP traffic is observed running on unexpected ports. This can be common in many environments.
action.escu.how_to_implement = Running this search properly requires a technology that can inspect network traffic and identify common protocols. Technologies such as Bro and Palo Alto Networks firewalls are two examples that will identify protocols via inspection, and not just assume a specific protocol based on the transport protocol and ports.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2017-09-11
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Protocol or Port Mismatch - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Command and Control", "Prohibited Traffic Allowed or Protocol Mismatch"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Protocol or Port Mismatch
action.notable = 1
action.notable.param.nes_fields = dest_ip, src_ip
action.notable.param.rule_description = This search looks for network traffic on common ports where the underlying protocol does not match the port being used. For example, this search should identify cases where protocols other than HTTP are running on port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications in traffic that is typically allowed and not well inspected.
action.notable.param.rule_title = Protocol / Port Mismatch from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip, dest_port
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where (All_Traffic.app=dns NOT All_Traffic.dest_port=53) OR ((All_Traffic.app=web-browsing OR All_Traffic.app=http) NOT (All_Traffic.dest_port=80 OR All_Traffic.dest_port=8080 OR All_Traffic.dest_port=8000)) OR (All_Traffic.app=ssl NOT (All_Traffic.dest_port=443 OR All_Traffic.dest_port=8443)) OR (All_Traffic.app=smtp NOT All_Traffic.dest_port=25) by All_Traffic.src_ip, All_Traffic.dest_ip, All_Traffic.app, All_Traffic.dest_port |`security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Protocols passing authentication in cleartext - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cleartext protocols at risk of leaking credentials. Currently, this consists of legacy protocols such as telnet, POP3, IMAP, and non-anonymous FTP sessions. While some of these protocols can be used over SSL, they typically run on different assigned ports in those cases.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 14"], "kill_chain_phases": ["Reconnaissance", "Actions on Objectives"], "mitre_attack": ["Credential Access", "Lateral Movement", "Collection"], "nist": ["PR.PT", "DE.AE", "PR.AC", "PR.DS"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search is checking for traffic on well-known ports that are associated with protocols that pass authentication in cleartext.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic, and populating the Network_Traffic data model.
action.escu.known_false_positives = Some networks may use kerberized FTP or telnet servers, however, this is rare.
action.escu.creation_date = 2017-08-03
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Protocols passing authentication in cleartext - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Use of Cleartext Protocols"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Protocols passing authentication in cleartext
action.notable = 1
action.notable.param.nes_fields = src, dest, user
action.notable.param.rule_description = This search looks for the use of cleartext protocols that are known to pass authentication information in the clear. The cleartext credentials are typically passed at the beginning of the session.
action.notable.param.rule_title = Possible credential leak over cleartext protocol
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.protocol="tcp" AND (All_Traffic.dest_port="23" OR All_Traffic.dest_port="143" OR All_Traffic.dest_port="110" OR (All_Traffic.dest_port="21" AND All_Traffic.user != "anonymous")) groupby All_Traffic.user All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Reg.exe Manipulating Windows Services Registry Keys - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for reg.exe modifying registry keys that define Windows services and their configurations.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation"], "mitre_attack": ["Persistence", "Privilege Escalation", "New Service", "Modify Existing Service", "Defense Evasion", "Disabling Security Tools"], "nist": ["PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for modifications to registry paths that specify the definition and configuration of Windows services by reg.exe. Reg.exe is a Windows utility that allows for manipulation of the registry via the command line. Malware often uses the Windows services architecture to persist, hide in plain sight, and gain the ability to interact with the Windows kernel. While it is common to modify the configuration of Windows services (and new services may be created with software installs), the use of reg.exe to create or modify a service configuration is unusual and a technique commonly used by attackers. The search returns the count, the first time the activity was seen, the last time activity was seen, the registry path that was modified, the host where the modification took place, and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.
action.escu.known_false_positives = It is unusual for a service to be created or modified by directly manipulating the registry. However, there may be legitimate instances of this behavior. It is important to validate and investigate, as appropriate.
action.escu.creation_date = 2018-6-29
action.escu.modification_date = 2019-03-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Reg.exe Manipulating Windows Services Registry Keys - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques", "Windows Service Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Reg.exe Manipulating Windows Services Registry Keys
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = A registry key associated with Windows services was modified via reg.exe on $dest$ by $src_user$.
action.notable.param.rule_title = Modification of Windows Services Via Reg.exe on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name = reg.exe by Processes.process_id Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | join [| tstats `security_content_summariesonly` values(Registry.registry_path) as registry_path count  FROM datamodel=Endpoint.Registry where Registry.registry_path="*\\services\\*" by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | table process_id dest registry_path]

[ESCU - Reg.exe used to hide files/directories via registry keys - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for command-line arguments used to hide a file or directory using the reg add command.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Persistence"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Reg.exe is a binary native to Windows platform used to edit the registry hives of the system. Attackers can leverage this binary to hide files by passing in arguments that are used to hide the files. In the search, we first gather results with keywords, add, Hidden, and REG_DWORD, that will be in the raw event and filter by process and the command-line. We then leverage regular expressions on the command-line field to look for /d value as 2 which is responsible for hiding a file or directory.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None at the moment
action.escu.creation_date = 2017-10-27
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Reg.exe used to hide files/directories via registry keys - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Reg.exe used to hide files/directories via registry keys
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = Regedit.exe is used by attackers to hide malware files/directories in windows environments via registry key settings. This rule detects command-line arguments used to hide a file/directory
action.notable.param.rule_title = Regedit.exe used to hide a file/directory on $dest$ 
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = reg.exe Processes.process="*add*" Processes.process="*Hidden*" Processes.process="*REG_DWORD*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)`| regex process = "(/d\s+2)"

[ESCU - Registry Keys Used For Persistence - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to registry keys that can be used to launch an application or service at system startup.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Registry Run Keys / Start Folder", "AppInit DLLs", "Authentication Package"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for specific registry paths that malware often uses to ensure survivability and persistence on system startup. The search returns the count, the first time the activity was seen, the last time the activity was seen, the registry path that was modified, the host where the modification took place and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that must execute on system startup and will use these registry keys to accomplish that task.
action.escu.creation_date = 2017-08-23
action.escu.modification_date = 2017-10-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Registry Keys Used For Persistence - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (DHS Report TA18-201A)", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Registry Keys Used For Persistence
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = A registry key that is used for persistence on Windows was modified on $dest$ by $src_user$.
action.notable.param.rule_title = Registry Key Associated With Persistence Modified on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,registry_path
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path=*currentversion\\run* OR Registry.registry_path=*currentVersion\\Windows\\Appinit_Dlls* OR Registry.registry_path=CurrentVersion\\Winlogon\\Shell* OR Registry.registry_path=*CurrentVersion\\Winlogon\\Userinit* OR Registry.registry_path=*CurrentVersion\\Winlogon\\VmApplet* OR Registry.registry_path=*currentversion\\policies\\explorer\\run* OR Registry.registry_path=*currentversion\\runservices* OR Registry.registry_path=*\\CurrentControlSet\\Control\\Lsa\\* OR Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*" OR Registry.registry_path=HKLM\\SOFTWARE\\Microsoft\\Netsh\\*) by Registry.dest , Registry.status, Registry.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)`

[ESCU - Registry Keys Used For Privilege Escalation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for modifications to registry keys that can be used to elevate privileges. The registry keys under "Image File Execution Options" are used to intercept calls to an executable and can be used to attach malicious binaries to benign system binaries.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Privilege Escalation", "Persistence", "Accessibility Features"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for specific registry paths that malware often uses to elevate privileges. The search returns the count, the first time the activity was seen, the last time the activity was seen, the registry path that was modified, the host where the modification took place, and the user who performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that must execute upon system startup and will use these registry keys to accomplish that task.
action.escu.creation_date = 2017-12-07
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Registry Keys Used For Privilege Escalation - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Registry Keys Used For Privilege Escalation
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = A registry key used for privilege escalation was modified on $dest$ by $user$.
action.notable.param.rule_title = Registry Key Associated With Privilege Escalation Modified on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, registry_path
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*") by Registry.dest , Registry.status, Registry.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)`

[ESCU - Registry Keys for Creating SHIM Databases - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for registry activity associated with application compatibility shims, which can be leveraged by attackers for various nefarious purposes.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Application Shimming"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Change_Analysis"]
action.escu.eli5 = In this search, we look for modifications to registry keys used for shim databases on Microsoft platforms via the object_category and object_path field in the Change_Analysis data model and give you the destination, command used to initiate the change, the user who conducted this activity, the resource affected(object), and the whole path of the object. An application compatibility shim is a small library that transparently intercepts an API (via hooking), changes the parameters passed, handles the operation itself, or redirects the operation elsewhere, such as additional code stored on a system. This capability can be also leveraged by attackers to create and store malicious files in a shim database as observed in CARBANAK backdoor.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that leverage shim databases for compatibility purposes for legacy applications
action.escu.creation_date = 2017-08-27
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Registry Keys for Creating SHIM Databases - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Registry Keys for Creating SHIM Databases
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = A registry key that is used for persistence on Windows was modified on $dest$ by $user$
action.notable.param.rule_title = Registry Key Associated With SHIM databases on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,object_path
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\Custom*" OR All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\InstalledSDB*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `drop_dm_object_name("All_Changes")`

[ESCU - Remote Desktop Network Bruteforce - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for RDP application network traffic and filters any source/destination pair generating more than twice the standard deviation of the average traffic.
action.escu.mappings = {"cis20": ["CIS 12", "CIS 9", "CIS 16"], "kill_chain_phases": ["Reconnaissance", "Delivery"], "mitre_attack": ["Credential Access", "Remote Desktop Protocol", "Lateral Movement"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search monitors for abnormal amounts of remote-desktop (RDP) traffic from a source to a destination that may be indicative of a brute-force attack. It does this by filtering out RDP traffic from the Network_Traffic.All_Traffic data model, using twice the standard deviation of all source-to-destination connections. If any tuple is within more than two standard deviations of all other usual RDP traffic flows, it is indicative of a brute-force attack.
action.escu.how_to_implement = You must ensure that your network traffic data is populating the Network_Traffic data model.
action.escu.known_false_positives = RDP gateways may have unusually high amounts of traffic from all other hosts' RDP applications in the network.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Desktop Network Bruteforce - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Desktop Network Bruteforce
action.notable = 1
action.notable.param.nes_fields = dest, src
action.notable.param.rule_description = Remote-desktop traffic detected from $src$ to $dest$. This activity is consistent with a brute-force attack.
action.notable.param.rule_title = Bruteforce Remote Desktop Network Traffic detected from $src$ to $dest$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=rdp by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | eventstats stdev(count) AS stdev avg(count) AS avg p50(count) AS p50 | where count>(avg + stdev*2) | rename All_Traffic.src AS src All_Traffic.dest AS dest | table firstTime lastTime src dest count avg p50 stdev

[ESCU - Remote Desktop Network Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic on TCP/3389, the default port used by remote desktop. While remote desktop traffic is not uncommon on a network, it is usually associated with known hosts. This search allows for whitelisting both source and destination hosts to remove them from the output of the search so you can focus on the uncommon uses of remote desktop on your network.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 9", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Lateral Movement", "Remote Desktop Protocol", "Commonly Used Port"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search finds systems that do not commonly communicate use remote desktop.  It does this by filtering out all systems that have the "common_rdp_source" or "common_rdp_destination" category applied to that system.  Categories are applied to systems using the Assets and Identity framework.
action.escu.how_to_implement = To successfully implement this search you need to identify systems that commonly originate remote desktop traffic and that commonly receive remote desktop traffic. You can use the included support search "Identify Systems Creating Remote Desktop Traffic" to identify systems that originate the traffic and the search "Identify Systems Receiving Remote Desktop Traffic" to identify systems that receive a lot of remote desktop traffic. After identifying these systems, you will need to add the "common_rdp_source" or "common_rdp_destination" category to that system depending on the usage, using the Enterprise Security Assets and Identities framework.  This can be done by adding an entry in the assets.csv file located in SA-IdentityManagement/lookups.
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Desktop Network Traffic - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Desktop Network Traffic
action.notable = 1
action.notable.param.nes_fields = dest, src
action.notable.param.rule_description = Remote Desktop Traffic detected between $src$ and $dest$.  These two systems typically do not communicate with RDP
action.notable.param.rule_title = Uncommon Remote Desktop Network Traffic between $src$ and $dest$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.dest_port=3389 AND All_Traffic.dest_category!=common_rdp_destination AND All_Traffic.src_category!=common_rdp_source by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Remote Desktop Process Running On System - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the remote desktop process mstsc.exe running on systems upon which it doesn't typically run. This is accomplished by filtering out all systems that are noted in the `common_rdp_source category` in the Assets and Identity framework.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 9", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Lateral Movement", "Remote Desktop Protocol"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search finds systems that do not commonly use remote desktop, but which begin using it. It filters out all systems that have the "common_rdp_source" category applied. Categories are applied to systems using the Assets and Identity framework.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. The search requires you to identify systems that do not commonly use remote desktop. You can use the included support search "Identify Systems Using Remote Desktop" to identify these systems. After identifying them, you will need to add the "common_rdp_source" category to that system using the Enterprise Security Assets and Identities framework. This can be done by adding an entry in the assets.csv file located in `SA-IdentityManagement/lookups`.
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Desktop Process Running On System - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Desktop Process Running On System
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = The system $dest$ is running the remote desktop process, mstsc.exe. This system does not commonly run this application.
action.notable.param.rule_title = Remote Desktop Process Running On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process=mstsc.exe AND Processes.dest_category!=common_rdp_source by Processes.dest Processes.user Processes.process | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)`

[ESCU - Remote Process Instantiation via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Windows Management Instrumentation"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers are increasingly abusing native Windows utilities such as wmic.exe as a means to "live off the land", and avoid introducing new executables to the target system. In this search, we are looking for instances of wmic.exe being run with various parameters that are not typically used by administrators.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = The wmic.exe utility is a benign Windows application. It may be used legitimately by Administrators with these parameters for remote system administration, but it's relatively uncommon.
action.escu.creation_date = 2017-01-13
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Process Instantiation via WMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Process Instantiation via WMI
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
action.notable.param.rule_title = Remote process instantiation via WMI on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wmic.exe Processes.process="*/node*" Processes.process="*process*" Processes.process="*call*" Processes.process="*create*"   by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)`

[ESCU - Remote Registry Key modifications - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search monitors for remote modifications to registry keys.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Persistence", "Lateral Movement"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for modifications made to the Windows registry from remote locations using reg.exe&#151;a tool used to create/update/delete/modify Windows registry keys. It is accomplished through specifying the machine names in the registry path, by entering double backslashes, followed by a computer name. In this search, we look for registry changes where the registry path contains the name of a remote computer. The search returns the number of times the remote server has been accessed, the first and last times the activity occurred, the name of the modified registry path, the host on which the modification took place, and the name of the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must populate the `Endpoint` data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = This technique may be legitimately used by administrators to modify remote registries, so it's important to filter these events out.
action.escu.creation_date = 2018-05-31
action.escu.modification_date = 2018-05-31
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Registry Key modifications - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Lateral Movement", "Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Registry Key modifications
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = A registry key was modified remotely using the machine $dest$ by $user$.
action.notable.param.rule_title = Remote Registry Key Modification detection on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user,registry_path
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where  Registry.registry_path="\\\\*"  by Registry.dest , Registry.status, Registry.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)`

[ESCU - Remote WMI Command Attempt - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for wmic.exe being launched with parameters to operate on remote systems.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Windows Management Instrumentation"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Many a times, attackers leverage native Windows utilities that are designed to help administrators better manage their systems, infrastructure, and auditing, but are instead leveraged for malicious purposes. In this case, we are looking for instances of wmic.exe being run with various parameters that are not typically used by administrators.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators may use this legitimately to gather info from remote systems.
action.escu.creation_date = 2017-01-13
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote WMI Command Attempt - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 50 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote WMI Command Attempt
action.notable = 1
action.notable.param.nes_fields = dest,user,process_name
action.notable.param.rule_description = This search looks for wmic.exe being launched with parameters to operate on remote systems.
action.notable.param.rule_title = Endpoint - Remote WMI command attempt
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process_name
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=wmic.exe  AND Processes.process= */node* by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - RunDLL Loading DLL By Ordinal - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2. Calling exported functions by ordinal is not as common as calling by exported name. There was a bug fixed in IDAPro on 2016-08-08 that would not display functions without names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Installation"], "mitre_attack": ["Execution", "Rundll32"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for rundll32.exe being run, loading a DLL out of a directory or subdirectory of AppData, and specifying the function at ordinal 2 be run.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = While not common, loading a DLL under %AppData% and calling a function by ordinal is possible by a legitimate process
action.escu.creation_date = 2016-08-09
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - RunDLL Loading DLL By Ordinal - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = RunDLL Loading DLL By Ordinal
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2.  Calling exported functions by ordinal is not as common as calling by exported name.  There was a bug fixed in IDAPro on 2016-08-08 that would not display functions with no names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
action.notable.param.rule_title = Endpoint - Suspicious RunDLL usage
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = rundll32.exe Processes.process="*AppData*" Processes.process="*,#2" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - SMB Traffic Spike - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for spikes in the number of Server Message Block (SMB) traffic connections.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Lateral Movement", "Execution", "Command and Control", "Commonly Used Port"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = Server Message Block (SMB) traffic, a protocol used for Windows file sharing-activity, is often leveraged by attackers. One example of SMB abuse was the WannaCry ransomware, which leveraged a vulnerability in the SMB protocol to propagate to other systems. Attackers have also used SMB for lateral movement with a target environment and to test credentials against target systems. While SMB is highly prevalent in Windows environments, a spike in SMB traffic may still be indicative of this type of malicious activity. This search looks for a traffic spike in SMB traffic from a particular system. If such a spike is detected, you may want to investigate the source and analyze the cause of the abnormal traffic.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic logs and populating the `Network_Traffic` data model.
action.escu.known_false_positives = A file server may experience high-demand loads that could cause this analytic to trigger.
action.escu.creation_date = 2017-08-20
action.escu.modification_date = 2017-09-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - SMB Traffic Spike - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -7d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = SMB Traffic Spike
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = There was a spike in SMB traffic from $src$.
action.notable.param.rule_title = SMB Traffic Spike from $src$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | `drop_dm_object_name("All_Traffic")` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-70m@m"), count, null))) as count avg(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as stdev by src | eval upperBound=(avg+stdev*2), isOutlier=if(count > upperBound AND num_data_samples >=50, 1, 0) | where isOutlier=1 | table src count

[ESCU - SMB Traffic Spike - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search uses the Machine Learning Toolkit (MLTK) to identify spikes in the number of Server Message Block (SMB) connections.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Lateral Movement", "Execution", "Command and Control", "Commonly Used Port"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = Attackers often leverage Server Message Block (SMB) traffic, a protocol used for Windows file-sharing activity. A high-profile example of SMB abuse was the WannaCry ransomware, which leveraged a vulnerability in the SMB protocol to propagate to other systems. Attackers have also used SMB for lateral movement with a target environment and to test credentials against target systems. While SMB is highly prevalent in Windows environments, a spike in SMB traffic may still be indicative of this type of malicious activity. This search leverages Splunk's Machine Learning Toolkit (MLTK) to identify spikes in SMB traffic that are unusual for a given hour of day/day of week combination. If such a spike is detected, you may want to investigate the source and analyze the cause of the abnormal traffic. The determination of what is considered an outlier may be adjusted via the threshold parameter in the search. More information on the algorithm used can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, the Machine Learning Toolkit (MLTK) version 4.2 or greater must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of SMB Traffic - MLTK" must be executed before this detection search, because it builds a machine-learning (ML) model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.\
This search produces a field (Number of events,count) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. This field contributes additional context to the notable. To see the additional metadata, add the following field, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry): \
1. **Label:** Number of events, **Field:** count\
Detailed documentation on how to create a new field within Incident Review is found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`
action.escu.known_false_positives = If you are seeing more results than desired, you may consider reducing the value of the threshold in the search. You should also periodically re-run the support search to re-build the ML model on the latest data.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - SMB Traffic Spike - MLTK - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = SMB Traffic Spike - MLTK
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = There was a spike in SMB traffic from $src$
action.notable.param.rule_title = SMB Traffic Spike from $src$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(All_Traffic.dest_ip) as dest values(All_Traffic.dest_port) as port from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | eval HourOfDay=strftime(_time, "%H") | eval DayOfWeek=strftime(_time, "%A") | `drop_dm_object_name(All_Traffic)` | apply smb_pdfmodel threshold=0.001 | rename "IsOutlier(count)" as isOutlier | search isOutlier > 0 | sort -count | table _time src dest port count

[ESCU - SQL Injection with Long URLs - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for long URLs that have several SQL commands visible within them.
action.escu.mappings = {"cis20": ["CIS 4", "CIS 13", "CIS 18"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability", "Execution", "Commonly Used Port"], "nist": ["PR.DS", "ID.RA", "PR.PT", "PR.IP", "DE.CM"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks only at your web servers and returns the source, the web server, the URL and its length, and the user agent associated with HTTP GET requests for extremely long URLs or user agent lengths with more than three common SQL commands found within the URL.
action.escu.how_to_implement = To successfully implement this search, you need to be monitoring network communications to your web servers or ingesting your HTTP logs and populating the Web data model. You must also identify your web servers in the Enterprise Security assets table.
action.escu.known_false_positives = It's possible that legitimate traffic will have long URLs or long user agent strings and that common SQL commands may be found within the URL. Please investigate as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-19
action.escu.confidence = medium
action.escu.full_search_name = ESCU - SQL Injection with Long URLs - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Database Server
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["SQL Injection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = SQL Injection with Long URLs
action.notable = 1
action.notable.param.nes_fields = dest, src, url
action.notable.param.rule_description = Using the length of url or user agent to identify SQL injection
action.notable.param.rule_title = SQL Injection with Long URLs
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src,url
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Web where Web.dest_category=web_server AND (Web.url_length > 1024 OR Web.http_user_agent_length > 200) by Web.src Web.dest Web.url Web.url_length Web.http_user_agent | `drop_dm_object_name("Web")` | eval num_sql_cmds=mvcount(split(url, "alter%20table")) + mvcount(split(url, "between")) + mvcount(split(url, "create%20table")) + mvcount(split(url, "create%20database")) + mvcount(split(url, "create%20index")) + mvcount(split(url, "create%20view")) + mvcount(split(url, "delete")) + mvcount(split(url, "drop%20database")) + mvcount(split(url, "drop%20index")) + mvcount(split(url, "drop%20table")) + mvcount(split(url, "exists")) + mvcount(split(url, "exec")) + mvcount(split(url, "group%20by")) + mvcount(split(url, "having")) + mvcount(split(url, "insert%20into")) + mvcount(split(url, "inner%20join")) + mvcount(split(url, "left%20join")) + mvcount(split(url, "right%20join")) + mvcount(split(url, "full%20join")) + mvcount(split(url, "select")) + mvcount(split(url, "distinct")) + mvcount(split(url, "select%20top")) + mvcount(split(url, "union")) + mvcount(split(url, "xp_cmdshell")) - 24 | where num_sql_cmds > 3

[ESCU - Samsam Test File Write - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a file named "test.txt" written to the windows system directory tree, which is consistent with Samsam propagation.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Delivery"], "mitre_attack": [], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts and monitors for a file named "test.txt" written to "windows\system32". This file is copied to potential targets during SamSam ransomware attacks to test the attacker's ability to access remote systems. If the file is successfully copied to the system, the system is added to a list of targets on which to deploy ransomware.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = No false positives have been identified.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - Samsam Test File Write - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Samsam Test File Write
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file named "test.txt," which is indicative of a SamSam ransomware attack, was written to system32 on $dest$.
action.notable.param.rule_title = File consistent with SamSam probes detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name from datamodel=Endpoint.Filesystem where Filesystem.file_path=*\\windows\\system32\\test.txt by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`

[ESCU - Sc.exe Manipulating Windows Services - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 8"], "kill_chain_phases": ["Installation"], "mitre_attack": ["Persistence", "Privilege Escalation", "New Service", "Modify Existing Service", "Defense Evasion", "Disabling Security Tools"], "nist": ["PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of sc.exe with parameters that indicate the utility is being used to create a new Windows service, or modify an existing one. Attackers often create a new service to host their malicious code, or they may take a non-critical service or one that is disabled, and modify it to point to their malware and enable the service if necessary. It is unusual for a service to be created or modified using the sc.exe utility.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Using sc.exe to manipulate Windows services is uncommon. However, there may be legitimate instances of this behavior. It is important to validate and investigate as appropriate.
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Sc.exe Manipulating Windows Services - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Orangeworm Attack Group", "Windows Persistence Techniques", "Windows Service Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Sc.exe Manipulating Windows Services
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
action.notable.param.rule_title = Sc.exe Manipulating Windows Services on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sc.exe (Processes.process="* create *" OR Processes.process="* config *") by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a task name associated with the Dragonfly threat actor was created or deleted.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Scheduled Task"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate that a specific task "reset," whose name is associated with the Dragonfly threat actor--has been created or deleted. Schtasks.exe is a native Windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = No known false positives
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Scheduled Task Name Used by Dragonfly Threat Actors
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command line that indicate that a task--whose name is associated with the Dragonfly threat actor--has been created or deleted
action.notable.param.rule_title = Scheduled task used by Dragonfly threat actor detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name, process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search (process=*delete* OR process=*create*) process=*reset*

[ESCU - Scheduled tasks used in BadRabbit ransomware - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names related to the execution of Bad Rabbit ransomware were created or deleted.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Lateral Movement", "Execution", "Scheduled Task"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate that specific task names related to the Bad Rabbit ransomware were created or deleted. The specific task name used are rhaegal, drogon and viserion_. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = No known false positives
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Scheduled tasks used in BadRabbit ransomware - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Scheduled tasks used in BadRabbit ransomware
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names specific to Bad Rabbit ransomware has been created or deleted
action.notable.param.rule_title = Scheduled tasks used in BadRabbit ransomware detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process) as process  from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe (Processes.process= "*create*"  OR Processes.process= "*delete*") by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | search (process=*rhaegal* OR process=*drogon* OR *viserion_*)

[ESCU - Schtasks scheduling job on remote system - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Lateral Movement", "Execution", "Scheduled Task", "Remote Services"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate a task is being scheduled on a remote host. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or malicious executables on remote systems.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators may create jobs on remote systems, but this activity is usually limited to a small set of hosts or users. It is important to validate and investigate as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Schtasks scheduling job on remote system - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Schtasks scheduling job on remote system
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
action.notable.param.rule_title = Schtasks scheduling job on remote system
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*/create*" Processes.process="* /s *" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Schtasks used for forcing a reboot - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that a forced reboot of system is scheduled.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Execution", "Scheduled Task"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate a task is being scheduled that would cause a forced reboot on the host. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence. This tactic is leveraged by the Bad Rabbit Ransomware.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Administrators may create jobs on systems forcing reboots to perform updates, maintenance, etc.
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Schtasks used for forcing a reboot - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -5h@h
dispatch.latest_time = -1h@h
action.correlationsearch.enabled = 1
action.correlationsearch.label = Schtasks used for forcing a reboot
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is scheduled to force a reboot
action.notable.param.rule_title = Schtasks used for scheduling a force reboot
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*shutdown*" Processes.process="*/r*" Processes.process="*/f*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Script Execution via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for scripts launched via WMI.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Windows Management Instrumentation"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for scripts launched via WMI, either remotely or locally, by looking for the execution of scrcons.exe, which is the scripting host used by WMI, similar to wscript or cscript.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Although unlikely, administrators may use wmi to launch scripts for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Script Execution via WMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Script Execution via WMI
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for scrcons.exe, which indicates that a script was launched via WMI.
action.notable.param.rule_title = Script execution via WMI on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = "scrcons.exe" by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Shim Database File Creation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for shim database files being written to default directories. The sdbinst.exe application is used to install shim database files (.sdb). According to Microsoft, a shim is a small library that transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Application Shimming"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for files being created in `Windows\AppPatch\Custom and Windows\AppPatch\Custom64`, the location where shim databases are installed. It will return all the files created, as well as the time of creation for the first and last file for each endpoint.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Because legitimate shim files are created and used all the time, this event, in itself, is not suspicious. However, if there are other correlating events, it may warrant further investigation.
action.escu.creation_date = 2017-10-03
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Shim Database File Creation - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Shim Database File Creation
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file, $file_name$, was created in the default shim database directory on $dest.
action.notable.param.rule_title = Shim database file created on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Filesystem.action) values(Filesystem.file_hash) as file_hash values(Filesystem.file_path) as file_path  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_path=*Windows\AppPatch\Custom* by Filesystem.file_name Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` |`drop_dm_object_name(Filesystem)`

[ESCU - Shim Database Installation With Suspicious Parameters - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the process execution and arguments required to silently create a shim database.  The sdbinst.exe application is used to install shim database files (.sdb). A shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Application Shimming"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of sdbinst.exe with command-line arguments of -q and -p.  The -q option performs a silent installation with no visible window, status, or warning information.  The -p option allows the shim database to contain patches.  It will return the count, the first time, and the last time these command-line arguments were seen on each endpoint and by each user.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-10-03
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Shim Database Installation With Suspicious Parameters - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Shim Database Installation With Suspicious Parameters
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = The system $dest$ had a shim database installed.
action.notable.param.rule_title = Shim Database Installation on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sdbinst.exe Processes.process="*-p*" Processes.process="*-q*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Short Lived Windows Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects accounts that were created and deleted in a short time period.
action.escu.mappings = {"cis20": ["CIS 16"], "mitre_attack": ["Persistence", "Create Account"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for Windows Event Logs 4720 (account creation) and 4726 (account deletion) and determines if they happen for the same user within 4 hours of each other.  It will report the user and machine that reported the events and the time it first and last saw this activity.
action.escu.how_to_implement = This search requires you to have enabled your Group Management Audit Logs in your Local Windows Security Policy and be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/
action.escu.known_false_positives = It is possible that an administrator created and deleted an account in a short time period.  Verifying activity with an administrator is advised.
action.escu.creation_date = 2018-01-05
action.escu.modification_date = 2018-01-05
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Short Lived Windows Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 0,4,8,12,16,20 * * *
dispatch.earliest_time = -245m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Short Lived Windows Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = The account $user$ was created and deleted in a short amount of time.
action.notable.param.rule_title = Short lived account $user$ on $dest
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(All_Changes.result_id) as result_id count min(_time) as firstTime max(_time) as lastTime from datamodel=Change where All_Changes.result_id=4720 OR All_Changes.result_id=4726 by _time span=4h All_Changes.user All_Changes.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("All_Changes")` | search result_id = 4720 result_id=4726 | transaction user connected=false maxspan=240m | table firstTime lastTime count user dest result_id

[ESCU - Single Letter Process On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for process names that consist only of a single letter.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns all the processes for each endpoint and user and filters out any process that isn't 5 characters long and ends with .exe.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Single-letter executables are not always malicious. Investigate this activity with your normal incident-response process.
action.escu.creation_date = 2018-03-22
action.escu.modification_date = 2019-04-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Single Letter Process On Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Single Letter Process On Endpoint
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = A process with a single letter, $process_name$ was detected on $dest$
action.notable.param.rule_title = Single-letter executable $process_name$ on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest, Processes.user, Processes.process, Processes.process_name | `drop_dm_object_name(Processes)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | eval process_name_length = len(process_name), endExe = if(substr(process_name, -4) == ".exe", 1, 0) | search process_name_length=5 AND endExe=1 | table count, firstTime, lastTime, dest, user, process, process_name

[ESCU - Spectre and Meltdown Vulnerable Systems - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to detect systems that are still vulnerable to the Spectre and Meltdown vulnerabilities.
action.escu.mappings = {"cis20": ["CIS 4"], "nist": ["ID.RA", "RS.MI", "PR.IP", "DE.CM"]}
action.escu.data_models = ["Vulnerabilities"]
action.escu.eli5 = This search looks for the three CVEs associated with the Spectre and Meltdown vulnerabilities.
action.escu.how_to_implement = The search requires that you are ingesting your vulnerability-scanner data and that it reports the CVE of the vulnerability identified.
action.escu.known_false_positives = It is possible that your vulnerability scanner is not detecting that the patches have been applied.
action.escu.creation_date = 2018-01-07
action.escu.modification_date = 2017-01-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Spectre and Meltdown Vulnerable Systems - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Nessus", "Qualys"]
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
cron_schedule = 0 6 * * *
dispatch.earliest_time = -25h@h
dispatch.latest_time = -1h@h
action.correlationsearch.enabled = 1
action.correlationsearch.label = Spectre and Meltdown Vulnerable Systems
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = $dest is vulnerable to the Spectre or Meltdown CPU vulnerabilities.
action.notable.param.rule_title = $dest is vulnerable to the Spectre or Meltdown CPU vulnerabilities
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 100
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Vulnerabilities where Vulnerabilities.cve ="CVE-2017-5753" OR Vulnerabilities.cve ="CVE-2017-5715" OR Vulnerabilities.cve ="CVE-2017-5754" by Vulnerabilities.dest| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Spike in File Writes - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a sharp increase in the number of files written to a particular host
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search calculates counts the number of file modification events per hour per host in your environment. It then takes the average and standard deviations of those numbers and displays any hosts with more than 20 events that have over four times the standard deviation more than the average number of file modifications.
action.escu.how_to_implement = In order to implement this search, you must populate the Endpoint file-system data model node. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the file system.
action.escu.known_false_positives = It is important to understand that if you happen to install any new applications on your hosts or are copying a large number of files, you can expect to see a large increase of file modifications.
action.escu.creation_date = 2017-08-20
action.escu.modification_date = 2018-12-03
action.escu.confidence = low
action.escu.full_search_name = ESCU - Spike in File Writes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -7d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Spike in File Writes
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = A sharp increase in file writes was detected on $dest
action.notable.param.rule_title = Spike in file writes on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = low
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 7200s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Filesystem where Filesystem.action=created by _time span=1h, Filesystem.dest | `drop_dm_object_name(Filesystem)` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-1d@d"), count, null))) as "count" avg(eval(if(_time<relative_time(maxtime, "-1d@d"), count,null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-1d@d"), count, null))) as stdev by "dest" | eval upperBound=(avg+stdev*4), isOutlier=if((count > upperBound) AND num_data_samples >=20, 1, 0) | search isOutlier=1

[ESCU - Splunk Enterprise Information Disclosure - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to look for evidence of exploitation for CVE-2018-11409, a Splunk Enterprise Information Disclosure Bug.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 4", "CIS 18"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.AC", "PR.IP", "DE.CM"]}
action.escu.eli5 = This search searches Splunk's internal logs for evidence of CVE-2018-11409 exploitation attempts.
action.escu.how_to_implement = The REST endpoint that exposes system information is also necessary for the proper operation of Splunk clustering and instrumentation. Whitelisting your Splunk systems will reduce false positives.
action.escu.known_false_positives = Retrieving server information may be a legitimate API request. Verify that the attempt is a valid request for information.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-06-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Splunk Enterprise Information Disclosure - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Splunk Server
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.analytic_story = ["Splunk Enterprise Vulnerability CVE-2018-11409"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Splunk Enterprise Information Disclosure
action.notable = 1
action.notable.param.nes_fields = dest, src_ip
action.notable.param.rule_description = The Splunk Server $dest$ had a possible Splunk information-disclosure possibility from $src_ip$
action.notable.param.rule_title = Possible Splunk Information Disclosure Exploitation Attempt from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, src_ip
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = index=_internal sourcetype=splunkd_ui_access server-info | search clientip!=127.0.0.1 uri_path="*raw/services/server/info/server-info" | rename clientip as src_ip, splunk_server as dest | stats earliest(_time) as firstTime, latest(_time) as lastTime, values(uri) as uri, values(useragent) as http_user_agent, values(user) as user by src_ip, dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Suspicious Changes to File Associations - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for changes to registry values that control Windows file associations, executed by a process that is not typical for legitimate, routine changes to this area.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Change Default File Association"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for changes made to the registry that control Windows file associations. It is typical for users to change the file association to open certain types of files with specific applications. However, when these changes are legitimately performed, they are typically done via the processes explorer.exe or openwith.exe. The search first executes the subsearch that looks at the Registry node, which specifies setting a value in the registry and creates a table of process_id and dest. It then uses those arguments to find out what process and parent process were responsible for making those registry changes.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.
action.escu.known_false_positives = There may be other processes in your environment that users may legitimately use to modify file associations. If this is the case and you are finding false positives, you can modify the search to add those processes as exceptions.
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-01-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious Changes to File Associations - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Changes to File Associations
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name, process
action.notable.param.rule_description = The system $dest$ had an unusual change to a file association
action.notable.param.rule_title = Suspicious File Association Change on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name!=Explorer.exe AND Processes.process_name!=OpenWith.exe by Processes.process_id Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | join [| tstats `security_content_summariesonly` values(Registry.registry_path) as registry_path count  FROM datamodel=Endpoint.Registry where Registry.registry_path=*\\Explorer\\FileExts* by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | table process_id dest registry_path]

[ESCU - Suspicious Email - UBA Anomaly - Rule]
action.escu = 0
action.escu.enabled = 1
description = This detection looks for emails that are suspicious because of their sender, domain rareness, or behavior differences. This is an anomaly generated by Splunk User Behavior Analytics (UBA).
action.escu.mappings = {"cis20": ["CIS 7"], "kill_chain_phases": ["Delivery"], "mitre_attack": [], "nist": ["PR.IP"]}
action.escu.data_models = ["UEBA"]
action.escu.eli5 = This detection monitors for emails that are suspicious because of their sender, domain rareness, or behavior differences, as determined by Splunk UBA. In this search, we query the "UEBA" data model to look for anomalies that are raised by the "SuspiciousEmailDetectionModel" and will output the count, description of the anomaly, signature, the type of event in UBA, the severity, and the user who received a potentially suspicious email from a newly seen domain. It will also output all the categories associated with that anomaly.
action.escu.how_to_implement = You must be ingesting data from email logs and have Splunk integrated with UBA. This anomaly is raised by a UBA detection model called  "SuspiciousEmailDetectionModel." Ensure that this model is enabled on your UBA instance.
action.escu.known_false_positives = This detection model will alert on any sender domain that is seen for the first time. This could be a potential false positive. The next step is to investigate and whitelist the URL if you determine that it is a legitimate sender.
action.escu.creation_date = 2019-07-21
action.escu.modification_date = 2019-07-21
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious Email - UBA Anomaly - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["user", "url"]
action.escu.entities = ["user", "url"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Email - UBA Anomaly
action.notable = 1
action.notable.param.nes_fields = user, url
action.notable.param.rule_description = Newly observed email domain $url$ sent an email to $user$.
action.notable.param.rule_title = Suspicious Email Anomaly
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = |tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(All_UEBA_Events.category) as category from datamodel=UEBA where nodename=All_UEBA_Events.UEBA_Anomalies All_UEBA_Events.UEBA_Anomalies.uba_model = "SuspiciousEmailDetectionModel" by All_UEBA_Events.description All_UEBA_Events.severity All_UEBA_Events.user All_UEBA_Events.uba_event_type All_UEBA_Events.link All_UEBA_Events.signature All_UEBA_Events.url All_UEBA_Events.UEBA_Anomalies.uba_model | `drop_dm_object_name(All_UEBA_Events)` | `drop_dm_object_name(UEBA_Anomalies)`| `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Suspicious Email Attachment Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for emails that have attachments with suspicious file extensions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 7", "CIS 12"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["Execution", "Defense Evasion"], "nist": ["DE.AE", "PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks at any email messages with attachments and checks the file names of those attachments against an included lookup file to see if it has a suspicious file extension.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. \
 **Splunk Phantom Playbook Integration**\
If Splunk Phantom is also configured in your environment, a Playbook called "Suspicious Email Attachment Investigate and Delete" can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, and add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search. The notable event will be sent to Phantom and the playbook will gather further information about the file attachment and its network behaviors. If Phantom finds malicious behavior and an analyst approves of the results, the email will be deleted from the user's inbox.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-04-20
action.escu.modification_date = 2019-05-13
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious Email Attachment Extensions - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_user", "message_id"]
action.escu.entities = ["src_user", "message_id"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Email Attachment Extensions
action.notable = 1
action.notable.param.nes_fields = src_user, file_name
action.notable.param.rule_description = The sender $src_user$ has sent an email with a suspicious file named $file_name$
action.notable.param.rule_title = Suspicious Email Attachment from $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user,message_id
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Email")` | `suspicious_email_attachments`

[ESCU - Suspicious File Write - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for files created with names that have been linked to malicious activity.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": [], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at files being created or modified in the Endpoint file-system data model. The names of those files are checked against an included lookup file, which contains the names of files associated with malware or attack activity. The search returns any files with matching names, along with a note (also specified in the lookup file) that gives or points to more information about the files.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes. In addition, this search leverages an included lookup file that contains the names of the files to watch for, as well as a note to communicate why that file name is being monitored. This lookup file can be edited to add or remove file the file names you want to monitor.
action.escu.known_false_positives = It's possible for a legitimate file to be created with the same name as one noted in the lookup file. Filenames listed in the lookup file should be unique enough that collisions are rare. Looking at the location of the file and the process responsible for the activity can help determine whether or not the activity is legitimate.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2019-04-25
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious File Write - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Hidden Cobra Malware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious File Write
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A write to a filename associated with malicious activity detected on $dest$.
action.notable.param.rule_title = Suspicious File Write Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Filesystem.action) as action values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem by Filesystem.file_name Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Filesystem)` | `suspicious_writes`

[ESCU - Suspicious Java Classes - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for suspicious Java classes that are often used to exploit remote command execution in common Java frameworks, such as Apache Struts.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 12"], "kill_chain_phases": ["Exploitation"], "mitre_attack": ["Execution"], "nist": ["DE.AE"]}
action.escu.eli5 = The search leverages HTTP form data from typically POST events that can be captured with Splunk streams or similar wire data capture tools. The search looks for java classes like `processbuilder` and `runtime` are used to create a new process and execute commands inside java, and are synonymous with spawning a shell. There are very exceptional reasons to ever these classes in Java via an HTTP API and hence when seen are highly suspicious. Also, this is a common vectors leverage to exploit Apache Struts.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your web-traffic appliances that serve or sit in the path of your Struts application servers. This can be accomplished by indexing data from a web proxy, or by using network traffic-analysis tools, such as Splunk Stream or Bro.
action.escu.known_false_positives = There are no known false positives.
action.escu.creation_date = 2018-12-06
action.escu.modification_date = 2018-12-06
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious Java Classes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Apache"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Java Classes
action.notable = 1
action.notable.param.nes_fields = src, url, http_user_agent
action.notable.param.rule_description = The host $src$ with user agent $http_user_agent$ is sending web traffic to $url$, which contains suspicious Java classes. These classes may be indicative of remote code execution in Java frameworks, such as Apache Struts.
action.notable.param.rule_title = Suspicious Java Classes: Possible RCE against Struts or similar Java framework from $src$
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, url, http_user_agent
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="stream:http" http_method=POST http_content_length>1 | regex form_data="(?i)java\.lang\.(?:runtime|processbuilder)" | rename src_ip as src | stats count earliest(_time) as firstTime, latest(_time) as lastTime, values(url) as uri, values(status) as status, values(http_user_agent) as http_user_agent by src, dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Suspicious LNK file launching a process - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for a ``*.lnk` file under `C:\User*` or `*\Local\Temp\*` executing a process. This is common behavior used by various spear phishing tools.
action.escu.mappings = {"cis20": ["CIS 7", "CIS 8"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "mitre_attack": ["Initial Access", "Spearphishing Attachment"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are essentially trying to detect if a LNK file created under the C:\User* or *\Local\Temp\* directory structures is launching a process with in 1 hour of its creation. LNK files or also known as Windows shortcut files are commonly associated with phishing and are a [preferred method used for exploitation](https://www.fireeye.com/blog/threat-research/2017/04/fin7-phishing-lnk.html).
action.escu.how_to_implement = You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.
action.escu.known_false_positives = This detection should yield little or no false positive results. It is uncommon for LNK files to execute process from temporary or user directories.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious LNK file launching a process - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Phishing Payloads"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious LNK file launching a process
action.notable = 1
action.notable.param.nes_fields = dest, process_name, file_name
action.notable.param.rule_description = suspicious LNK file from $file_name$ is executing a process $process_name$ on $dest$
action.notable.param.rule_title = LNK file $file_name$ is executing process $process_name$ on $dest$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_name="*.lnk" AND (Filesystem.file_path="C:\\Users*" OR Filesystem.file_path="*Local\\Temp*")  by _time span=1h Filesystem.process_id Filesystem.file_name Filesystem.file_path Filesystem.file_hash Filesystem.user | `drop_dm_object_name(Filesystem)` | rename process_id as lnk_pid | join lnk_pid, _time [| tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Processes where Processes.process_name=*  by _time span=1h Processes.parent_process_id Processes.process_id Processes.process_name Processes.dest Processes.process_path Processes.process | `drop_dm_object_name(Processes)` | rename parent_process_id as lnk_pid | fields _time lnk_pid process_id dest process_name process_path process] | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime, lastTime, lnk_pid, process_id, user, dest, file_name, file_path, process_name, process, process_path, file_hash

[ESCU - Suspicious Reg.exe Process - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for reg.exe being launched from a command prompt not started by the user. When a user launches cmd.exe, the parent process is usually explorer.exe. This search filters out those instances.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Modify Registry", "Disabling Security Tools"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of reg.exe with a parent process of cmd.exe. It then executes a subsearch looking for those cmd.exe processes with a parent that is not explorer.exe. It then joins those two searches to make sure that the reg.exe process is a grandchild of the non explorer.exe process. The search will return the number of such instances and the first and last time this activity has been seen on each endpoint and user.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = It's possible for system administrators to write scripts that exhibit this behavior. If this is the case, the search will need to be modified to filter them out.
action.escu.creation_date = 2017-10-11
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious Reg.exe Process - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Windows Defense Evasion Tactics"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Reg.exe Process
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ had reg.exe process run not initiated by a user.
action.notable.param.rule_title = Suspicious reg.exe process detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.parent_process_name != explorer.exe Processes.process_name =cmd.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest Processes.process_id Processes.parent_process_id | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Processes where Processes.parent_process_name=cmd.exe Processes.process_name= reg.exe by Processes.parent_process_id Processes.dest Processes.process_name | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename parent_process_id as process_id |dedup process_id| table process_id dest]

[ESCU - Suspicious wevtutil Usage - Rule]
action.escu = 0
action.escu.enabled = 1
description = The wevtutil.exe application is the windows event log utility. This searches for wevtutil.exe with parameters for clearing the application, security, setup, or system event logs.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 6"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "nist": ["DE.DP", "PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for execution of wevtutil.exe with command-line arguments that indicate that it has been used to delete the setup, application, security, or system event logs. The search returns the number of times the behavior was observed, the first and last time it was seen, the host exhibiting the behavior and the user context of the process execution.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = The wevtutil.exe application is a legitimate Windows event log utility. Administrators may use it to manage Windows event logs.
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious wevtutil Usage - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious wevtutil Usage
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = wevtutil is the windows event log tool. This searches for wevtutil clearing the security or system logs.
action.notable.param.rule_title = Suspicious wevtutil Usage
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.drilldown_name = View wevtutil process information on $dest$
action.notable.param.drilldown_search = | from datamodel:Endpoint.Processes | search dest="$dest$"  process=*wevtutil*
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wevtutil.exe Processes.process="*cl*" (Processes.process="*System*" OR Processes.process="*Security*" OR Processes.process="*Setup*" OR Processes.process="*Application*") by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)`

[ESCU - Suspicious writes to System Volume Information - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects writes to the 'System Volume Information' folder by something other than the System process.
action.escu.mappings = {"cis20": ["CIS 8"], "mitre_attack": ["Collection", "Data Staged"], "nist": ["DE.CM"]}
action.escu.eli5 = This search uses data on file writes captured via Sysmon to watch for writes to the "System Volume Information" folder by processes other than the system process. The search looks for event code 11 in the Sysmon events, which indicates a file-creation event. It then looks for a file created with a path that includes "System Volume Information" and a process ID (PID) other than 4. PID 4 is assigned to the System process on Windows systems. Excluding these writes allows us to filter out legitimate activity. It will report the system where the activity occurred, the path to which the file was written, the process responsible for the write, and the times it first and last saw this activity.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = It is possible that other utilities or system processes may legitimately write to this folder. Investigate and modify the search to include exceptions as appropriate.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious writes to System Volume Information - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious writes to System Volume Information
action.notable = 1
action.notable.param.nes_fields = dest, file_name, process
action.notable.param.rule_description = The process $process$ on $dest$ wrote $file_name$ to 'System Volume Information'.
action.notable.param.rule_title = Suspicious process $process$ wrote to 'System Volume Information' on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) EventCode=11 process_id!=4 file_path=*System\ Volume\ Information* | stats count min(_time) as firstTime max(_time) as lastTime by dest, Image, file_path | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Suspicious writes to windows Recycle Bin - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects writes to the recycle bin by a process other than explorer.exe.
action.escu.mappings = {"cis20": ["CIS 8"], "mitre_attack": ["Collection", "Data Staged"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search uses data on file writes captured via Sysmon to watch for writes to the Recycle Bin by processes other than explorer.exe. The search looks for event code 11 in the Sysmon events, which indicates a file-creation event. Next, it looks for files created with a path that includes the string "$Recycle.Bin" by processes other than explorer.exe, which is the process responsible for copying files to the Recycle Bin on delete. It will report the system where the activity occurred, the path to which the file was written, the process responsible for the write, and the times it first and last saw this activity.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on filesystem and process logs responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Filesystem` nodes.
action.escu.known_false_positives = Because the Recycle Bin is a hidden folder in modern versions of Windows, it would be unusual for a process other than explorer.exe to write to it. Incidents should be investigated as appropriate.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious writes to windows Recycle Bin - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious writes to windows Recycle Bin
action.notable = 1
action.notable.param.nes_fields = dest, file_name, process_name
action.notable.param.rule_description = The process $process_name$ on $dest$ wrote $file_name$ to the Recycle Bin.
action.notable.param.rule_title = Suspicious process $process_name$ wrote to the Recycle Bin on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name FROM datamodel=Endpoint.Filesystem where Filesystem.filepath = "*$Recycle.Bin*" by Filesystem.process_id Filesystem.dest | `drop_dm_object_name("Filesystem")`| search [| tstats `security_content_summariesonly` values(Processes.user) as user values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name != "explorer.exe" by Processes.process_id Processes.dest| `drop_dm_object_name("Processes")` | table process_id dest]

[ESCU - System Processes Run From Unexpected Locations - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for system processes that normally run out of C:\Windows\System32\ or C:\Windows\SysWOW64 that are not run from that location.  This can indicate a malicious process that is trying to hide as a legitimate process.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Masquerading"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns all the processes that are not executing out of the C:\Windows\System32 or C:\Windows\SysWOW64 directories. It then uses a regular expression to extract the file name of the running process. Next, it takes the filename and looks it up in a table of files that should normally run out of the C:\Windows\System32 or C:\Windows\SysWOW64 directory. Any matches are then returned.
action.escu.how_to_implement = To successfully implement this search you need to ingest details about process execution from your hosts. Specifically, this search requires the process name and the full path to the process executable.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2016-08-24
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - System Processes Run From Unexpected Locations - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Suspicious Command-Line Executions", "Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = System Processes Run From Unexpected Locations
action.notable = 1
action.notable.param.nes_fields = user, process_name, dest
action.notable.param.rule_description = The system $dest$ has a process that normally runs out of Windows\System32\ that is not being run from that location.
action.notable.param.rule_title = System Processes Run From Unexpected Location on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process_name
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_path !="C:\\Windows\\System32*" Processes.process_path !="C:\\Windows\\SysWOW64*" by Processes.user Processes.dest Processes.process_name Processes.process_path Processes.process_id | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `is_windows_system_file`

[ESCU - TOR Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic identified as The Onion Router (TOR), a benign anonymity network which can be abused for a variety of nefarious purposes.
action.escu.mappings = {"cis20": ["CIS 9", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Commonly Used Port", "Exfiltration"], "nist": ["DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = The search leverages the Enterprise Security Network_Traffic data model to look for network traffic that has been identified as TOR and marked as 'allowed'.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2017-09-11
action.escu.confidence = medium
action.escu.full_search_name = ESCU - TOR Traffic - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Command and Control", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = TOR Traffic
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = Network traffic accessing TOR detected from $src_ip$
action.notable.param.rule_title = TOR Network Traffic Allowed from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=tor AND All_Traffic.action=allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - USN Journal Deletion - Rule]
action.escu = 0
action.escu.enabled = 1
description = The fsutil.exe application is a legitimate Windows utility used to perform tasks related to the file allocation table (FAT) and NTFS file systems. The update sequence number (USN) change journal provides a log of all changes made to the files on the disk. This search looks for fsutil.exe deleting the USN journal.
action.escu.mappings = {"cis20": ["CIS 6", "CIS 8", "CIS 10"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "nist": ["DE.CM", "PR.PT", "DE.AE", "DE.DP", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of fsutil.exe with command-line arguments to delete the USN journal. The search returns the count of the number of times it's seen this process execution with these arguments, the first and last time it's seen this behavior, the hosts it was executed on, and the user context under which it was executed.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-27
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - USN Journal Deletion - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = USN Journal Deletion
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ deleted its NTFS journals.
action.notable.param.rule_title = File System Journal Deleted on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process_name
alert.suppress.period = 14400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=fsutil.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process="*deletejournal*" AND process="*usn*"

[ESCU - Uncommon Processes On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for applications on the endpoint that you have marked as uncommon.
action.escu.mappings = {"cis20": ["CIS 2"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Accessibility Features"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns the number of times, as well as the first and last time, it has seen every process run for each endpoint and user, and then displays only those processes that you have marked as uncommon in the `uncommon_processes_default.csv` table.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. This search uses a lookup file `uncommon_processes_default.csv` to track various features of process names that are usually uncommon in most environments. Please consider updating `uncommon_processes_local.csv` to hunt for processes that are uncommon in your environment.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-12-08
action.escu.modification_date = 2019-04-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Uncommon Processes On Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes", "Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Uncommon Processes On Endpoint
action.notable = 1
action.notable.param.nes_fields = dest, process_name, user
action.notable.param.rule_description = Prohibited software $process_name$ has been detected on $dest$
action.notable.param.rule_title = Prohibited Software Detected On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `uncommon_processes`

[ESCU - Unsigned Image Loaded by LSASS - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects loading of unsigned images by LSASS.
action.escu.mappings = {"cis20": ["CIS 8", "CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Credential Access", "Credential Dumping"], "nist": ["DE.CM"]}
action.escu.eli5 = This search detects unsigned images loaded by LSASS (Local Security Authrity Subsystem Service). Normally, LSASS only loads signed images. Therefore, it is a malicious indicator when unsigned images are loaded by LSASS. This can be an indicator for credential dumping using tools like Windows Credential Editor.
action.escu.how_to_implement = This search needs Sysmon Logs with a sysmon configuration, which includes EventCode 7 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = Other tools could load images into LSASS for legitimate reason. But enterprise tools should always use signed DLLs.
action.escu.creation_date = 2019-12-06
action.escu.modification_date = 2019-12-06
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Unsigned Image Loaded by LSASS - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unsigned Image Loaded by LSASS
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Possible attempt at credential dumping was detected on $dest$.
action.notable.param.rule_title = unsigned images loaded by LSASS on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, ImageLoaded
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = `sysmon` EventID=7 Image=*lsass.exe Signed=false | stats count min(_time) as firstTime max(_time) as lastTime by Computer, Image, ImageLoaded, Signed, SHA1 | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `unsigned_image_loaded_by_LSASS_filter`

[ESCU - Unsuccessful Netbackup backups - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search gives you the hosts where a backup was attempted and then failed.
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.eli5 = This search looks across the most recent backup events for each host, and returns those messages that indicate there was a backup failure.
action.escu.how_to_implement = To successfully implement this search you need to obtain data from your backup solution, either from the backup logs on your endpoints or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your specific backup solution.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-15
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unsuccessful Netbackup backups - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution"]
cron_schedule = 0 7 * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unsuccessful Netbackup backups
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ attempted a backup but encountered an error.
action.notable.param.rule_title = Failed backup attempt by $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" | stats latest(_time) as latestTime by COMPUTERNAME, MESSAGE | search MESSAGE="An error occurred, failed to backup." | `security_content_ctime(latestTime)` | rename COMPUTERNAME as dest, MESSAGE as signature | table latestTime, dest, signature

[ESCU - Unusually Long Command Line - Rule]
action.escu = 0
action.escu.enabled = 1
description = Command lines that are extremely long may be indicative of malicious activity on your hosts.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search calculates the average and standard deviation for the length of the command lines on each of your endpoints and alerts when it detects a command line with a length over 10 times the standard deviation larger than the average command line.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships, from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Some legitimate applications start with long command lines.
action.escu.creation_date = 2017-08-23
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Unusually Long Command Line - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unusually Long Command Line
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = An unusually long command line $cmdline$ was found on $dest$
action.notable.param.rule_title = Unusually Long Command Line on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`|  eval processlen=len(process) | eventstats stdev(processlen) as stdev, avg(processlen) as avg by dest | stats max(processlen) as maxlen, values(stdev) as stdevperhost, values(avg) as avgperhost by dest, user, process_name, process| eval threshold = 10 | where maxlen > ((threshold*stdevperhost) + avgperhost)

[ESCU - Unusually Long Command Line - MLTK - Rule]
action.escu = 0
action.escu.enabled = 1
description = Command lines that are extremely long may be indicative of malicious activity on your hosts. This search leverages the Machine Learning Toolkit (MLTK) to help identify command lines with lengths that are unusual for a given user.
action.escu.mappings = {"cis20": ["CIS 8"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search leverages the Machine Learning Toolkit (MLTK) to identify outliers in the length of the command lines observed to be used by a specific user. The companion search, "Baseline of Command Line Length - MLTK," creates a machine-learning (ML) model built over the historical data used by this search. The determination of what is considered an outlier may be adjusted via the threshold parameter in the search. More information on the algorithm used can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.how_to_implement = You must be ingesting endpoint data that monitors command lines and populates the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model. In addition, MLTK version >= 4.2 must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of Command Line Length - MLTK" must be executed before this detection search, as it builds an ML model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.
action.escu.known_false_positives = Some legitimate applications use long command lines for installs or updates. You should review identified command lines for legitimacy. You may modify the first part of the search to omit legitimate command lines from consideration. If you are seeing more results than desired, you may consider changing the value of threshold in the search to a smaller value. You should also periodically re-run the support search to re-build the ML model on the latest data. You may get unexpected results if the user identified in the results is not present in the data used to build the associated model.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Unusually Long Command Line - MLTK - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = ["dest", "process_name", "user"]
action.escu.entities = ["dest", "process_name", "user"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unusually Long Command Line - MLTK
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = An unusually long command line $cmdline$ was found on $dest$
action.notable.param.rule_title = Unusually Long Command Line on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process_name
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| eval processlen=len(process) | search user!=unknown | apply cmdline_pdfmodel threshold=0.01 | rename "IsOutlier(processlen)" as isOutlier | search isOutlier > 0 | table firstTime lastTime user dest process_name process processlen count

[ESCU - Unusually Long Content-Type Length - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for unusually long strings in the Content-Type http header that the client sends the server.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 4", "CIS 18", "CIS 12"], "kill_chain_phases": ["Delivery"], "mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.eli5 = This detection search uses HTTP traffic data captured with Splunk Stream.  The search is constructed to use "stream:http" sourcetype and counts of the number of times an HTTP request is received by a destination which the length of the Content-Type header value the client sends the server is greater than 100 characters long. We calculate this content_type_length field and output the results.
action.escu.how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
action.escu.known_false_positives = Very few legitimate Content-Type fields will have a length greater than 100 characters.
action.escu.creation_date = 2017-03-14
action.escu.modification_date = 2017-10-13
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unusually Long Content-Type Length - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unusually Long Content-Type Length
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip, url
action.notable.param.rule_description = This search looks for unusually long strings in the Content-Type http header
action.notable.param.rule_title = Unusually Long Content-Type Length
action.notable.param.security_domain = network
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http | eval cs_content_type_length = len(cs_content_type) | where cs_content_type_length > 100 | table endtime src_ip dest_ip cs_content_type_length cs_content_type url

[ESCU - WMI Permanent Event Subscription - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI permanent event subscriptions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Windows Management Instrumentation", "Persistence", "Windows Management Instrumentation Event Subscription"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for the creation of a WMI event subscription by watching for Windows event ID 5861.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].
action.escu.known_false_positives = Although unlikely, administrators may use event subscriptions for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - WMI Permanent Event Subscription - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = WMI Permanent Event Subscription
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = This search looks for the creation of a permanent WMI event subscription via Windows event logs.
action.notable.param.rule_title = WMI Event Subscription Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="wineventlog:microsoft-windows-wmi-activity/operational" EventCode=5861 Binding | rex field=Message "Consumer =\s+(?<consumer>[^;|^$]+)" | search consumer!="NTEventLogEventConsumer=\"SCM Event Log Consumer\"" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, consumer, Message | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | rename ComputerName as dest

[ESCU - WMI Permanent Event Subscription - Sysmon - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI permanent event subscriptions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Windows Management Instrumentation", "Persistence", "Windows Management Instrumentation Event Subscription"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for the creation of a WMI event subscription by watching for Sysmon event ID 21.
action.escu.how_to_implement = To successfully implement this search, you must be collecting Sysmon data using Sysmon version 6.1 or greater and have Sysmon configured to generate alerts for WMI activity. In addition, you must have at least version 6.0.4 of the Sysmon TA installed to properly parse the fields.
action.escu.known_false_positives = Although unlikely, administrators may use event subscriptions for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - WMI Permanent Event Subscription - Sysmon - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = WMI Permanent Event Subscription - Sysmon
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = This search looks for the creation of a permanent WMI event subscription via Sysmon logs.
action.notable.param.rule_title = WMI Event Subscription Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" EventCode=21 | rename host as dest | table _time, dest, user, Operation, EventType, Query, Consumer, Filter

[ESCU - WMI Temporary Event Subscription - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI temporary event subscriptions.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Execution", "Windows Management Instrumentation", "Persistence", "Windows Management Instrumentation Event Subscription"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for the creation of a WMI temporary event subscription by watching for Windows event ID 5860.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].
action.escu.known_false_positives = Some software may create WMI temporary event subscriptions for various purposes. The included search contains an exception for two of these that occur by default on Windows 10 systems. You may need to modify the search to create exceptions for other legitimate events.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - WMI Temporary Event Subscription - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = WMI Temporary Event Subscription
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for the creation of a temporary WMI event subscription via Windows event logs.
action.notable.param.rule_title = Temporary WMI Event Subscription Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="wineventlog:microsoft-windows-wmi-activity/operational" EventCode=5860 Temporary | rex field=Message "NotificationQuery =\s+(?<query>[^;|^$]+)" | search query!="SELECT * FROM Win32_ProcessStartTrace WHERE ProcessName = 'wsmprovhost.exe'" AND query!="SELECT * FROM __InstanceOperationEvent WHERE TargetInstance ISA 'AntiVirusProduct' OR TargetInstance ISA 'FirewallProduct' OR TargetInstance ISA 'AntiSpywareProduct'" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, query  | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Web Fraud - Account Harvesting - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to identify the creation of multiple user accounts using the same email domain name.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Persistence", "Create Account"], "nist": ["DE.CM", "DE.DP"]}
action.escu.eli5 = When a fraudster is setting the stage for a campaign, they will often create many user accounts on the website. This is a simple example of how to detect a many-account creation hosted on a Magento2 e-commerce platform, where the fraudster is using email addresses from a single email domain.
action.escu.how_to_implement = We start with a dataset that provides visibility into the email address used for the account creation. In this example, we are narrowing our search down to the single web page that hosts the Magento2 e-commerce platform (via URI) used for account creation, the single http content-type to grab only the user's clicks, and the http field that provides the username (form_data), for performance reasons.  After we have the username and email domain, we look for numerous account creations per email domain.  Common data sources used for this detection are customized Apache logs or Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamolous behavior. This search will need to be customized to fit your environment&#151;improving its fidelity by counting based on something much more specific, such as a device ID that may be present in your dataset. Consideration for whether the large number of registrations are occuring from a first-time seen domain may also be important.  Extending the search window to look further back in time, or even calculating the average per hour/day for each email domain to look for an anomalous spikes, will improve this search.  You can also use Shannon entropy or Levenshtein Distance (both courtesy of URL Toolbox) to consider the randomness or similarity of the email name or email domain, as the names are often machine-generated.
action.escu.creation_date = 2018-07-12
action.escu.modification_date = 2018-10-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Fraud - Account Harvesting - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Account
action.escu.fields_required = ["src_user"]
action.escu.entities = ["src_user"]
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 1 * * *
dispatch.earliest_time = -1445m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Fraud - Account Harvesting
action.notable = 1
action.notable.param.nes_fields = src_user
action.notable.param.rule_description = This search is used to identify multiple created accounts tied to a specific email domain. Such activity is often indicative of account harvesting. A list of $src_user$ accounts were created.
action.notable.param.rule_title = Web Fraud Detection: Possible Account Harvesting
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http http_content_type=text* uri="/magento2/customer/account/loginPost/" | rex field=cookie "form_key=(?<SessionID>\w+)" | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | search Username=* | rex field=Username "@(?<email_domain>.*)"|stats dc(Username) as UniqueUsernames list(Username) as src_user by email_domain|where UniqueUsernames> 25

[ESCU - Web Fraud - Anomalous User Clickspeed - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to examine web sessions to identify those where the clicks are occurring too quickly for a human or are occurring with a near-perfect cadence (high periodicity or low standard deviation), resembling a script driven session.
action.escu.mappings = {"cis20": ["CIS 6"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Initial Access", "Valid Accounts"], "nist": ["DE.AE", "DE.CM"]}
action.escu.eli5 = It's suspicious when someone or something is moving throughout your website too quickly or with a perfect click cadence. Fortunately, it's easy to detect by calculating the time between clicks for each session and highlighting the anomalous behavior.
action.escu.how_to_implement = Start with a dataset that allows you to see clickstream data for each user click on the website. That data must have a time stamp and must contain a reference to the session identifier being used by the website. This ties the clicks together into clickstreams. This value is usually found in the http cookie. With a bit of tuning, a version of this search could be used in high-volume scenarios, such as scraping, crawling, application DDOS, credit-card testing, account takeover, etc. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosly written detections that simply detect anamoluous behavior.
action.escu.creation_date = 2018-07-12
action.escu.modification_date = 2018-10-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Fraud - Anomalous User Clickspeed - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = account
action.escu.fields_required = ["session_id"]
action.escu.entities = ["session_id"]
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Fraud - Anomalous User Clickspeed
action.notable = 1
action.notable.param.nes_fields = session_id
action.notable.param.rule_description = This search is used to examine web sessions in order to identify unnaturally rapid clicks with near-perfect cadence (high periodicity or low standard deviation), which resemble a script-driven session.
action.notable.param.rule_title = Web Fraud Detection: Anomalous User Clickspeed
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = session_id
action.risk.param._risk_object_type = other
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = session_id
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http http_content_type=text* | rex field=cookie "form_key=(?<session_id>\w+)" | streamstats window=2 current=1 range(_time) as TimeDelta by session_id | where TimeDelta>0 |stats count stdev(TimeDelta) as ClickSpeedStdDev avg(TimeDelta) as ClickSpeedAvg by session_id | where count>5 AND (ClickSpeedStdDev<.5 OR ClickSpeedAvg<.5)

[ESCU - Web Fraud - Password Sharing Across Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to identify user accounts that share a common password.
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["DE.DP"]}
action.escu.eli5 = A common password across user accounts generally indicates that the users are choosing poor passwords or that a fraudster has a common password across multiple accounts embedded within a script. The search will extract the username and password information from the form_data field, then calculate the number and values for usernames that have the same passwords. Finally, it outputs the values where the unique usernames sharing passwords are greater than 5
action.escu.how_to_implement = We need to start with a dataset that allows us to see the values of usernames and passwords that users are submitting to the website hosting the Magento2 e-commerce platform (commonly found in the HTTP form_data field). A tokenized or hashed value of a password is acceptable and certainly preferable to a clear-text password. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamoluous behavior.
action.escu.creation_date = 2018-07-12
action.escu.modification_date = 2018-10-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Fraud - Password Sharing Across Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = account
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Fraud - Password Sharing Across Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = This search is used to identify user accounts, $user$, that share common passwords
action.notable.param.rule_title = Web Fraud Detection: Password Sharing Across Accounts
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = other
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 3600s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http http_content_type=text* uri=/magento2/customer/account/loginPost*  | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | rex field=form_data "login\[password\]=(?<Password>[^&|^$]+)" | stats dc(Username) as UniqueUsernames values(Username) as user list(src_ip) as src_ip by Password|where UniqueUsernames>5

[ESCU - Web Servers Executing Suspicious Processes - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for suspicious processes on all systems labeled as web servers.
action.escu.mappings = {"cis20": ["CIS 3"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability", "Execution", "Discovery", "System Information Discovery"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This detection search uses the Enterprise Security Endpoint data model. The search uses tstats to search within an accelerated data model to find suspicious applications or processes such as whoami, ping, iptables, wget, service, or curl, running on hosts which are marked as web servers in the Assets and Identity Framework of ES.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. In addition, web servers will need to be identified in the Assets and Identity Framework of Enterprise Security.
action.escu.known_false_positives = Some of these processes may be used legitimately on web servers during maintenance or other administrative tasks.
action.escu.creation_date = 2017-03-14
action.escu.modification_date = 2019-04-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Servers Executing Suspicious Processes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Servers Executing Suspicious Processes
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for suspicious processes on all systems labeled as web servers
action.notable.param.rule_title = Web Servers Executing Suspicious Processes
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest_category="web_server" AND (Processes.process="*whoami*" OR Processes.process="*ping*" OR Processes.process="*iptables*" OR Processes.process="*wget*" OR Processes.process="*service*" OR Processes.process="*curl*") by Processes.process Processes.process_name, Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Windows Event Log Cleared - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Windows events that indicate one of the Windows event logs has been purged.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 5", "CIS 6"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "nist": ["DE.DP", "PR.IP", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.eli5 = This search looks at the Windows security and system event logs. EventCode 1002 in the security log indicates that the log has been cleared, EventCode 1000 in the security log indicates the event logging service has been shut down, and EventCode 104 in the system log indicates the application log has been cleared. If any of these events are found, a notable will be generated.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting Windows event logs from your hosts.
action.escu.known_false_positives = It is possible that these logs may be legitimately cleared by Administrators.
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2019-02-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - Windows Event Log Cleared - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Windows Event Log Cleared
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The Event Logging System has been cleared or shutdown on $dest$
action.notable.param.rule_title = Windows Event Log Cleared on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, signature_id
alert.suppress.period = 28800s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = ((eventtype=wineventlog_security) AND (signature_id=1102 OR signature_id=1100)) OR ((eventtype=wineventlog_system) AND signature_id=104) | stats count min(_time) as firstTime max(_time) as lastTime by signature_id dest user| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Windows hosts file modification - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to the hosts file on all Windows endpoints across your environment.
action.escu.mappings = {"cis20": ["CIS 3", "CIS 8", "CIS 12"], "kill_chain_phases": ["Command and Control"], "mitre_attack": ["Command and Control", "Exfiltration"], "nist": ["PR.IP", "PR.PT", "PR.AC", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The hosts file is present on both Windows and Linux endpoints. The purpose of the hosts file is to provide a mapping between hostnames and IP addresses, the same way DNS is used to provide such a mapping. However, the information in the hosts file takes precedence over information received via DNS and a DNS query will not be issued if the hostname of interest is found in the hosts file. As such, attackers have been observed adding entries to the host file to override any DNS resolution. For this reason, it is useful to monitor for changes to this file, which typically do not occur very often in legitimate cases.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = There may be legitimate reasons for system administrators to add entries to this file.
action.escu.creation_date = 2017-06-07
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Windows hosts file modification - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Host Redirection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Windows hosts file modification
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file modification was noted for the hosts file on $dest$.
action.notable.param.rule_title = Modification of hosts file detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem  by Filesystem.file_name Filesystem.file_path Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | search Filesystem.file_name=hosts AND Filesystem.file_path=*Windows\\System32\\* | `drop_dm_object_name(Filesystem)`

### END ESCU DETECTIONS ###

### ESCU INVESTIGATIONS ###

[ESCU - AWS Investigate User Activities By ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By ARN
description = This search lists all the logged CloudTrail activities by a specific user ARN and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and all the user's identity information.
action.escu.creation_date = 2018-01-22
action.escu.modification_date = 2019-04-30
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "Cloud Cryptomining", "Command and Control", "Suspicious AWS EC2 Activities", "Suspicious AWS Login Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Unusual AWS EC2 Modifications"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.arn={user} | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType

[ESCU - AWS Investigate User Activities By AccessKeyId]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By AccessKeyId
description = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific credentials.
action.escu.creation_date = 2018-06-08
action.escu.modification_date = 2018-06-08
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["accessKeyId"]
action.escu.entities = ["accessKeyId"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.accessKeyId={accessKeyId} | spath output=user path=userIdentity.arn  | rename sourceIPAddress as src_ip | table _time, user, src_ip, awsRegion, eventName, errorCode, errorMessage

[ESCU - AWS Investigate User Activities By Source User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By Source User
description = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific ARNs.
action.escu.creation_date = 2018-06-08
action.escu.modification_date = 2018-06-08
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_user"]
action.escu.entities = ["src_user"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.arn={src_user} | spath output=user path=userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, awsRegion, eventName, errorCode, errorMessage

[ESCU - AWS Network ACL Details from ID]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network ACL Details from ID
description = This search queries AWS description logs and returns all the information about a specific network ACL via network ACL ID
action.escu.creation_date = 2018-01-18
action.escu.modification_date = 2017-01-22
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["networkAclId"]
action.escu.entities = ["networkAclId"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:description id={networkAclId} | table id account_id vpc_id network_acl_entries{}.*

[ESCU - AWS Network Interface details via resourceId]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network Interface details via resourceId
description = This search queries AWS configuration logs and returns the information about a specific network interface via network interface ID. The information will include the ARN of the network interface, its relationships with other AWS resources, the public and the private IP associated with the network interface.
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS configuration inputs
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["resourceId"]
action.escu.entities = ["resourceId"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config resourceId={resourceId} | table _time ARN relationships{}.resourceType relationships{}.name relationships{}.resourceId  configuration.privateIpAddresses{}.privateIpAddress configuration.privateIpAddresses{}.association.publicIp

[ESCU - AWS S3 Bucket details via bucketName]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS S3 Bucket details via bucketName
description = This search queries AWS configuration logs and returns the information about a specific S3 bucket. The information returned includes the time the S3 bucket was created, the resource ID, the region it belongs to, the value of action performed, AWS account ID, and configuration values of the access-control lists associated with the bucket.
action.escu.creation_date = 2018-06-26
action.escu.modification_date = 2018-06-26
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = To implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later) and configure your AWS inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["bucketName"]
action.escu.entities = ["bucketName"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config resourceId={bucketName} | table resourceCreationTime resourceId awsRegion action aws_account_id supplementaryConfiguration.AccessControlList

[ESCU - All backup logs for host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - All backup logs for host
description = Retrieve the backup logs for the last 2 weeks for a specific host in order to investigate why backups are not completing successfully.
action.escu.creation_date = 2017-06-19
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = none
action.escu.how_to_implement = The successfully implement this search you must first send your backup logs to Splunk.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" dest={dest}

[ESCU - Get All AWS Activity From City]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From City
description = This search retrieves all the activity from a specific city and will create a table containing the time, city, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["City"]
action.escu.entities = ["City"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search City={City} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, City, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Country]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Country
description = This search retrieves all the activity from a specific country and will create a table containing the time, country, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["Country"]
action.escu.entities = ["Country"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Country={Country} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Country, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From IP Address]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From IP Address
description = This search retrieves all the activity from a specific IP address and will create a table containing the time, ARN, username, the type of user, the IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Network ACL Activity", "AWS Suspicious Provisioning Activities", "Command and Control", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search sourceIPAddress={src_ip} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Region]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Region
description = This search retrieves all the activity from a specific geographic region and will create a table containing the time, geographic region, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["Region"]
action.escu.entities = ["Region"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Region={Region} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Region, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get Authentication Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Authentication Logs For Endpoint
description = This search returns all users that have attempted to access a particular endpoint.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Authentication"]
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need to be ingesting authentication logs from your various systems and populating the Authentication data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count from datamodel=Authentication where Authentication.dest={dest} by _time, Authentication.dest, Authentication.user, Authentication.app, Authentication.action | `drop_dm_object_name("Authentication")`

[ESCU - Get Backup Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Backup Logs For Endpoint
description = This search will tell you the backup status from your netbackup_logs of a specific endpoint for the last week.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting your backup logs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" COMPUTERNAME={dest} | rename COMPUTERNAME as dest, MESSAGE as signature | table _time, dest, signature

[ESCU - Get Certificate logs for a domain]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Certificate logs for a domain
description = This search queries the Certificates datamodel and give you all the information for a specific domain. Please note that the certificates issued by "Let's Encrypt" are widely used by attackers.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.analytic_story = ["Common Phishing Frameworks"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Certificates"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting your certificates or SSL logs from your network traffic into your Certificates datamodel. Please note the wildcard(*) before domain in the search syntax, we use to match for all domain and subdomain combinations
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["domain"]
action.escu.entities = ["domain"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Certificates.All_Certificates where All_Certificates.SSL.ssl_subject_common_name=*{domain}  by All_Certificates.dest All_Certificates.src All_Certificates.SSL.ssl_issuer_common_name All_Certificates.SSL.ssl_subject_common_name All_Certificates.SSL.ssl_hash | `drop_dm_object_name(All_Certificates)` | `drop_dm_object_name(SSL)` | rename ssl_subject_common_name as domain | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get DNS Server History for a host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS Server History for a host
description = While investigating any detections it is important to understand which and how many DNS servers a host has connected to in the past. This search uses data that is tagged as DNS and gives you a count and list of DNS servers that a particular host has connected to the previous 24 hours.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "DNS Hijacking", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Host Redirection", "Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your DNS traffic
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
disabled = true
schedule_window = auto
is_visible = false
search = | search tag=dns src_ip={src_ip} dest_port=53 | streamstats time_window=1d count values(dest_ip) as dcip by src_ip | table date_mday src_ip dcip count | sort -count

[ESCU - Get DNS traffic ratio]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS traffic ratio
description = This search calculates the ratio of DNS traffic originating and coming from a host to a list of DNS servers over the last 24 hours. A high value of this ratio could be very useful to quickly understand if a src_ip (host) is sending a high volume of data out via port 53, could be an indicator of data exfiltration via DNS.  
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Network_Traffic"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting your network traffic
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip", "dest_ip"]
action.escu.entities = ["src_ip", "dest_ip"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats allow_old_summaries=true sum(All_Traffic.bytes_out) as "bytes_out" sum(All_Traffic.bytes_in) as "bytes_in" from datamodel=Network_Traffic where nodename=All_Traffic All_Traffic.dest_port=53 All_Traffic.src={src_ip} All_Traffic.dest={dest_ip} | eval ratio = (bytes_out/bytes_in) | table ratio

[ESCU - Get EC2 Instance Details by instanceId]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Instance Details by instanceId
description = This search queries AWS description logs and returns all the information about a specific instance via the instanceId field
action.escu.creation_date = 2018-02-12
action.escu.modification_date = 2018-02-12
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "Unusual AWS EC2 Modifications"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["instanceId"]
action.escu.entities = ["instanceId"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="aws:description" source="*:ec2_instances"| dedup id sortby -_time | search id={instanceId} | spath output=tags path=tags | eval tags=mvzip(key,value," = "), ip_address=if((ip_address == "null"),private_ip_address,ip_address) | table id, tags.Name, aws_account_id, placement, instance_type, key_name, ip_address, launch_time, state, vpc_id, subnet_id, tags | rename aws_account_id as "Account ID", id as ID, instance_type as Type, ip_address as "IP Address", key_name as "Key Pair", launch_time as "Launch Time", placement as "Availability Zone", state as State, subnet_id as Subnet, "tags.Name" as Name, vpc_id as VPC

[ESCU - Get EC2 Launch Details]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Launch Details
description = This search returns some of the launch details for a EC2 instance.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail responseElements.instancesSet.items{}.instanceId={dest} |rename userIdentity.arn as arn, responseElements.instancesSet.items{}.instanceId as instanceId, responseElements.instancesSet.items{}.privateIpAddress as privateIpAddress, responseElements.instancesSet.items{}.imageId as amiID, responseElements.instancesSet.items{}.architecture as architecture, responseElements.instancesSet.items{}.keyName as keyName | table arn, awsRegion, instanceId, architecture, privateIpAddress, amiID, keyName

[ESCU - Get Email Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Email Info
description = This search returns all the information Splunk might have collected a specific email message over the last 2 hours.
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your email logs or capturing unencrypted network traffic which contains email communications.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["message_id"]
action.escu.entities = ["message_id"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search message_id={message_id}

[ESCU - Get Emails From Specific Sender]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Emails From Specific Sender
description = This search returns all the emails from a specific sender over the last 24 and next hours.
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails", "Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_user"]
action.escu.entities = ["src_user"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search src_user={src_user}

[ESCU - Get First Occurrence and Last Occurrence of a MAC Address]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get First Occurrence and Last Occurrence of a MAC Address
description = This search allows you to gather more context around a notable which has detected a new device connecting to your network. Use this search to determine the first and last occurrences of the suspicious device attempting to connect with your network.
action.escu.creation_date = 2017-06-14
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Network_Sessions"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the logs from your DHCP server.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_mac"]
action.escu.entities = ["src_mac"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST All_Sessions.All_Sessions.src_mac= {src_mac} by All_Sessions.src_ip All_Sessions.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`

[ESCU - Get History Of Email Sources]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get History Of Email Sources
description = This search returns a list of all email sources seen in the 48 hours prior to the notable event to 24 hours after, and the number of emails from each source.
action.escu.creation_date = 2019-02-21
action.escu.modification_date = 2019-02-21
action.escu.analytic_story = []
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
disabled = true
schedule_window = auto
is_visible = false
search = |tstats `security_content_summariesonly` values(All_Email.dest) as dest values(All_Email.recipient) as recepient  min(_time) as firstTime max(_time) as lastTime count from datamodel=Email.All_Email by All_Email.src |`drop_dm_object_name(All_Email)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Logon Rights Modifications For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For Endpoint
description = This search allows you to retrieve any modifications to logon rights associated with a specific host.
action.escu.creation_date = 2017-08-16
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) dest={dest} | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Logon Rights Modifications For User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For User
description = This search allows you to retrieve any modifications to logon rights for a specific user account.
action.escu.creation_date = 2017-08-16
action.escu.modification_date = 2019-02-27
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
disabled = true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) user={user} | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Notable History]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Notable History
description = This search queries the notable index and returns all the Notable Events for the particular destination host, giving the analyst an overview of the incidents that may have occurred with the host under investigation.
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cross Account Activity", "AWS Cryptomining", "AWS Network ACL Activity", "AWS User Monitoring", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "Cloud Cryptomining", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual AWS EC2 Modifications", "Unusual Processes", "Use of Cleartext Protocols", "Web Fraud Detection", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = If you are using Enterprise Security you are likely already creating notable events with your correlation rules. No additional configuration is necessary.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | search `notable` | search dest={dest} | table _time, rule_name, owner, priority, severity, status_description

[ESCU - Get Notable Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Notable Info
description = This search queries the notable index to retrieve detailed information captured within the notable. Every notable has a unique ID associated with it, which is used to point us directly to the notable event under investigation.
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "AWS User Monitoring", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "Cloud Cryptomining", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Web Fraud Detection", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = If you are using Enterprise Security you are likely already creating notable events with your correlation rules. No additional configuration is necessary.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["event_id"]
action.escu.entities = ["event_id"]
disabled = true
schedule_window = auto
is_visible = false
search = | search `notable_by_id({event_id})` | table time, rule_name, dest, dest_asset_id, dest_owner, priority, severity, owner, status_description

[ESCU - Get Outbound Emails to Hidden Cobra Threat Actors]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Outbound Emails to Hidden Cobra Threat Actors
description = This search returns the information of the users that sent emails to the accounts controlled by the Hidden Cobra Threat Actors: specifically to `misswang8107@gmail.com`, and from `redhat@gmail.com`.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-06-14
action.escu.analytic_story = []
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_user", "recipient"]
action.escu.entities = ["src_user", "recipient"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search recipient=misswang8107@gmail.com OR src_user=redhat@gmail.com | stats count earliest(_time) as firstTime, latest(_time) as lastTime values(dest) values(src) by src_user recipient | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Parent Process Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Parent Process Info
description = This search queries the Endpoint data model to give you details about the parent process of a process running on a host which is under investigation. Enter the values of the process name in question and the dest
action.escu.creation_date = 2017-08-22
action.escu.modification_date = 2019-02-28
action.escu.analytic_story = ["Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Phishing Payloads", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process_name", "dest"]
action.escu.entities = ["process_name", "dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = {process_name} Processes.dest = {dest} by Processes.user Processes.parent_process_name  Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`

[ESCU - Get Process File Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process File Activity
description = This search returns the file activity for a specific process on a specific endpoint
action.escu.creation_date = 2019-11-06
action.escu.modification_date = 2019-11-06
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data and populating the Endpoint data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process_id", "dest"]
action.escu.entities = ["process_id", "dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Filesystem.file_name) as file_name values(Filesystem.dest) as dest, values(Filesystem.process_id) as process_id from datamodel=Endpoint.Filesystem where Filesystem.dest={dest} Filesystem.process_id={process_id} by Filesystem.file_path, Filesystem.action, _time | `drop_dm_object_name(Filesystem)`  | sort _time | table _time, process_id, dest, action, file_name, file_path

[ESCU - Get Process Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Info
description = This search queries the Endpoint data model to give you details about the process running on a host which is under investigation. To gather the process info, enter the values for the process name in question and the destination IP address.
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data and populating the Endpoint data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process_name", "dest"]
action.escu.entities = ["process_name", "dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Proceses.dest={dest} Proceses.process_name={process_name} by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` 

[ESCU - Get Process Information For Port Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Information For Port Activity
description = This search will return information about the process associated with observed network traffic to a specific destination port from a specific host.
action.escu.creation_date = 2017-06-25
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "DHS Report TA18-074A", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Lateral Movement", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious AWS Traffic", "Use of Cleartext Protocols"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that associates processes with network events and populate the Endpoint Datamodel
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest_port", "dest"]
action.escu.entities = ["dest_port", "dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest = {dest} by Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` count from datamodel=Endpoint.Ports where Ports.dest_port={dest_port} by Ports.process_id Ports.src  | `drop_dm_object_name(Ports)` | rename src as dest]

[ESCU - Get Process Registry Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Registry Activity
description = This search returns the registry activity for a specific process on a specific endpoint
action.escu.creation_date = 2019-11-06
action.escu.modification_date = 2019-11-06
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data and populating the Endpoint data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process_id", "dest"]
action.escu.entities = ["process_id", "dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Registry.registry_key_name) as registry_key_name, values(Registry.dest) as dest, values(Registry.process_id) as process_id from datamodel=Endpoint.Registry where Registry.process_id={process_id} AND Registry.dest={dest} by Registry.registry_path, Registry.action, _time | `drop_dm_object_name(Registry)` | sort _time | table _time, process_id, dest, action, registry_key_name, registry_path

[ESCU - Get Process Responsible For The DNS Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Responsible For The DNS Traffic
description = While investigating, an analyst will want to know what process and parent_process is responsible for generating suspicious DNS traffic. Use the following search and enter the value of `dest` in the search to get specific details on the process responsible for creating the DNS traffic.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Brand Monitoring", "Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting endpoint data that associates processes with network events into the Endpoint datamodel. This can come from endpoint protection products such as carbon black, or endpoint data sources such as Sysmon.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest = {dest} by Processes.parent_process Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` count from datamodel=Endpoint.Ports where Ports.dest_port=53 by Ports.process_id Ports.src | `drop_dm_object_name(Ports)` | rename src as dest]

[ESCU - Get Registry Activities]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Registry Activities
description = This search queries the Endpoint Datamodel to give you details of the latest registry values for a specific destination computer.
action.escu.creation_date = 2018-08-07
action.escu.modification_date = 2019-03-01
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (DHS Report TA18-201A)", "Lateral Movement", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Persistence Techniques", "Windows Privilege Escalation"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Registry.registry_path) as registry_path values(Registry.registry_key_name) as registry_key_name count FROM datamodel=Endpoint.Registry where Registry.dest = "{dest}" by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | join [| tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name = reg.exe by Processes.process_id | `drop_dm_object_name("Processes")`]

[ESCU - Get Risk Modifiers For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Risk Modifiers For Endpoint
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk\_scores, names of the correlation searches that contributed to create a risk score for a specific endpoint(machine\_name) 
action.escu.creation_date = 2017-10-14
action.escu.modification_date = 2017-10-19
action.escu.analytic_story = ["AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Risk"]
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = Enable the correlation searches included in Splunk Enterprise Security that include Risk Analysis alert actions by leveraging the Risk Analysis Framework
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Risk.All_Risk | search risk_object_type=system risk_object={dest} | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Risk Modifiers For User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Risk Modifiers For User
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk_scores, names of the correlation searches that contributed to create a risk score for a specific user 
action.escu.creation_date = 2017-10-14
action.escu.modification_date = 2017-10-19
action.escu.analytic_story = ["AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Risk"]
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = Enable the correlation searches included in Splunk Enterprise Security that include Risk Analysis alert actions by leveraging the Risk Analysis Framework
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Risk.All_Risk | search risk_object_type=user risk_object={user} | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` 

[ESCU - Get Sysmon WMI Activity for Host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Sysmon WMI Activity for Host
description = This search queries Sysmon WMI events for the host of interest.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Sysmon"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be collecting Sysmon data using Sysmon version 6.1 or greater and have Sysmon configured to generate events for WMI activity. In addition, you must have at least version 6.0.4 of the Sysmon TA installed to properly parse the fields.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process", "dest"]
action.escu.entities = ["process", "dest"]
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" EventCode>18 EventCode<22 host={dest} | rename host as dest | table _time, dest, user, Name, Operation, EventType, Type, Query, Consumer, Filter

[ESCU - Get Update Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Update Logs For Endpoint
description = This search will tell you give you the update logs for a specific endpoint for the last week.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-08-24
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)", "Monitor for Unauthorized Software", "Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Updates"]
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.eli5 = none
action.escu.how_to_implement = You need to be ingesting the update logs from your various systems.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Updates.Updates  | search (vendor_product="Microsoft Windows" OR vendor_product="OSX:Update" OR vendor_product="Linux:Update") dest={dest}

[ESCU - Get User Information from Identity Table]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get User Information from Identity Table
description = Gather more information about the user identified in the Notable Event.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Brand Monitoring", "Cloud Cryptomining", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must have populated the identity table with information about your users.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
disabled = true
schedule_window = auto
is_visible = false
search = | `identities` | search identity={user} | table _time, identity, first, last, email, category, watchlist

[ESCU - Get Vulnerability Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Vulnerability Logs For Endpoint
description = This search will show you any vulnerabilities noted for a specific endpoint for the last week.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-10
action.escu.analytic_story = ["ColdRoot MacOS RAT", "DHS Report TA18-074A", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Monitor for Unauthorized Software", "Ransomware", "SamSam Ransomware", "Windows Log Manipulation"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Vulnerabilities"]
action.escu.providing_technologies = ["Nessus"]
action.escu.eli5 = none
action.escu.how_to_implement = You need to be ingesting the logs from your vulnerability scanner.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Vulnerabilities.Vulnerabilities | search dest={dest}

[ESCU - Get Web Session Information via session_id]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Web Session Information via session_id
description = This search helps an analyst investigate a notable event to find out more about a specific web session. The search looks for a specific web session ID in the HTTP web traffic and outputs the URL and user agents, grouped by source IP address and HTTP status code.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.eli5 = none
action.escu.how_to_implement = This search leverages data extracted from Stream:HTTP. You must configure the HTTP stream using the Splunk Stream App on your Splunk Stream deployment server.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["session_id"]
action.escu.entities = ["session_id"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http {session_id} | stats values(url) values(http_user_agent) by src_ip status

[ESCU - Investigate AWS User Activities by user field]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS User Activities by user field
description = This search lists all the logged CloudTrail activities by a specific user and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and the user's identity information.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
action.escu.entities = ["user"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail user={user} | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType 

[ESCU - Investigate AWS activities via region name]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS activities via region name
description = This search lists all the user activities logged by CloudTrail for a specific region in question and will create a table of the values of parameters requested, the type of the event and the response from the AWS API by each user
action.escu.creation_date = 2018-02-09
action.escu.modification_date = 2018-02-09
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["awsRegion"]
action.escu.entities = ["awsRegion"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail awsRegion={awsRegion}| rename requestParameters.instancesSet.items{}.instanceId as instanceId| stats values(eventName) by userName instanceId

[ESCU - Investigate Cloud Compute Instance Activities]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Cloud Compute Instance Activities
description = This search returns a logs of events that operated on the compute instance.
action.escu.creation_date = 2019-10-02
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Cloud_Infrastructure.Compute | search dest={dest} | fields - _* | `investigate_cloud_compute_instance_activities_output_filter`

[ESCU - Investigate Failed Logins for Multiple Destinations]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Failed Logins for Multiple Destinations
description = This search returns failed logins to multiple destinations by user.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Authentication"]
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need to be ingesting authentication logs from your various systems and populating the Authentication data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count `security_content_summariesonly` earliest(_time) as first_login latest(_time) as last_login dc(Authentication.dest) AS distinct_count_dest values(Authentication.dest) AS Authentication.dest values(Authentication.app) AS Authentication.app  from datamodel=Authentication where Authentication.action=failure by Authentication.user | where distinct_count_dest > 1 | `security_content_ctime(first_login)` | `security_content_ctime(last_login)` | `drop_dm_object_name("Authentication")`

[ESCU - Investigate Network Traffic From src_ip]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Network Traffic From src_ip
description = This search allows you to find all the network traffic from a specific IP address.
action.escu.creation_date = 2018-06-15
action.escu.modification_date = 2018-06-15
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Splunk Enterprise Vulnerability CVE-2018-11409"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Network_Traffic"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your web-traffic logs and populating the web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Network_Traffic.All_Traffic | search src_ip={src_ip}

[ESCU - Investigate Pass the Hash Attempts]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Pass the Hash Attempts
description = This search hunts for dumped NTLM hashes used for pass the hash.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need be ingesting windows security logs. This search uses an input macro named `wineventlog_security`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Security logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = `wineventlog_security` EventCode=4624 Logon_Type=9 AuthenticationPackageName=Negotiate | stats count earliest(_time) as first_login latest(_time) as last_login by src_user dest | `security_content_ctime(first_login)` | `security_content_ctime(last_login)`

[ESCU - Investigate Pass the Ticket Attempts]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Pass the Ticket Attempts
description = This search hunts for dumped kerberos ticket from LSASS memory.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need to be ingesting windows security logs. This search uses an input macro named `wineventlog_security`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Security logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = `wineventlog_security` EventCode=4768 OR EventCode=4769 | rex field=user "(?<new_user>[^\@]+)" | stats count BY new_user, dest, EventCode | stats max(count) AS max_count sum(count) AS sum_count BY new_user, dest | where sum_count/max_count!=2 | rename new_user AS user

[ESCU - Investigate Previous Unseen User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Previous Unseen User
description = This search returns previous unseen user, which didn't log in for 30 days.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Authentication"]
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need to be ingesting authentication logs from your various systems and populating the Authentication data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count `security_content_summariesonly` earliest(_time) as first_login latest(_time) as last_login values(Authentication.dest) AS Authentication.dest values(Authentication.app) AS Authentication.app values(Authentication.action) AS Authentication.action from datamodel=Authentication where Authentication.action=success by _time, Authentication.user | bucket _time span=30d | stats count min(first_login) as first_login max(last_login) as last_login values(Authentication.dest) AS Authentication.dest by Authentication.user | where count=1 | where first_login >= relative_time(now(), "-30d") | `security_content_ctime(first_login)` | `security_content_ctime(last_login)` | `drop_dm_object_name("Authentication")`

[ESCU - Investigate Successful Remote Desktop Authentications]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Successful Remote Desktop Authentications
description = This search returns the source, destination, and user for all successful remote-desktop authentications. A successful authentication after a brute-force attack on a destination machine is suspicious behavior. 
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Authentication"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be populating the Authentication data model with security events from your Windows event logs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Authentication where Authentication.signature_id=4624 Authentication.app=win:remote by Authentication.src Authentication.dest Authentication.app Authentication.user Authentication.signature Authentication.src_nt_domain | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("Authentication")`| table firstTime lastTime src src_nt_domain dest user app count | sort count

[ESCU - Investigate Suspicious Strings in HTTP Header]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Suspicious Strings in HTTP Header
description = This search helps an analyst investigate a notable event related to a potential Apache Struts exploitation. To investigate, we will want to isolate and analyze the "payload" or the commands that were passed to the vulnerable hosts by creating a few regular expressions to carve out the commands focusing on common keywords from the payload, such as cmd.exe, /bin/bash and whois. The search returns these suspicious strings found in the HTTP logs of the system of interest.
action.escu.creation_date = 2017-06-26
action.escu.modification_date = 2017-10-20
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.eli5 = none
action.escu.how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip", "dest_ip"]
action.escu.entities = ["src_ip", "dest_ip"]
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http src_ip="{src_ip}" dest_ip="{dest_ip}" | eval cs_content_type_length = len(cs_content_type) | search cs_content_type_length > 100 | rex field="cs_content_type" (?<suspicious_strings>cmd.exe) | eval suspicious_strings_found=if(match(cs_content_type, "application"), "True", "False")  | rename suspicious_strings_found AS "Suspicious Content-Type Found" | fields "Suspicious Content-Type Found", dest_ip, src_ip, suspicious_strings, cs_content_type, cs_content_type_length, url

[ESCU - Investigate User Activities In All Cloud Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate User Activities In All Cloud Regions
description = This search lists all the logged cloud infrastructure activities by a specific cloud user
action.escu.creation_date = 2019-10-02
action.escu.modification_date = 2019-04-30
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["region", "src_user"]
action.escu.entities = ["region", "src_user"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Cloud_Infrastructure.Compute | search user={src_user} | fields - _* | `investigate_user_activities_in_all_cloud_region_output_filter`

[ESCU - Investigate User Activities In Single Cloud Region]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate User Activities In Single Cloud Region
description = This search lists all the logged cloud infrastructure activities by a specific cloud user in a specific cloud region
action.escu.creation_date = 2019-10-02
action.escu.modification_date = 2019-04-30
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Cloud_Infrastructure"]
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["region", "src_user"]
action.escu.entities = ["region", "src_user"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel:Cloud_Infrastructure.Compute | search region={region} user={src_user} | fields - _* | `investigate_user_activities_in_single_cloud_region_output_filter`

[ESCU - Investigate Web Activity From Host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web Activity From Host
description = This search allows you to find all the web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Web"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your web traffic and populating the Web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
action.escu.entities = ["dest"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Web.Web | search src={dest}

[ESCU - Investigate Web Activity From src_ip]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web Activity From src_ip
description = This search searches for all web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.creation_date = 2018-06-15
action.escu.modification_date = 2018-06-15
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Dynamic DNS", "Splunk Enterprise Vulnerability CVE-2018-11409"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Web"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your web traffic and populating the web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
action.escu.entities = ["src_ip"]
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Web.Web | search src={src_ip}

[ESCU - Investigate Web POSTs From src]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web POSTs From src
description = This investigative search retrieves POST requests from a specified source IP or hostname. Identifying the POST requests, as well as their associated destination URLs and user agent(s), may help you scope and characterize the suspicious traffic. 
action.escu.creation_date = 2018-12-06
action.escu.modification_date = 2018-12-06
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Web"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your web-traffic logs and populating the web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src"]
action.escu.entities = ["src"]
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Web.url) as url from datamodel=Web by Web.src,Web.http_user_agent,Web.http_method | `drop_dm_object_name("Web")`| where like(src, "{src}") and like(http_method, "POST")


### END ESCU INVESTIGATIONS ###


### ESCU BASELINES ###

[ESCU - Add Prohibited Processes to Enterprise Security]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Add Prohibited Processes to Enterprise Security
description = This search takes the existing interesting process table from ES, filters out any existing additions added by ESCU and then updates the table with processes identified by ESCU that should be prohibited on your endpoints.
action.escu.creation_date = 2017-06-27
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = ["Emotet Malware (DHS Report TA18-201A)", "Monitor for Unauthorized Software", "SamSam Ransomware"]
action.escu.data_models = []
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = This search outputs the interesting processes lookup table and filters out all processes in the table that haven't already been inserted by ESCU. It then appends to those results all the processes currently identified by ESCU that should be prohibited. Next, it fills in the required fields with processes identified by ESCU, and then writes the results back to the interesting process lookup table. This is done so any new processes identified that should be prohibited will be added to the lookup table without creating any duplicate entries.
action.escu.how_to_implement = This search should be run on each new install of ESCU.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | inputlookup interesting_processes_lookup | search note!=ESCU* | inputlookup append=T prohibitedProcesses_lookup | fillnull value=* dest dest_pci_domain | fillnull value=false is_required is_secure | fillnull value=true is_prohibited | outputlookup interesting_processes_lookup | stats count

[ESCU - Baseline of API Calls per User ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of API Calls per User ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = This search returns all log events that are API calls, pulls out the ARN that initiated each call, and collects them in one-hour groupings. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis.  It also includes the number of data points each ARN had. This table is then stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | stats count

[ESCU - Baseline of Command Line Length - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Command Line Length - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the command lines observed for each user in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies outliers in the length of the command line.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Unusual Processes"]
action.escu.data_models = ["Endpoint"]
dispatch.earliest_time = -31d@d
dispatch.latest_time = -1d@d
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = Create a machine-learning (ML) model to characterize the length of the command lines used in your environment. This can help you identify unusually long ones that may indicate that attackers are executing commands on yout systems.
action.escu.how_to_implement = You must be ingesting endpoint data and populating the Endpoint data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as start_time max(_time) as end_time FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name(Processes)` | search user!=unknown | `security_content_ctime(start_time)`| `security_content_ctime(end_time)`| eval processlen=len(process) | fit DensityFunction processlen by user into cmdline_pdfmodel

[ESCU - Baseline of DNS Query Length - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of DNS Query Length - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the DNS queries for each DNS record type observed in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which uses it to identify outliers in the length of the DNS query.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["Command and Control", "Hidden Cobra Malware", "Suspicious DNS Traffic"]
action.escu.data_models = ["Network_Resolution"]
dispatch.earliest_time = -31d@d
dispatch.latest_time = -1d@d
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = Create a machine-learning (ML) model to characterize the length of DNS requests seen in your environment to help identify unusually long ones that may be indicative of attacker infrastrucutre or the use of DNS as a command-and-control channel in your environment.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type | search DNS.record_type=* | `drop_dm_object_name("DNS")` | eval query_length = len(query) | fit DensityFunction query_length by record_type into dns_query_pdfmodel

[ESCU - Baseline of Excessive AWS Instances Launched by User - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Excessive AWS Instances Launched by User - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many RunInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of RunInstances performed by a user in a small time window.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.analytic_story = ["Cloud Cryptomining", "Suspicious AWS EC2 Activities"]
dispatch.earliest_time = -91d@d
dispatch.latest_time = -1d@d
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Create a machine-learning (ML) model to establish a baseline for how many RunInstances users do in the environment. This can help you identify excessive numbers of RunInstances which may warrant further investigation to determine if there is misuse or abuse.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success `ec2_excessive_runinstances_mltk_input_filter` | bucket span=10m _time | stats count as instances_launched by _time src_user | fit DensityFunction instances_launched threshold=0.0005 into ec2_excessive_runinstances_v1

[ESCU - Baseline of Excessive AWS Instances Terminated by User - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Excessive AWS Instances Terminated by User - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many TerminateInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of TerminateInstances performed by a user in a small time window.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
dispatch.earliest_time = -91d@d
dispatch.latest_time = -1d@d
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Create a machine-learning (ML) model to establish a baseline for how many TerminateInstances users do in the environment. This can help you identify excessive numbers of TerminateInstances which may warrant further investigation to determine if there is misuse or abuse.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=TerminateInstances errorCode=success `ec2_excessive_terminateinstances_mltk_input_filter` | bucket span=10m _time | stats count as instances_terminated by _time src_user | fit DensityFunction instances_terminated threshold=0.0005 into ec2_excessive_terminateinstances_v1

[ESCU - Baseline of Network ACL Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Network ACL Activity by ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls that were related to network ACLs made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-05-21
action.escu.modification_date = 2018-05-21
action.escu.analytic_story = ["AWS Network ACL Activity"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline for API calls related to network ACLs for the users who initiated this activity. It returns all logged API calls for network activity, pulls out the ARN that initiated each call, and collects the `eventNames` in one-hour groupings. Next, it calculates the number of API calls made per ARN per-hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis. It also includes the number of data points for each ARN. This table is stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for network ACLs, edit the macro `network_acl_events`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `network_acl_events` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | stats count

[ESCU - Baseline of S3 Bucket deletion activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of S3 Bucket deletion activity by ARN
description = This search establishes, on a per-hour basis, the average and standard deviation for the number of API calls related to deleting an S3 bucket by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-07-17
action.escu.modification_date = 2018-07-17
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline for API calls related to deleting an S3 bucket, grouped by the users who initiated this activity. It returns all logged API calls for S3 bucket-deletion activity and then pulls out the ARN that initiated each call. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis. It also includes the number of data points for each ARN. This table is stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=DeleteBucket | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | stats count

[ESCU - Baseline of SMB Traffic - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of SMB Traffic - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the number of SMB connections observed each hour for every day of week. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search to identify outliers in the number of SMB connections for that hour and day of the week.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware (DHS Report TA18-201A)", "Hidden Cobra Malware", "Netsh Abuse", "Ransomware"]
action.escu.data_models = ["Network_Traffic"]
dispatch.earliest_time = -31d@d
dispatch.latest_time = -1d@d
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = Create a machine-learning (ML) model to characterize the number of SMB connections observed in your environment. This may help identify spikes in SMB traffic that may be indicative of attackers scanning or attempting to propagate to other systems in your environment. By default, this model is built over 30 days of data and profiles the number of SMB connections in your environment by the hour of day/day of week that the connections occur.
action.escu.how_to_implement = You must be ingesting network traffic and populating the Network_Traffic data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. To improve your results, you may consider adding "src" to the by clause, which will build the model for each unique source in your enviornment. However, if you have a large number of hosts in your environment, this search may be very resource intensive. In this case, you may need to raise the value of max_inputs and/or max_groups in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=10m, All_Traffic.src | eval HourOfDay=strftime(_time, "%H") | eval DayOfWeek=strftime(_time, "%A") | `drop_dm_object_name("All_Traffic")` | fit DensityFunction count by "HourOfDay,DayOfWeek" into smb_pdfmodel

[ESCU - Baseline of Security Group Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Security Group Activity by ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-17
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline for API calls related to security groups by the users who initiated this activity. It returns all logged API calls for all security-group-related activity, pulls out the ARN that initiated each call, and collects the `eventNames` in one-hour groupings. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis. It also includes the number of data points for each ARN. This table is stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for security groups, edit the macro `security_group_api_calls`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `security_group_api_calls` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | stats count

[ESCU - Baseline of blocked outbound traffic from AWS]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of blocked outbound traffic from AWS
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-26
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline of blocked outbound network connections by each source IP in your AWS environment. This search returns all log events that correspond to a blocked outbound network connection, extracts the source IP from where the outbound connection was initiated, and collects the events in one-hour groupings. Next, it calculates the number of outbound connections blocked per hour. For each source IP, it calculates the average and standard deviation of this count on a per-hour basis.  It also includes the number of data points each source IP had. This table is then stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your `VPC flow logs.`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | bucket _time span=1h | stats count as numberOfBlockedConnections by _time, src_ip | stats count(numberOfBlockedConnections) as numDataPoints, latest(numberOfBlockedConnections) as latestCount, avg(numberOfBlockedConnections) as avgBlockedConnections, stdev(numberOfBlockedConnections) as stdevBlockedConnections by src_ip | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | stats count

[ESCU - Count of Unique IPs Connecting to Ports]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of Unique IPs Connecting to Ports
description = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
action.escu.creation_date = 2017-06-24
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = []
action.escu.data_models = ["Network_Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = For each port being accessed on the network, this search gives the total number of connections observed, and the number of unique IP addresses making those connections.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting network traffic, and populating the Network_Traffic data model.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count dc(All_Traffic.src) as numberOfUniqueHosts from datamodel=Network_Traffic by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Count of assets by category]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of assets by category
description = This search shows you every asset category you have and the assets that belong to those categories.
action.escu.creation_date = 2017-06-11
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.data_models = ["Identity_Management"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = This search gives you the number and the names of the hosts of each host in your environment by category. It will then sort them by the count.
action.escu.how_to_implement = To successfully implement this search you must first leverage the Assets and Identity framework in Enterprise Security to populate your assets_by_str.csv file which should then be mapped to the Identity_Management data model. The Identity_Management data model will contain a list of known authorized company assets. Ensure that all inventoried systems are constantly vetted and updated.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Identity_Management.All_Assets | stats count values(nt_host) by category | sort -count

[ESCU - Create a list of approved AWS service accounts]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Create a list of approved AWS service accounts
description = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into `aws_service_accounts.csv` lookup file.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-12-03
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = We first look for all successful CloudTrail API activity caused by types of user accounts and then remove all the events caused by users in the Identity table. This generates a list of accounts--typically service accounts--configured in your AWS environment. We output this list of service accounts to `aws_service_accounts.csv`.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the service account entires in `aws_service_accounts.csv`, which is a lookup file created as a result of running this support search. Please remove the entries of service accounts that are not legitimate.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail errorCode=success | rename userName as identity | search NOT [inputlookup identity_lookup_expanded | fields identity] | stats count by identity | table identity | outputlookup aws_service_accounts | stats count

[ESCU - DNSTwist Domain Names]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - DNSTwist Domain Names
description = This search creates permutations of your existing domains, removes the valid domain names and stores them in a specified lookup file so they can be checked for in the associated detection searches.
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.eli5 = This search starts with the dnstwist command consuming domains from a file called domains.csv in the DA-ESS-SOC/lookups directory. This search then adds a domain\_abuse=true term to each permutation, removes all the valid domain names and stores all that information into a lookup file that is used in the associated detection search. Alternatively domain dnstwist permutations can be calculated from domains in the `cim_corporate_email_domains.csv` and `cim_corporate_web_domains.csv` lookups located in **Splunk\_SA\_CIM** using argument `populate_from_cim=true`. Also an individual domain can be passed using argument `domain=<domain>`
action.escu.how_to_implement = To successfully implement this search you need to update the file called domains.csv in the DA-ESS-SOC/lookup directory. Or `cim_corporate_email_domains.csv` and `cim_corporate_web_domains.csv` from **Splunk\_SA\_CIM**.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | dnstwist domainlist=domains.csv | `remove_valid_domains` | eval domain_abuse="true" | table domain, domain_abuse | outputlookup brandMonitoring_lookup | stats count

[ESCU - Discover DNS records]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Discover DNS records
description = The search takes corporate and common cloud provider domains configured under `cim_corporate_email_domains.csv`, `cim_corporate_web_domains.csv`, and `cloud_domains.csv` finds their responses across the last 30 days from data in the `Network_Resolution ` datamodel, then stores the output under the `discovered_dns_records.csv` lookup
action.escu.creation_date = 2019-02-14
action.escu.modification_date = 2019-02-14
action.escu.analytic_story = ["DNS Hijacking"]
action.escu.data_models = ["Network_Resolution"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = Discover the DNS records and their answers for domains owned by the company using network traffic events. The discovered events are exported as a lookup named `discovered_dns_records.csv`
action.escu.how_to_implement = To successfully implement this search, you must be ingesting DNS logs, and populating the Network_Resolution data model. Also make sure that the cim_corporate_web_domains and cim_corporate_email_domains lookups are populated with the domains owned by your corporation
action.escu.known_false_positives = Please vet the lookup created by this baseline search 
action.escu.fields_required = ["query", "answer"]
action.escu.entities = ["query", "answer"]
disabled = true
schedule_window = auto
is_visible = false
search = | inputlookup cim_corporate_email_domains.csv | inputlookup append=T cim_corporate_web_domains.csv | inputlookup append=T cim_cloud_domains.csv | eval domain = trim(replace(domain, "\*", "")) | join domain [|tstats `security_content_summariesonly` count values(DNS.record_type) as type, values(DNS.answer) as answer from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,domain,type,query,answer | outputlookup createinapp=true discovered_dns_records.csv

[ESCU - Identify Systems Creating Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Creating Remote Desktop Traffic
description = This search counts the numbers of times the system has generated remote desktop traffic.
action.escu.creation_date = 2017-04-24
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
action.escu.data_models = ["Network_Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = This search counts the numbers of times the system has tried to connect to another system on TCP/3389, the default port used for RDP traffic.
action.escu.how_to_implement = To successfully implement this search, you must ingest network traffic and populate the Network_Traffic data model.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Receiving Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Receiving Remote Desktop Traffic
description = This search counts the numbers of times the system has created remote desktop traffic
action.escu.creation_date = 2017-04-24
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
action.escu.data_models = ["Network_Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = This search counts the numbers of times the system has received a connection to TCP/ 3389, the default port used for RDP traffic.
action.escu.how_to_implement = To successfully implement this search you must ingest network traffic and populate the Network_Traffic data model. If a system receives a lot of remote desktop traffic, you can apply the category common_rdp_destination to it.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.dest | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Using Remote Desktop]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Using Remote Desktop
description = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
action.escu.data_models = ["Endpoint"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system. It does this by looking for the process name in the Endpoint data model.
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that records process activity.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Endpoint.Processes where Processes.process_name="*mstsc.exe*" by Processes.dest Processes.process_name | `drop_dm_object_name(Processes)` | sort - count

[ESCU - Monitor Successful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Successful Backups
description = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = This search gives you the count and the hostname of all the systems that had a successful backup each day.
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" "Disk/Partition backup completed successfully." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Monitor Unsuccessful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Unsuccessful Backups
description = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = This search gives you the count and hostname of all the systems that had a backup failure each day
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" "An error occurred, failed to backup." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Previously Seen AWS Cross Account Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Cross Account Activity
description = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.creation_date = 2018-06-04
action.escu.modification_date = 2018-06-04
action.escu.analytic_story = ["AWS Cross Account Activity"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we look for **AssumeRole** events where the requesting account is different from the requested account. The first and last times these events are seen are written to a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId!=requestedAccountId | stats earliest(_time) as firstTime latest(_time) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | stats count

[ESCU - Previously Seen AWS Provisioning Activity Sources]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Provisioning Activity Sources
description = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = This search includes any event name that begins with "run" or "create," and then determines the first and last time these events were seen for each IP address that initiated the action. The search then consults a **GeoIP** database to determine the physical location of this IP address. This table outputs to a file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats count

[ESCU - Previously Seen AWS Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Regions
description = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the first time (earliest) and most recent time (latest) that this region has been seen in our dataset, grouped by the value `awsRegion`. We only look for those events where an instance has been started. All of these entries will be added to the `previously_seen_aws_regions.csv` lookup file, which will act like a baseline for detections. Please validate the entries of region names in the lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail StartInstances | stats earliest(_time) as earliest latest(_time) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | stats count

[ESCU - Previously Seen Cloud Compute Creations By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Creations By User
description = This search builds a table of previously seen users that have launched a cloud compute instance.
action.escu.creation_date = 2019-10-03
action.escu.modification_date = 2018-03-15
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest time for each user that has created a cloud compute instance.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `previously_seen_cloud_compute_creations_by_user_input_filter` by Compute.src_user | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_compute_creations_by_user | stats count

[ESCU - Previously Seen Cloud Compute Images]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Images
description = This search builds a table of previously seen images used to launch cloud compute instances
action.escu.creation_date = 2019-10-03
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest time for each image id that has been seen. This table is then outputted to a csv file.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `previously_seen_cloud_compute_image_input_filter` by Compute.image_id | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_compute_images | stats count

[ESCU - Previously Seen Cloud Compute Instance Types]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Instance Types
description = This search builds a table of previously seen cloud compute instance types
action.escu.creation_date = 2019-10-03
action.escu.modification_date = 2019-10-03
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.eli5 = In this support search, we create a table of the first time `firstTime` and most recent time `lastTime` that the compute type has been seen in our dataset. We only look for those events where an instance has been created. All of these entries will be added to the `previously_seen_cloud_compute_instance_types` lookup file, which will act as a baseline for detections.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `previously_seen_cloud_compute_instance_types_input_filter` by Compute.instance_type | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_compute_instance_types | stats count

[ESCU - Previously Seen Cloud Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Regions
description = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
action.escu.creation_date = 2019-10-02
action.escu.modification_date = 2019-10-02
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Cloud_Infrastructure"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS", "Azure", "GCP"]
action.escu.eli5 = In this support search, we create a table of the first time `firstTime` and most recent time `lastTime` that this region has been seen in our dataset, grouped by the region. We only look for those events where an instance has been started. All of these entries will be added to the `previously_seen_cloud_regions` lookup file, which will act like a baseline for detections.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Cloud_Infrastructure.Compute where Compute.action=start `previously_seen_cloud_regions_input_filter` by Compute.region | `drop_dm_object_name("Compute")` | outputlookup previously_seen_cloud_regions | stats count

[ESCU - Previously Seen EC2 AMIs]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 AMIs
description = This search builds a table of previously seen AMIs used to launch EC2 instances
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest time that a specific AMI ID has been seen. This table is then outputted to a csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename requestParameters.instancesSet.items{}.imageId as amiID | stats earliest(_time) as firstTime latest(_time) as lastTime by amiID | outputlookup previously_seen_ec2_amis.csv | stats count

[ESCU - Previously Seen EC2 Instance Types]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Instance Types
description = This search builds a table of previously seen EC2 instance types
action.escu.creation_date = 2018-03-08
action.escu.modification_date = 2018-03-08
action.escu.analytic_story = ["AWS Cryptomining"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest time that a specific EC2 instance type has been seen. The instanceType request field is not required and defaults to m1.small, so any time this field is null, the search defaults the field to m1.small. This table is then outputted to a csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename requestParameters.instanceType as instanceType | fillnull value="m1.small" instanceType | stats earliest(_time) as earliest latest(_time) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | stats count

[ESCU - Previously Seen EC2 Launches By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Launches By User
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-15
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest times that an ARN has launched a EC2 instance. This table is then outputted to a csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename userIdentity.arn as arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | stats count

[ESCU - Previously Seen EC2 Modifications By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Modifications By User
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-04-05
action.escu.modification_date = 2018-04-05
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest times that an ARN has modified a EC2 instance. The list of APIs that modify an EC2 are defined in the `ec2_modification_api_calls` macro for ease of use. This table is then outputted to a file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `ec2_modification_api_calls` errorCode=success | spath output=arn userIdentity.arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | stats count

[ESCU - Previously Seen Running Windows Services]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Running Windows Services
description = This collects the services that have been started across your entire enterprise.
action.escu.creation_date = 2018-07-20
action.escu.modification_date = 2019-02-27
action.escu.analytic_story = ["Orangeworm Attack Group", "Windows Service Abuse"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = In this support search, we look for Windows system-event code that indicates a status change of a Windows service. It extracts both the name of the service and the action taken by the service from the logs. It keeps only services that have entered the running state. Finally, it finds the first time the service has been seen running across the enterprise and writes that file to a lookup table.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_system signature_id=7036 | rex field=Message "The (?<serviceName>[\w\s-]*) service entered the (?<action>\w*) state" | where action="running" | stats earliest(_time) as firstTime, latest(_time) as lastTime by serviceName | outputlookup previously_seen_running_windows_services | stats count

[ESCU - Previously seen API call per user roles in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen API call per user roles in CloudTrail
description = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset--grouped by user role and name of the API call--that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
action.escu.creation_date = 2018-04-01
action.escu.modification_date = 2018-04-16
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we are looking for successful API calls made by user roles within your AWS infrastructure. The intent is to create an initial baseline cache of names of the API calls per security role for the previous 30 days--including the earliest and latest times seen in our dataset--grouped by the value of user role and the name of the API call. It is also worth noting that the role of a particular user is parsed as "userName" in the CloudTrail logs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user role entries in `previously_seen_api_calls_from_user_roles.csv`, which is a lookup file created as a result of running this support search.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles | stats count

[ESCU - Previously seen S3 bucket access by remote IP]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen S3 bucket access by remote IP
description = This search looks for successful access to S3 buckets from remote IP addresses, then creates a baseline of the earliest and latest times we have encountered this remote IP within the last 30 days. In this support search, we are only looking for S3 access events where the HTTP response code from AWS is "200"
action.escu.creation_date = 2018-06-28
action.escu.modification_date = 2018-06-28
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we are looking for successful S3 bucket-access attempts made from remote IPs. The intent is to create an initial baseline cache of remote IP addresses per bucket name for the previous 30 days--including the earliest and latest times seen in our dataset--grouped by the value of remote IP and the name of the S3 bucket.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access-logs inputs. You must validate the remote IP and bucket name entries in `previously_seen_S3_access_from_remote_ip.csv`, which is a lookup file created as a result of running this support search.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:s3:accesslogs http_status=200  | stats  earliest(_time) as earliest latest(_time) as latest by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip | stats count

[ESCU - Previously seen command line arguments]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen command line arguments
description = This search looks for command-line arguments where `cmd.exe /c` is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2019-03-01
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Hidden Cobra Malware", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity"]
action.escu.data_models = ["Endpoint"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = In this support search, we look for command-line arguments using the parameter `/c` to execute processes and create an initial baseline cache for the previous 30 days. This will include the earliest and latest times a particular command-line argument is seen in our dataset, grouped by the command-line value.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe AND Processes.process="* /c *" by Processes.process | `drop_dm_object_name(Processes)`

[ESCU - Previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen users in CloudTrail
description = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last 30 days.
action.escu.creation_date = 2018-02-23
action.escu.modification_date = 2018-04-30
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we look for console login events by a particular user and create an initial baseline cache for the previous 30 days, including the earliest and latest times, City, Region, and Country a particular user ARN is seen in our dataset, grouped by the ARN value. In cases where City and Region cannot be determined, the source IP address is substituted for these values.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins.csv`, which is a lookup file created as a result of running this support search.
action.escu.known_false_positives = n/a
action.escu.fields_required = ["user", "src"]
action.escu.entities = ["user", "src"]
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=ConsoleLogin | rename userIdentity.arn as user | iplocation src | eval City=if(City LIKE "",src,City),Region=if(Region LIKE "",src,Region) | stats earliest(_time) as firstTime latest(_time) as lastTime by user src City Region Country | outputlookup previously_seen_users_console_logins.csv | stats count

[ESCU - Systems Ready for Spectre-Meltdown Windows Patch]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Systems Ready for Spectre-Meltdown Windows Patch
description = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
action.escu.data_models = ["Change_Analysis"]
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = This search looks to see if a registry key was created at `HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat`. It will tell you when it was created and, if possible, what process created it.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - Update previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Update previously seen users in CloudTrail
description = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last hour.
action.escu.creation_date = 2019-04-25
action.escu.modification_date = 2018-04-30
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
dispatch.earliest_time = -60m@m
dispatch.latest_time = m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we look for console login events by a particular user to update the baseline cache of users/arns making the accesses, including the earliest and latest times, City, Region, and Country a particular user ARN is seen in our dataset, grouped by the ARN value. In cases where City and Region cannot be determined, the source IP address is substituted for these values.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins.csv`, which is a lookup file created as a result of running this support search.
action.escu.known_false_positives = n/a
action.escu.fields_required = ["user", "src"]
action.escu.entities = ["user", "src"]
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=ConsoleLogin | rename userIdentity.arn as user | iplocation src | eval City=if(City LIKE "",src,City),Region=if(Region LIKE "",src,Region) | stats earliest(_time) AS firstTime latest(_time) AS firstTime by user src City Region Country | inputlookup append=t previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(firstTime) as firstTime by user src City Region Country | outputlookup previously_seen_users_console_logins.csv

[ESCU - Windows Updates Install Failures]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Failures
description = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = []
action.escu.data_models = ["Updates"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = This search gives you the count of the number of systems that attempted and failed to install a Windows update each day.
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=failure by _time span=1d

[ESCU - Windows Updates Install Successes]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Successes
description = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = []
action.escu.data_models = ["Updates"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = This search gives you the count and name of all the systems that had a successful update applied each day
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
action.escu.known_false_positives = 
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=installed by _time span=1d


### USAGE DASHBOARD CONFIGURATIONS ###

[escu-metrics-usage]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
`comment("Find all the search names in the audittrail.")`\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name=="","Adhoc","Scheduled")) \
`comment("If the savedsearch_name field in the audittrail is empty, the search was run adhoc. Otherwise it was run as a scheduled search")`\
| rex field=search "\"(?<savedsearch_name>.*)\""\
`comment("Extract the name of the search from the search string")`\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*

[escu-metrics-search]
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
enableSched = 1
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_audit action=search | transaction search_id maxspan=3m | search ESCU | stats sum(total_run_time) avg(total_run_time) max(total_run_time) sum(result_count)

[escu-metrics-search-events]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
enableSched = 1
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = [search index=_audit sourcetype="audittrail" \"ESCU NOT "index=_audit" | where search !="" | dedup search_id | rex field=search "\"(?<search_name>.*)\"" | rex field=_raw "user=(?<user>[a-zA-Z0-9_\-]+)" | eval usage=if(savedsearch_name!="", "scheduled", "adhoc") | eval savedsearch_name=if(savedsearch_name != "", savedsearch_name, search_name) | table savedsearch_name search_id user _time usage | outputlookup escu_search_id.csv | table search_id] index=_audit total_run_time event_count result_count NOT "index=_audit" | lookup escu_search_id.csv search_id | stats count(savedsearch_name) AS search_count avg(total_run_time) AS search_avg_run_time sum(total_run_time) AS search_total_run_time sum(result_count) AS search_total_results earliest(_time) AS firsts latest(_time) AS lasts by savedsearch_name user usage| eval first_run=strftime(firsts, "%B %d %Y") | eval last_run=strftime(lasts, "%B %d %Y")

[escu-metrics-search-longest-runtime]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
enableSched = 1
cron_schedule = 0 0 * * *
disabled = 1
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_* ESCU [search index=_* action=search latest=-2h earliest=-1d| transaction search_id maxspan=3m | search ESCU | stats values(total_run_time) AS run by search_id | sort -run | head 1| table search_id] | table search search_id

[escu-metrics-usage-search]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
enableSched = 1
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
`comment("Find all the search names in the audittrail. Ignore the last few minutes so we can exclude this search's text from the result.")`\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name=="","Adhoc","Scheduled")) \
`comment("If the savedsearch_name field in the audittrail is empty, the search was run adhoc. Otherwise it was run as a scheduled search")`\
| rex field=search "\"(?<savedsearch_name>.*)\""\
`comment("Extract the name of the search from the search string")`\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*

### END OF USAGE DASHBOARD CONFIGURATIONS ###